\documentclass[12pt,twoside]{reedthesis}

\usepackage{graphicx,latexsym}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace} 
\usepackage[hyphens]{url}
\usepackage{rotating}
\usepackage{hyperref}
\usepackage{outlines}
\usepackage{enumitem} % custom labels

% font stuff
\usepackage{bbm, stmaryrd}
\usepackage{unicode-math} % $this is incompatible with Coloneqq for some reason, and I'm not sure why I used it in the first place...
\usepackage{luatexja} % for memes

\usepackage{amsmath}
\usepackage{mathtools} % paired delimeters
\usepackage{braket}
\usepackage{epigraph} % funny quotes
\usepackage{tikz-cd} % diagrams

\usepackage{mathpartir} % inference rules

\usepackage[
backend=biber,
style=alphabetic,
citestyle=alphabetic
]{biblatex} % better citation style
\addbibresource{thesis.bib}

\hypersetup{
  colorlinks,
  allcolors=black,
  hidelinks,
}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{joke}{Joke}
\newtheorem{notation}{Notation}
\newtheorem{remark}{Remark}

\theoremstyle{remark}
\newtheorem{recall}{Recall}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corrolary}{Corrolary}

\include{autodelims}
\include{macros}

\newcommand{\cl}{\text{Cl}_\Sigma}
\newcommand{\ren}{\text{Ren}_\Sigma}
\newcommand{\renhat}{\hat{\ren}}
\newcommand{\tm}{\mathfrak{Tm}}
\newcommand{\catset}{\mathfrak{Set}}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}

% Comment out the natbib line above and uncomment the following two lines to use the new 
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the 
% bibliography is included. 
% \usepackage{biblatex-chicago}
% \bibliography{thesis}

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino

\title{慣性ドリフト: From 0 to Normalization by Gluing in 4.9 seconds\\ A Brisk Drift through Categorical Semantics of Lambda Calculi}
\author{Jay Kruer}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{December 2021}
\division{Mathematics and Natural Sciences}
\advisor{Ang\'elica Osorno}
\altadvisor{James (Jim) Fix}

\department{Mathematics}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
\thedivisionof{The Established Interdisciplinary Committee for Mathematics and Computer Science}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
% \approvedforthe{Committee}

\setlength{\parskip}{0pt}

\begin{document}

\maketitle
\frontmatter % this stuff will be roman-numbered
\pagestyle{empty} % this removes page numbers from the frontmatter

% Acknowledgements (Acceptable American spelling) are optional
% So are Acknowledgments (proper English spelling)
\chapter*{Acknowledgements}
% Jaclyn, My parents, Uncle Jay, Grandma, Aunt Susie, Jim Fix, Ang\'elica
% Osorno, Irena Swanson, Kyle Ormsby, Amal Ahmed for taking me under her wing
% and overseeing my scientific development when I took a leap of faith to Boston, Albyn Jones, Jaclyn, Nick
% Chaiyachakorn, Ms.\ King, 柳老師 (Hyong Rhew), Mrs.\ Leitsch, Mr.\ Raveli,
% Noah Koster, Shulav, Aditya, Francis, Alec Forget, Joebob, Jit, Eli, Gabe and
% Ciara, Murali Vijayaraghavan, 吳老師, Ian Desai, Becca, Andres, Sara
% Rosenberger in the business office, the GNU project and free software
% foundation along with the developers of so many other free software projects
% whose generously donated works were instrumental in the production of this
% thesis.

% Alice McKean

% My van

% Megan, Luke, Ryan, Kathleen

% Young Kim for corrupting my soul
% Salma, Mary, Carter, Dan Genya, Tristan, Max
% Holden

% Curtis, Cody Roux and Dan McArdle at the Charles Stark Draper Laboratory for
% early encouragement!

% I would like to give special thanks to Paul Taylor who, though I do not know
% him personally, wrote the book that made this thesis possible. Almost every
% day spent on this project I learned a new awe-inspiring fact about the lambda
% calculus and its semantics. Paul's book is a love letter to the type of
% computer scientist who wants to understand how the world works.

% The preface is optional
% To remove it, comment it out or delete it.
\chapter*{Preface}
\epigraph{And further, by these, my son, be admonished: of making many books
  there is no end; and much study is a weariness of the flesh.}{Ecclesiastes
  12:12, KJV.}

I don't know what to put here, but this is certainly a funny quote that should
find a home somewhere in the thesis.

% \chapter*{List of Abbreviations}
% \begin{table}[h]
%   \centering % You could remove this to move table to the left
%   \begin{tabular}{ll}
%     \textbf{TMA}  	&  Too Many Abbreviations
%   \end{tabular}
% \end{table}


\tableofcontents
% if you want a list of tables, optional
\listoftables
% if you want a list of figures, also optional
\listoffigures

% The abstract is not required if you're writing a creative thesis (but aren't they all?)
% If your abstract is longer than a page, there may be a formatting issue.
\chapter*{Abstract}
Normalization by gluing is poggers.

% \chapter*{Dedication}


\mainmatter% here the regular arabic numbering starts
\pagestyle{fancyplain} % turns page numbering back on

% The \introduction command is provided as a convenience.
% if you want special chapter formatting, you'll probably want to avoid using it altogether

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
\chaptermark{Introduction}
\markboth{Introduction}{Introduction}
% The three lines above are to make sure that the headers are right, that the intro gets included in the table of contents, and that it doesn't get numbered 1 so that chapter one is 1.

% Double spacing: if you want to double space, or one and a half 
% space, uncomment one of the following lines. You can go back to 
% single spacing with the \singlespacing command.
% \onehalfspacing
% \doublespacing

Blah blah blah, I should write some stuff about how category theory helps us
avoid insane proof heuristics in metatheory of type theory.

\chapter{Functorial semantics: sketches and their models; algebraic theories and their algebras}
In this chapter we develop tools for reasoning about (syntactic)
\emph{theories}, which are in some sense ``notions of'' abstract structure.
Examples of theories include the theory of rings, and simple type theory. To
discuss how we write down our theories, we need another level of abstraction. We
will work with several \emph{notions of} (syntactic) theory, and we will more
laconically refer to a notion of syntactic theory as a \emph{doctrine}. A
\emph{doctrine} is something like a meta-framework specifying how we are to
write down a theory. The first doctrine we will consider is that of the
\emph{elementary sketch}. % The reader familiar with and/or traumatized by
% experience with pencils of geodesics in hyperbolic geometry need not be scared
% away by this terminology; there is nothing non-Euclidean afoot here.
The doctrine of the \emph{elementary sketch} allows us to write down theories
involving \emph{unary} operations (those defined over a single argument.) This
restriction on the arity of operations turns out to be quite limiting. To
address this, we will later upgrade the doctrine of elementary sketches to the
doctrine of \emph{algebraic theories} which allow encoding operations with any
finite number of arguments, thus covering a broad variety of theories. Algebraic
theories are known more famously as \emph{Lawvere theories} after categorical
logic superstar (and former Reed College professor!) William Lawvere who
originally studied them while building his functorial treatment of universal
algebra. Keeping with our sketchy terminology and emphasizing the doctrinal
upgrade, algebraic theories are also called \emph{finite product sketches}. As
an example of the strength of algebraic theories, we will show how to write down
(as an algebraic theory) what it means to be a ring, with no reference to sets
or functions. In the following chapter, we will use the doctrine of algebraic
theories to develop categorical semantics of the lambda calculus. This chapter
is strictly expository in nature. Much of the following presentation draws
heavily from Paul Taylor's \emph{Practical Foundations of
  Mathematics}~\cite{taylor_practical_1999}. Our humble contribution is to flesh
out some of his examples, add some of our own, and make parts of the
presentation more palatable and quickly digestible to the reader already
acquainted with basic category theory and type theory.

\section{Elementary sketches and their models}
\subsection{An algebraic prelude}
We begin by recalling from algebra the notion of an \emph{action} of, say, a
group or a monoid. Actions are, from our perspective, a way of giving meaning,
or \emph{semantics} to elements of a set which enjoys some algebraic structure.
\begin{definition}\label{def:covariant action}
  Recall that a \textbf{covariant action} of a group or monoid \((M, id, \cdot)\) on
  a set \(A\) is a binary operation \((-)_* (=) : M ‌\times A \rightarrow A\) such that
  \(\text{id}_* a = a\) and \( (g \circ f)_* a = g_* (f_* a) \). We can similarly a
  define the notion of a \textbf{contravariant action} which similarly requires
  the identity action to do nothing, but instead flips the order of action for
  compositions: $(g \circ f)^{*}a = f^{*}(g^{*} a)$
\end{definition}

For example, in algebra we learn that the dihedral group of order 8, written
$D_{4}$, acts on the square (with uniquely identified points) by reflections and
rotations\footnote{https://groupprops.subwiki.org/wiki/Dihedral\_group:D8}; each
of the operations encoded by the action results in the same image of the square
up to ignoring the unique identity of the points we started with. This action
gives geometric meaning to each of the group elements, and was used in the first
day of the author's algebra class to explain the algebraic mechanics of the
group itself; discovering which elements of the group are inverse to one another
is done by geometric experimentation using a square with uniquely colored
vertices. Similarly, the symmetric groups $S_{n}$ act on lists of length $n$ by
permutation of the list elements. In this case, the action can be even more
trivially defined. We now turn to the definition of an important property of
actions: \emph{faithfulness}.

\begin{definition}\label{def:faithful}
  A \textbf{faithful} action $(-)_{*}$ is one for which things are
  \emph{semantically} equal (or, act the same) only when they are
  \emph{syntactically} equal (or, \emph{are} the same as far as your eyeballs
  are concerned.) More precisely rendered, we
  require: \[ \forall (a:A)\ldotp f_* a = g_* a \Longrightarrow f = g \]
\end{definition}

It can now be seen that the crucial property enjoyed by the natural action of
$D_{8}$ on the square which enabled our use of paper cutouts in studying the
group is faithfulness. If the action were not faithful, determining which
operations in $D_{8}$ are inverses would not be so easy as printing out a square
and plugging away, because we may (among other catastrophes) be working with an
action which may not take only the identity element to the
leave-everything-in-place operation on the square.

Having gesticulated that actions gives groups and monoids their meaning, we turn
to the development of the doctrines of \emph{elementary sketch} and
\emph{algebraic theory} which will allow us to generalize both sets with
algebraic structures and their actions to new settings.

\subsection{Elementary sketches}
As promised, we begin with the definition.
\begin{definition}\label{def:elem sketch}
  An \textbf{elementary sketch} is comprised of the following data:
  \begin{enumerate}
    \item a collection \(X, Y, Z, \dots \) of named \textbf{base types} or
          \textbf{sorts}
    \item a \textbf{variable} \(x:X\) for each occurrence of each named sort.
    \item a collection of \textbf{unary operation-symbols} or
          \textbf{constructors} \(\tau\) having at most one variable. As a
          clarifying example: when sketching type theories, we will write
          \( x:X \vdash \tau(x) : Y \).
    \item a collection of equations or \textbf{laws} of the
          form: \[ \tau_n (\tau_{n-1}(\cdots \tau_2 (\tau_1 (x))\cdots )) = \sigma_m (\sigma_{m-1}(\cdots \sigma_2 (\sigma_1 (x))\cdots )) \]
  \end{enumerate}
\end{definition}

We will discuss the generality provided by this definition after some
intervening examples. One of the simplest examples is the sketch of a (free)
monoid on some set $S$:

\begin{example}[Sketch of a (free) monoid]\label{ex:monoid sketch}
  The requisite data for the sketch are as follows:
  \begin{enumerate}
    \item The collection of sorts is the singleton \( \{M\} \).
    \item The collection of variables is \( \{m:M\} \).
    \item The collection of operation symbols is the set \( S \). Each has as its signature \( M \rightarrow M \)
    \item No equations are imposed.
  \end{enumerate}
\end{example}

To really buy that this sketch generates a free monoid, we need an intervening
definition of a concept we will get a lot of mileage out of in this thesis. The
idea should already be familiar from our study of type theory, despite the
drastically simplified setting.

\begin{definition}\label{def:term}
  Given an elementary sketch, a \textbf{term} $x : \Gamma \vdash X$ is a string of
  composable unary operation-symbols applied to a variable $\gamma : \Gamma$ as in:
  \( \tau_{n} (\tau_{n-1} (\cdots (\tau_{2}(\tau_{1}(\gamma))))) \). Composable unary-operation
  symbols are ones which have compatible domains and codomains in the usual
  sense as in set theory.
\end{definition}

We now propose a more precise version of the above claim: the terms of the
sketch defined above form the elements of a free monoid over $S$. Before we can
continue, we should decide what our term composition will be.

\begin{definition}[Composition of terms]\label{def:term composition}
  Composition of terms is by substitution for the variable: for a term
  \( \sigma : \Delta \vdash \Gamma\) and some terms \( \tau_{i}\) with \( \tau_{n} : \cdots \vdash \Xi \) we define
  \[ (\tau_{n} (\tau_{n-1} (\cdots (\tau_{2}(\tau_{1}(\gamma)))))) \circ \sigma = \tau_{n} (\tau_{n-1} (\cdots (\tau_{2}(\tau_{1}(\sigma(\delta)))))) : \Delta \vdash \Xi. \]
\end{definition}

With our notion of composition in hand, we can now handwave an argument for our
revised claim that the terms of the sketch form the elements of a free monoid.
The reader will recall from our early discussions of basic type theory that
substitution is associative [TODO in Ch 1]. As a consequence, any elementary
sketch, including this one, satisfies that axiom for free. The identity term is
given by zero composable unary operation-symbols applied to a variable. It's
just a variable; when composing the identity term with any other term, we end up
getting exactly that original term.

This loose argument is somewhat satisfying, but we can do better. To get there,
we will first develop a notion generalizing \emph{actions} from algebra. After
doing so, we will give more concrete meaning to this sketch and complete our
intuitive handle on it.

\begin{definition}\label{def:model}
  A \textbf{model} (also known as an algebra, an interpretation, a covariant
  action) of an elementary sketch is comprised of:
  \begin{enumerate}
    \item an assignment of a set $A_X$ to each sort $X$ and
    \item an assignment of a function $\tau_* : A_X \rightarrow A_Y$ for each
    operation-symbol of the appropriate arity such that:
    \item each law is preserved; i.e., for each law as before we have
    \[ {\tau_n}_* ({\tau_{n-1}}_* (\cdots {\tau_2}_* ({\tau_1}_* (x))\cdots )) = {\sigma_m}_* ({\sigma_{m-1}}_*(\cdots {\sigma_2}_* ({\sigma_1}_* (x))\cdots )) \]
    that is, the covariant action on operation-symbols is faithful in
    the sense defined above.
  \end{enumerate}
\end{definition}

The next definition will feature prominently in our later study of type theory,
but will also prove immediately useful in studying Example~\ref{ex:monoid
  sketch} by forming the sets of a ``for-free'' model for any elementary sketch.

\begin{definition}\label{def:clone}
  Given an elementary (unary) sketch, the \textbf{clone} at \( (\Gamma, X) \) is
  the set \( \text{Cn}_{\mathcal{L}} (\Gamma, X) \) of all the \textbf{terms} of sort
  $X$ assuming a single variable of sort $\Gamma$, quotiented by the laws of the
  sketch.
\end{definition}
The fact that a sketch's clones contain \emph{equivalence classes} (with respect
to the laws) of its terms will feature prominently in our later study of ideas
central to the goals of this thesis. In particular, clones alone don't allow for
any meaningful discussion of computational behavior of terms undergoing
reduction; a term's normal form and its various reducible forms are identified
in the clone.

It can be shown that the clones of a sketch form (the sets for) a model of a
sketch. In particular, it can be shown that the sketch acts covariantly on the
set of its clones:
\begin{theorem}\label{thm:clone model}
  Every elementary sketch has a faithful covariant action on its clones
  \(\mathcal{H}_{X} = \cup_{\Gamma} \text{Cn}_{\mathcal{L}}(\Gamma,X)\) by sequencing with
  the operation symbol. Substitution for the (single) variable in a term gives
  a faithful contravariant action on
  \(\mathcal{H}^{Y} = \cup_{\Theta} \text{Cn}_{\mathcal{L}}(Y,\Theta)\).
\end{theorem}
\begin{proof}
  The actions of \(\tau : X \rightarrow Y\) on
  \(\text{Cn}_{\mathcal{L}} (\Gamma,X) \subseteq \mathcal{H}_{X}\) and
  \(\text{Cn}_{\mathcal{L}} (Y,\Theta) \subseteq \mathcal{H}^{Y}\) are given by:
  \begin{itemize}
    \item \(\tau_{*}a_{n}(\cdots a_{2}(a_{2}(\sigma))\cdots) =
    \tau(a_{n}(\cdots(a_{2}(a_{1}(\sigma))))) \in
    \text{Cn}_{\mathcal{L}}(\Gamma,Y)\)
    \item \(\tau^{*}\zeta_{m}(\cdots \zeta_{2}(\zeta_{1}(y))) =
    \zeta_{m}(\cdots\zeta_{2}(\zeta_{1}(\tau(x)))) \in
    \text{Cn}_{\mathcal{L}}(X,\Theta)\)
  \end{itemize}
  where \(\sigma : \Gamma, x : X, \text { and }, y:Y\). Covariance of the
  former is clear. Contravariance of the latter follows by considering the
  behavior of substitutions in sequence.
\end{proof}

Recalling our sketch of a monoid from Example~\ref{ex:monoid sketch}, the
substance of this covariant action morally amounts to saying that the sketch
acts on its terms by left multiplication (here ``multiplication'' is actually
just juxtaposition plus some parentheses) which gives the robust version of the
handwavy argument we provided above.

\begin{joke}
  A couple of type theorists walk into a Michelin starred restaurant. The menu
  reads in blackboard bold letters $\mathbbm{``NO\, SUBSTITUTIONS''}$. They promptly leave.
\end{joke}

\subsection{The category of contexts and substitutions}
We now introduce a very special category. This category is special in both the
structure it enjoys as well as the central role it will play in the rest of the
thesis. This category goes by many names: \emph{syntactic category}, the (rather
verbose) \emph{category of contexts and substitutions}, and the elusive
\emph{classifying category}. We endeavor to explain the meaning behind each of
these names over the course of the thesis, but for now we adopt the name most
closely describing its presentation.



\begin{definition}[The category of contexts and substitutions]\label{def:syn cat}
  Given a sketch $\mathcal{L}$, the \textbf{category of contexts and substitutions}, written \( \text{Cn}^{\times}_{\mathcal{L}}\) is presented as follows:
  \begin{outline}
    \1 The objects are the contexts of \( \mathcal{L} \), i.e., finite lists of
    distinct variables and their types.

    \1 The generating morphisms are:

    \2 Single substitutions or \emph{declarations} \( [a/x] : \Gamma \rightarrow [\Gamma, x:X] \)
    for each term \( \Gamma \vdash a : X \). The direction in the signature should be
    confusing unless you're either already an expert or a total novice to type
    theory.

    \2 Single omissions or \emph{drops} \( \hat{x} : [\Gamma, x : X] \rightarrow \Gamma \) for each
    variable $x:X$.

    \1 The laws are given by an extended version of the familiar substitution
    lemma from type theory. The following laws are added for each collection of
    terms $a,b$ and distinct variables $x$ and $y$ such that $x$ does not appear
    free in $a$ and $y$ appears free in neither $a$ or $b$:
    \begin{align*}
      % declaration follow by drop does nothing
      [a/x] ; \hat{x} &= \id \\
      % successive declarations commute up to accounting for the first
      % declaration in the body of the second
      [a/x] ; [b/y]   &= [ [ a/x ]^{*} b/y ] ; [a/x] \\
      % non-overlapping declarations and drops commute
      [a/x]; \hat{y} &= \hat{y}; [a/x] \\
      % non-overlapping drops commute
      \hat{x}; \hat{y} &= \hat{y}; \hat{x} \\
      [x/y]; \hat{x}; [y/x]; \hat{y} &= \id
    \end{align*}
  \end{outline}
  We will briefly speak to the meaning of the laws. The first law says that
  binding a variable to some term and then forgetting the variable is just the
  same as doing nothing. The second law says that successive variable
  declarations commute \emph{up to accounting for the first declaration in the
    body of the second}. The third law says that \emph{non-overlapping}
  declarations and drops commute. The fourth law says that pairs of
  non-overlapping drops commute. The last law is tricky and is easier to explain
  by passing to the substitution point-of-view. Since the substitution functor
  is contravariant, this requires considering the compositions in reverse order
  as:
  \[ \hat{y}^{*}; [y/x]^{*}; \hat{x}^{*}; [x/y]^{*} = {\id}^{*} \] Rendered
  thus, this law means that introducing a free variable $y$ to the
  context\footnote{possibly having no effect if $y$ is already present},
  followed by replacing every free occurrence of $x$ with $y$, followed by
  re-introducing $x$ as a variable in the context, and then finally replacing
  every free occurrence of $y$ with $x$ is the same as doing nothing. More
  concisely at the expense of precision, renaming a free variable in a term and
  then un-renaming it results in the same term.
\end{definition}

This category, as with most in category theory, serves to allow us to define a
special class of functor. In our case, that class of functor captures what it
means to produce a model of an elementary sketch. The proof of this theorem is
rather bureaucratic, but its importance is that it teaches us that the canonical
elementary language of a category is purpose-built so that its models are
precisely set-valued functors out of the category in question.

% TODO: must include Theorem 4.2.12 from Taylor, it is essential to the
% statement of this theorem.
\subsection{Models are essentially set-valued functors on the category of a sketch}
\newcommand{\clone}[3]{{\text{Cn}_{#1} (#2,#3)}}
\newcommand{\cn}{\mathrm{Cn}}
\begin{theorem}[The classifying category]\label{thm:classify_elem_sketch}
  Let $\mathcal{L}$ be an elementary sketch and \( \cn_{\mathcal{L}} \) the
  category it presents. Then the models of $\mathcal{L}$ correspond to functors
  $\cn_{\mathcal{L}} \rightarrow \mathfrak{Set}$.
\end{theorem}
\begin{proof}
  \( (\Rightarrow) \) Suppose we have an \( \mathcal{L}\)-model $A$. Then $A$ is an
  assignment of a set $\ceil{X}_{A}$ to each sort \( \ceil{X}\) and an
  assignment of a function \( \ceil{r}_{A} : X_{A} \rightarrow Y_{A}\) to each operation-symbol
  \( X \vdash \ceil{r}(x) : Y\) such that the laws (given by
  Theorem~\ref{thm:category_of_sketch}) of \( \mathcal{L} \) are preserved. These
  assignment form precisely the data of a functor

  \begin{align*}
   F_{A} &: \cn_{\mathcal{L}} \rightarrow \mathfrak{Set} \\
    X &\mapsto \ceil{X}_{A} \\
    (X \xrightarrow{r} Y) &\mapsto \ceil{r}_{A}
  \end{align*}.

  It remains to show functoriality of these assignments which follow from the
  laws of the canonical elementary language and faithfulness of the model. \\

  \( (\Leftarrow) \) Suppose we have a functor
  $F_A : \cn_{\mathcal{L}} \rightarrow \mathfrak{Set}$. We will construct a model $A$ of
  $\mathcal{L}$ from $F_{A}$ as follows: Recall from
  Theorem~\ref{thm:category_of_sketch} % TODO: bad ref
  that the sorts \(\ceil{X} \) of the sketch $\mathcal{L}$ are precisely the
  objects $X$ of \( \cn_{ \mathcal{L}} \), and the operation symbols
  \( X \vdash \ceil{ f } : Y \) are the morphisms \( f \) of \( \cn_{\mathcal{L}}\). Now,
  \begin{enumerate}
    \item For each sort \(\ceil{X}\) we assign \( \ceil{X}_A = F_{A}(X)\).
    \item For each operation symbol \( \ceil{f} \) we assign \( \ceil{f}_{A} = F_{A}(f) \).
    \item Again by Theorem~\ref{thm:category_of_sketch}, the only laws of the
          sketch are that \(\ceil{\text{id}}(x) = x\) and
          \(\ceil{g}(\ceil{f}(x)) = \ceil{g \circ f}(x)\). According to the
          assignments in the previous two points, the first law says that
          \(F_{A}(\text{id}_{X}) = \text{id}_{\ceil{X}_{A}}\), and the second says that
          \( (F_{A} \ceil{g}) \circ (F_{A}(\ceil{f})) = F_{A} (g \circ f)\). Both are
          ensured by functoriality.
  \end{enumerate}
\end{proof}

% \subsection{Example morphisms in the syntactic category}
% A natural question for the operationally-minded reader to ask after having seen
% the definition of the syntactic category is: how does all this ornate structure
% encode terms in the calculus I'm interested in? Let us ask instead a more
% precise question: how do we represent by a substitution a term \(\Gamma \vdash t : T\)?
% For such a term, there is a canonical substitution (morphism of contexts)
% \( \Gamma \xrightarrow[]{[t/x]} \Gamma,x:X \) which ``picks'' that term in $T$. Here
% $[t/x]$ is an explicit encoding/formula for the substitution inserting $t$
% anywhere it sees $x$. The ordering of the codomain and domain here should be
% confusing, but the contravariant base change functor, which lifts this encoding
% to a real substitution \emph{operation} clarifies things; we have:
% \( [t/x]^{*} : \clone{}{\Gamma, x:X}{T} \longrightarrow \clone{}{\Gamma}{T} \). In words, the
% substitution operation takes a term of type $T$ under $\Gamma$ and an additional free
% variable $x:X$ and gives us a term of type $T$ under just $\Gamma$; we reduce our
% assumption set by filling in one of the assumptions with some concrete evidence,
% namely the (syntactic) term $t$. In the special case of a closed (syntactic)
% term $t$, we have \( [t/x]^{*} : \clone{}{x:X}{T} \longrightarrow \clone{}{\emptyset}{T}\).

\section{Algebraic theories and their algebras}
Having defined elementary sketches, which give us a way to define multi-sorted
theories, it's obvious to request the ability to define multi-input
operations\footnote{Here's a little known statistic: At least one in two readers
  of this draft will observe that the doctrine of algebraic theory can be
  rephrased in terms of operards: algebraic theories are operads for which the
  tensor product used in forming the operation domains happens to be the plain
  ol' Cartesian product~\cite{TODO: Nlab}}. Algebraic theories generalize the
doctrine of elementary sketches and allow us to do so. As we upgrade our
doctrine to allow products, many of the notions (\emph{terms, clones, syntactic
  category, etc.}) which we developed in the simplified world of elementary
sketches will come along for the ride.

\begin{definition}[Algebraic theory]\label{def:alg theory}
  A (finitary many-sorted) \textbf{algebraic theory} $\mathcal{L}$ has
  \begin{enumerate}
    \item a collection $\Sigma$ of base types or \textbf{sorts} $X$
    \item an inexhaustible collection of variables $x_{i}:X$ of each sort;
    \item a collection of \textbf{operation symbols},
          $X_{1},\dots , X_{k} \vdash r : Y$ each having an \textbf{arity}, namely a
          list of input sorts $X_{i}$, and an output sort $Y$; and
    \item a collection of \textbf{laws}, posed as equalities between different
          terms (in the sense defined before)
  \end{enumerate}
\end{definition}

The next major concept we will introduce generalizes to algebraic theories the
notion of \emph{action} or \emph{model} we saw previously for elementary
sketches. As expected, the definition will be essentially the same up to taking
some products. Before doing so, we will give an intervening example of an
algebraic theory.
\begin{example}[Algebraic theory of \emph{ring}]\label{ex:theory of ring}

  We sketch an algebraic theory encoding the familiar structure of a ring from
  abstract algebra. The presentation should look familiar (when squinting) to
  anyone with a background in abstract algebra, except that we force the
  existence of multiplicative and additive identities by requiring any model (to
  be defined!) of this theory to provide \emph{global elements}, namely
  operations out of a distinguished sort $\mathbbm{1}$.
  \begin{enumerate}
    \item Sorts: The sorts are \( \mathbbm{1}, S\). The variable collections for
          each sort are \( \set{\square} \cup \set{\square_{i}}_{i} \) and
          \( \set{s_{i}}_{i} \cup {x,y,z} \) respectively.

    \item Operations: \begin{align*}
                        \cdot &: S \times S \rightarrow S, \\
                        + &: S \times S \rightarrow S,\\
                        0 &: \mathbbm{1} \rightarrow S,\\
                        1 &: \mathbbm{1} \rightarrow S,\\
                        - &: S \rightarrow S
                      \end{align*}

    \item Laws: \begin{align*}
                  +(x,y) &= +(y,x)\\
                  +(0(\square), x) &= x\\
                  +(x, -(x)) &= 0(\square)\\
                  \cdot(x,y) &= \cdot(y,x)\\
                  \cdot(1(\square), x) &= x\\
                  \cdot(x, +(y,z)) &= +(\cdot(x,y), \cdot(x,z))
                \end{align*}
  \end{enumerate}
\end{example}

Having given the obligatory concrete example, we now have permission to proceed
with another abstract definition: that of an \emph{$\mathcal{L}$-algebra} for an
algebraic theory:

\begin{definition}[$\mathcal{L}$-algebra]\label{def:algebra}
  Given an algebraic theory $\mathcal{L}$ and a category $C$ with finite
  products (in the sense of the universal property as treated in the chapter on
  basic category theory) an \emph{$\mathcal{L}$-algebra in $C$} is comprised of
  \begin{enumerate}
    \item an object $A_{X}$ of $C$ for each sort $X$ of $\mathcal{L}$, and
    \item for each operation symbol $X_{1}, \dots , X_{k} \vdash r : Y$, an
          assignment of a map \(r_{A} : A_{X_{1}} \times \cdots \times A_{X_{k}} \rightarrow A_{Y}\) in
          $C$.
  \end{enumerate}
  such that the assignments respect the laws of $\mathcal{L}$.
\end{definition}

We are now in good shape to give an example of an algebra (in the category of
sets) for the theory of a ring given in Example~\ref{ex:theory of ring}.
\begin{example}\label{ex:integer ring}
  % TODO: maybe need to explicate the product structure here, though I think we
  % really should get that for free with an algebraic theory.
  \begin{enumerate}
    \item For the sorts, we set $A_{S} = \mathbb{Z}$ and $A_{\mathbbm{1}} = \{\star\}$
    \item For the operations, we set
    \begin{enumerate}
      \item $\cdot_A = *$ where $*$ is the ordinary multiplication of integers
      \item $+_{A} = +$ where the second plus is ordinary addition of integers
      \item $0_{A}$ to the constant function $x \mapsto 0 \in \mathbb{Z}$
      \item $1_{A}$ to the constant function $x \mapsto 1 \in \mathbb{Z}$
      \item $-_{A}$ to the function $x \mapsto -x$ taking an integer to its additive inverse
    \end{enumerate}
    \item We wouldn't dare bore the reader by verifying all the laws, so we
          demonstrate just one. We show that the $0$ selected by the model
          indeed serves as the left identity of addition in the model.
          \begin{proof}
            \begin{align*}
              +_{A} \circ \braket{0_{A}, \id} &= (x : \{ \star \}, y : \mathbb{Z}) \mapsto 0_{A}(x) + \id(y)\\
                                          &= (x : \{ \star \}, y : \mathbb{Z}) \mapsto 0_{\mathbb{Z}} + y \\
                                          &= (x : \{ \star \}, y : \mathbb{Z}) \mapsto y\\
                                          &= \id_{\mathbbm{1}_{Z} \times S_{A}} \\
            \end{align*}

            Our proof is almost done, but we must justify that the final
            identity morphism is actually the interpretation of the variable
            (regarded as a term) $x$. This fact will be validated by results
            later in this section. In particular, Definition~\ref{def:term
              model} will give a proper treatment to the interpretation of terms
            in an algebraic theory and allow us to justify the equivalence of
            the terms $x$ and $\hat{\square}^{*} x$ by\footnote{recall from
              Definition~\ref{def:syn cat} that $\square$ is the variable we settled
              on for the sort $\mathbbm{1}$ and substitution by the hat is
              context weakening or adding the variable} way of our construction
            of the syntactic category. With the clearing of that remaining
            goal-post deferred, we have shown what is required for this law.
          \end{proof}
  \end{enumerate}
\end{example}

The reader familiar with algebra will observe that this example (at least when
fully worked out by a less lazy typist) amounts to verifying that the integers
form a ring under the standard multiplication and addition operations we learn
in elementary school. A natural next question to ask is how we might encode a
ring homomorphism in this framework. To answer this question, we (of course)
define a more general notion:

\begin{definition}[$\mathcal{L}$-algebra homomorphism]\label{def:homomorphism}
  A \emph{homomorphism} \( A \rightarrow B\) of $\mathcal{L}$-algebras $A$ and $B$ in some
  category $\mathfrak{C}$ with finite-products is an assignment to each sort $X$
  of a $\mathfrak{C}$-morphism \( \phi_{X} : A_{X} \rightarrow B_{X}\) between the
  corresponding objects in each algebra such that diagrams of the following form
  commute:

  \[\begin{tikzcd}
      {A_{X_1}\times\cdots \times A_{X_k}} &&& {A_{X_0}} \\
      \\
      {B_{X_1}\times\cdots\times B_{X_k}} &&& {B_{X_0}}
      \arrow["{r_A}", from=1-1, to=1-4]
      \arrow["{r_B}", from=3-1, to=3-4]
      \arrow["{\phi_{X_0}}"', from=1-1, to=3-1]
      \arrow["{\phi_{X_1}\times \cdots \times \phi_{X_k}}", from=1-4, to=3-4]
    \end{tikzcd}\]

\end{definition}

\begin{remark}\label{rmk:alg_func}
  (The following is an observation due to Lawvere in a paper written in his time
  teaching at Reed College~\cite{lawvere_functorial_1963}.) The familiarity of
  this diagram is no mistake: indeed, by analogy to
  Theorem~\ref{thm:classify_elem_sketch}, we may understand algebras as
  product-preserving functors. A mapping between algebras then is a natural
  transformation, hence the naturality diagram in
  Definition~\ref{def:homomorphism}. We will later make this analogy more
  concrete in Theorem~\ref{thm:classifying alg theory}.
\end{remark}

\begin{remark}
  Predictably, the $\mathfrak{C}$-valued algebras and homomorphisms of an
  algebraic theory $\mathcal{L}$ form a category, called
  $\mathscr{Mod}_{\mathfrak{C}}(\mathcal{L})$.
  \begin{proof}
    Per Remark~\ref{rmk:alg_func}, we consider algebras and their homomorphisms
    as functors and natural transformations respectively. The identity morphisms
    are the identity natural transformations whose component morphisms are the
    identities of $\mathfrak{C}$. Composition of natural transformations is
    given by composition of their component morphisms, hence we may out-source
    the associativity condition to that guaranteed by the categorical structure
    of $\mathfrak{C}$.
  \end{proof}

\end{remark}

Most questions in type theory are concerned with the \emph{terms} of the theory
at hand. Normalization theorems talk about the accessibility (under some
reduction relation) of a certain class of terms from any arbitrary term.
Canonicity, a stronger property implying normalization, talks about the
accessibility of another more strict class of terms from arbitrary start terms.
These are but two examples of a broad spectrum of properties one might desire of
the terms of a theory. Considering the primacy of term properties in type
theory, it is rather strange that the notion of semantics we have built so far
makes no commentary on terms besides the action on the clones given in
Theorem~\ref{thm:clone model}. Our models so far have only given meaning to the
individual \emph{sorts} (types) and individual \emph{operation symbols}
(constructors) of the theory considered. In fact, this is enough: our models
extend canonically to contexts and substitutions and thus give meaning to terms.

\DeclarePairedDelimiter{\sem}{\llbracket}{\rrbracket}

\begin{definition}[Extending a model to terms]\label{def:term model}
  Let $A$ be an $\mathcal{L}$-algebra in a category $\mathfrak{C}$. This algebra
  extends canonically to an interpretation $\sem{-}$ of contexts by the
  following definition recursive in the structure of contexts:
  \begin{align}
    \label{eq:contexts interp}
    \sem{\varnothing} &= \mathbbm{1}_{C} \\
    \sem{\Gamma, x : X} &= \sem{\Gamma} \times A_{X}
  \end{align}
  The (overly) careful reader will complain that $\mathfrak{C}$ doesn't
  necessarily feature a terminal object, but it turns out that a terminal object
  is guaranteed\footnote{as the nullary finite product} by the finite product
  closure we imposed on $\mathfrak{C}$ in our definition of algebras. We are
  good to go.

  Recalling more from the definition of an algebra, we know that $A$ gives
  meaning to each operation symbol \( Y_{1},\dots , Y_{k} \vdash r : Z \) as a
  morphism \( r_{A} : A_{Y_{1}} \times \cdots \times A_{Y_{k}} \rightarrow A_{Z} \) and gives meaning to
  each constant \( c : Z \) by a morphism \( 1_{\mathfrak{C}} \rightarrow A_{Z} \). We can
  extend this uniquely to arbitrary terms in the context
  \( \Gamma \equiv \sem{x_{1} : X_{1}, \dots , x_{n} : X_{n}} \) by the following
  recursive definition:
  \begin{align}
    \label{eq:term interp}
    \sem{x_{i}} &: \sem{\Gamma} \equiv A_{X_{1}} \times \cdots \times A_{X_{n}} \xrightarrow{\pi_{i}} A_{X_{i}} \\
    \sem{c} &: \sem{\Gamma} \xrightarrow{<_{!}} \mathbbm{1}_{C} \xrightarrow{c_{A}} A_{Z} \\
    \sem{r(u_{1}, \dots , u_{k})} &: \sem{\Gamma} \xrightarrow{\braket{\sem{u_{1}}, \dots, \sem{u_{k}}}} A_{Y_{1}} \times \cdots \times A_{Y_{k}} \xrightarrow{r_{A}} A_{Z}
  \end{align}
  where the $\sem{u_{i}}$ are the interpretations of the sub-expressions of the
  expression in the final line, $\pi_{i}$ is the $i$th projection guaranteed to us
  by the universal property of products, and $<_{!}$ is the unique map into the
  terminal object. The angle bracket notion is used to express the product
  functor's action on morphisms in $\mathfrak{C}$. For clarity, we write out
  explicitly the composites for the reader:
  \begin{align*}
    \sem{x_{i}} &\equiv \pi_{i} \\
    \sem{c} &\equiv c_{A } \circ <_{!} \\
    \sem{r(u_{1}, \dots , u_{k})} &\equiv r_{A} \circ \braket{\sem{u_{1}}, \dots,\sem{u_{k}}}
  \end{align*}
\end{definition}

\begin{theorem}[The classifying category of an algebraic
  theory]\label{thm:classifying alg theory} Let \( \mathcal{L} \) be an
  algebraic theory. Then \begin{enumerate}
    \item $\cn_{\mathcal{L}}^{\times}$ has finite products and an $\mathcal{L}$-algebra.
    \item Let $\mathfrak{C}$ be another category with a choice of finite
    products and an $\mathcal{L}$-algebra. Then the functor $\sem{-} :
    \cn_{\mathcal{L}}^{\times} \rightarrow \mathfrak{C}$ preserves finite
    products and the $\mathcal{L}$-algebra, and is the unique such functor.
    \item Any functor \( \cn_{\mathcal{L}}^{\times} \rightarrow C \) which
    preserves finite products also preserves the $mathcal{L}$-algebra.
  \end{enumerate}
\end{theorem}
\newcommand{\ob}{\mathrm{ob}\,}
\begin{proof}\,\\
  \begin{enumerate}
    \item We first show that the syntactic category has finite products. Recall
    that the objects of the syntactic category are variable contexts \([x : X, y
    : Y, z : Z, \dots]\). For any other context \( [t : T, u : U, v : V, \dots]
    \) we have the product \[ [x : X, y : Y, z : Z, \dots] \times [t : T, u : U,
    v : V] = [x : X, y : Y, z : Z, \dots, t : T, u : U, v : V, \dots]\] That
    is, products are given by concatenation of contexts. Now the model is given
    as follows:
    \begin{enumerate}
      \item The sorts $X$ of $\mathcal{L}$ are interpreted as single variable
      contexts $[x:X] \in \ob C$ where the variable $x$ is arbitrary.
      \item The operation symbols \( X_1, X_2, \dots \vdash r : Y \) of
      $\mathcal{L}$ are interpreted as substitutions \( [r(x_1, x_2, \dots)/y] :
      [x_1:X_1, x_2:X_2,\dots] \rightarrow [y : Y]\) 
    \end{enumerate}
    \item The functor promised is precisely the one defined by
          Definition~\ref{def:term model}. TODO: we still need to verify the
          uniqueness of this functor, which Taylor himself never demonstrates.
          \item This result demands a full proof, which isn't given in Taylor.
          \begin{proof}
            Suppose we have a functor $F : \cn_{\mathcal{L}}^{\times} \rightarrow \mathfrak{C}$
            which preserves products. We will show that it preserves the
            $\mathcal{L}$-model, in particular, that it takes the interpretation
            in $\cn_{\mathcal{L}}^{\times}$ of any context $\Gamma$ to the interpretation
            of $\Gamma$ in $\mathfrak{C}$. TODO.

            \textbf{Note}: Taylor claims the proof of this is given
            in~\cite{lawvere_functorial_1963}, but I am (so far, I haven't tried
            too long) unable to identify the result in that paper, probably
            because Lawvere's formulation of algebraic theories is very
            different from Taylor's. I plan to tie up this loose end sometime
            soon.
          \end{proof}
  \end{enumerate}
\end{proof}
\chapter{Functorial semantics of the simply typed lambda calculus in cartesian closed categories}
\epigraph{``Eeny, meeny, miny, moe''}{Alonzo Church (Allegedly, on his choice of
  $\lambda$ as the name for his calculus.)}

This chapter exploits the heavy machinery developed in the previous chapter to
give meaning, in specially structured categories, to the types and terms of the
simply typed lambda calculus. In particular, we will present the lambda calculus
as an \emph{algebraic theory} and leverage our existing theory to give an
interpretation of lambda terms in any \emph{cartesian closed} category with an
interpretation of the base types. We will begin by presenting the term language
and type system for the calculus under consideration.

\section{The simply typed lambda calculus}
We'll work with the simply typed lambda calculus with a boolean base type. We
will not dwell on the details of standard aspects of this development and refer
the reader to the standard references (\cite{pierce_types_2002},
\cite{harper_practical_2016}) for the full story.

\newcommand{\termob}{\mathbbm{1}}
\newcommand{\bool}{\mathbb{B}}


\begin{definition}[Types]\label{def:stlc_types}
  The types \( \widetilde{T} \) of the simply typed lambda calculus are
  generated by the following grammar:
  \[
    \tau \Coloneqq \termob \mid \tau_{1} \rightarrow \tau_{2} \mid \tau_{1} * \tau_{2}
  \]
\end{definition}

\newcommand{\abstr}[3]{\lambda #1 : #2.\, #3}

\begin{definition}[Terms]
  The terms of the simply typed lambda calculus (with booleans) are generated by the
  following grammar:
  \[
    t \Coloneq x \mid () \mid \pi_{1} t \mid \pi_{2} t \mid (t_{1}, t_{2}) \mid t_{1} t_{2} \mid \abstr{x}{\tau}{t}
  \]
  where the variables $x$ are drawn from a countably infinite set \( V \).
\end{definition}

\begin{definition}[Typing rules]
  Here they are.

  \begin{mathpar}
    \inferrule[]{ \Gamma \vdash t : \tau_1 * \tau_2 }{ \Gamma \vdash \pi_{i} t: \tau_{i} } \and \inferrule{ \Gamma \vdash t_{i} : \tau_{i} }{(\tau_1,\tau_{2}) : \tau_{1} * \tau_{2}}\\
    \inferrule{ \Gamma \vdash t_{1} : \tau' \rightarrow \tau  \\  \Gamma \vdash t_{2} : \tau' }{ \Gamma \vdash t_{1} t_{2} : \tau } \and \inferrule{ \Gamma,x:\tau' \vdash t : \tau}{ \Gamma \vdash \abstr{x}{\tau'}{t} : \tau' \rightarrow \tau}\\
    \inferrule*[Right={ (x:\tau) \in \Gamma }]{ }{ \Gamma \vdash x : \tau }\\
    \inferrule{ }{ \Gamma \vdash () : \termob }
  \end{mathpar}
\end{definition}

\section{Lambda theories, beta-eta rules, and cartesian closed categories}
\newcommand{\evsig}[2]{\textrm{ev}_{#1,#2} : #2^{#1} \times #1 \rightarrow #2}
\newcommand{\ev}[2]{\textrm{ev}_{#1,#2}}

Most sources define this notion only by \emph{context clues}, which is a
technical term meaning that they don't define it at all. We give an explicit
characterization of \emph{lambda theories} for the reader who like the author is
a 5head.

\newcommand{\cnprod}{\cn_{\mathcal{L}}^{\times}}
\begin{definition}[Raw cartesian closed structure]
  % TODO: is this actually a lambda-theory? Should I instead call it a theory
  % with raw cartesian-closed sturcture? Perhaps instead it is better to follow
  % Taylor and begin with the category of the algebraic theory, and then
  % characterize raw CC structure with reference to the category...
  Let \( \mathfrak{C} \) be a category with a specified terminal object
  \( \termob \) and specific products together product projections. We say that
  \( \mathfrak{C} \) is \emph{raw cartesian closed} or \emph{has raw cartesian
    closed structure} if we have the following for each pair of objects
  \( X, Y \) of \( \mathfrak{C} \):
  \begin{enumerate}
    \item An object \( Y^{X} \)
    \item An morphism, \emph{application}, \( \evsig{X}{Y} \) and
    \item For each object \( \Gamma \), a function of hom-sets
          \( \lambda_{\Gamma, X, Y} : \mathfrak{C}(\Gamma \times X, Y) \rightarrow \mathfrak{C}(\Gamma, Y^{X})\) obeying
          the naturality law:
          \[
            \lambda_{\Gamma, X, Y} ( \mathfrak{p} \circ (\mathfrak{u} \times \id_{X})) = \lambda_{\Gamma, X, Y}(\mathfrak{p}) \circ \mathfrak{u}
          \]
          for each \( \mathfrak{u} : \Gamma \rightarrow \Delta \) and
          \( \mathfrak{p} : \Delta \times X \rightarrow Y \).
  \end{enumerate}
\end{definition}

\begin{definition}[Lambda theory]
  An algebraic theory $\mathcal{L}$ is a \emph{lambda theory} if its classifying
  category \( \cnprod \) has raw cartesian closed structure.
\end{definition}

\begin{definition}[Beta-eta rules]
  A lambda-theory $\mathcal{L}$ satisfies the \emph{$\beta-\eta$ rules} if for all
  \( \mathfrak{p} \in \cn_{\mathcal{L}}(\Gamma \times X,Y) \) we have
  \begin{align*}
    \ev{X}{Y} \circ (\lambda_{\Gamma,X,Y}(\mathfrak{p}) \times \id_{X}) &= \mathfrak{p} && (\beta) \\
    \lambda_{Y^{X},X,Y}(\ev{X}{Y}) &= \id_{Y^{X}} && (\eta)\\
  \end{align*}
\end{definition}

These deserve some commentary. The beta rule says that application of an
abstracted body $\mathfrak{p}$ to the identity gives you back the body you
started with: the beta rule forces that application of lambda expressions does
nothing more than substitute for the abstracted variable. TODO: explain eta.

We now define a notion more well-known outside of computer science. Cartesian
closed structure endows a category with the ability to take products and
function spaces over its objects in a suitable fashion.
\begin{definition}[Cartesian closed structure]
  A category \( \mathfrak{C} \) is \emph{cartesian closed} if it has all
  products and exponentials.
\end{definition}

The category \( \catset \) is the prototypical cartesian closed category whose
products are the usual cartesian products of sets and whose exponentials are
function spaces: for sets $X$ and $Y$, \( Y^{X} = \{ \textrm{functions
} f \mid \dom(f) = X \wedge \cod(f) = Y \}\). Another good source of example cartesian
closed categories is topos theory. All elementary toposes, including categories
of presheaves, are cartesian closed (\cite{leinster_informal_2011}.) It turns
out that all of these examples of cartesian closed categories can also be
characterized as the classifying categories of

\begin{theorem}[Finite-product category + raw CCS + beta-eta $\iff$ cartesian closed]
  Let \( \mathfrak{C} \) be a category. Then \( \mathfrak{C}\) is cartesian
  closed if and only if \( \mathfrak{C} \) has finite products, a specified
  terminal object, and both is raw cartesian closed and satisfies the beta-eta
  laws.
\end{theorem}

We will now present the lambda calculus as an algebraic theory.

\begin{definition}[Algebraic theory of the lambda calculus]
  The lambda calculus can be encoded as an algebraic theory with the following
  data:
  \begin{enumerate}
    \item Sorts: We define the sorts \( \Sigma_{\lambda}\) to be the set
    \( \widetilde{T} \) given in Definition \ref{def:stlc_types}.
    \item Variables: The variables are drawn from some countably infinite set
          $V$ as in the definition of terms.
     \item The operation symbols are the following:
          \[
            t : \tau_{1} * \tau_{2} \vdash \pi_{1}(t) : \tau_{1} \\
            t : \tau_{1} * \tau_{2} \vdash \pi_{2}(t) : \tau_{2} \\
            [t_{1} : \tau_{1}, \t_{2} : \tau_{2}] \vdash (t_{1},t_{2}) : \tau_{1} * \tau_{2} \\
            \\
            [t : \tau' \rightarrow \tau , \t' : \tau'] \vdash t t' : \tau \\\\
            \vdash () : \termob
          \]
    \item The equations are those of the usual equational theory for the lambda
          calculus. Let \( \Gamma, x : \tau' \vdash t : \tau \) be a lambda term
    \begin{align*}

    \end{align*}

    \end{align*}
  \end{enumerate}
\end{definition}

\begin{theorem}[Lambda calculus is a lambda theory with beta-eta]
\end{theorem}

\chapter{Normalization by evaluation: the classical perspective}
In this chapter, we outline the technique of \emph{normalization by evaluation}
which exploits an existing programming language evaluator to produce a
normalization function for the \emph{open terms} of some other language. Our
intent is merely to communicate the ideas involved with a view to drawing
analogies to normalization by evaluation in our later discussion of gluing. In
light of this, we describe the technique in full detail but omit all proofs of
correctness (in the literature called ``soundness'') % TODO: explain what
                                                     % soundness is here;
                                                     % mention other nbe
                                                     % desiderata?
The chapter will follow our OCaml implementation of normalization by evaluation
for G\"odel's System T. Our implementation was inspired by the habilitation of
Andreas Abel and the Wikipedia page on normalization by evaluation written by a
number of authors.

\chapter{Normalization by gluing}
\epigraph{``i really thought u meant arts and crafts glue''}{new gluing understander}
\newcommand{\red}{\rightarrow^{*}} % TODO: move me

This chapter is the culmination of all that we've developed so far in the
thesis. We will consider the normalization problem for the simply typed lambda
calculus. Normalization comes in both weak and strong flavors, but both are
properties of a formal system together with a \emph{reduction} relation, say,
\( - \rightarrow = \). Now by a \emph{normal form} we mean term $t$ for which there is no
other $t'$ such that \( t \rightarrow t' \). Writing \( - \rightarrow^{*} = \) for the least
transitive, reflexive closure of this relation, to say that the reduction system
enjoys \emph{weak normalization} means that for any well-typed term \( e \),
there exists a normal form \( n \) such that \( e \red n\). A reduction system
enjoying \emph{Strong normalization} is one for which \emph{every} reduction
sequence ends in a normal term; equivalently, \emph{strong normalization}
requires that there are no infinite reduction sequences over distinct terms.
\emph{Metatheorems} of this kind tend to resist standard techniques like
straight-forward induction over the types of the lambda calculus. Instead,
metatheoreticians resort to the \emph{occult} technique of logical relations.
(cite TAPL). The method of logical relations is, broadly speaking, somewhat
opaque even to experienced practitioners. The construction is simple to write
down and use in easy settings like that of the simply-typed lambda calculus, but
becomes devilishly complicated when working with more complex lambda calculi.

The method of \emph{Artin gluing}, torn from the topos theorist's cookbook, is
deeply related to the method of \emph{logical relations} well-known to
programming language metatheoreticians. Where the method of logical relations is
ad-hoc and mysterious, however, gluign regularizes some the thinking involved
and makes most of the choices involved in proofs by logical relations completely
automatic. The \emph{scone} or \emph{Sierpinski cone} is a famous instance of
the gluing construction used in and outside of type theory. The \emph{scone} is
not suited to our particular problem of \emph{(open) normalization} however, as
the scone is generally concerned with properties of \emph{closed terms} with no
free variables, whereas our construction will apply to terms in any context.

\section{Variable-arity Kripke relations}

\section{The comma construction and friends}

\subsection{An easy example: the category of renamings}
The category of renamings is, in a very loose sense, like a less proof relevant
version of the category of contexts and substitutions. In particular, if there
exists a substitution relating two contexts in syntactic category, then there
exists a renaming relating the same contexts. In this sense, renamings allow us
to track changes in context due to substitution without actually using
substitutions which are problematic due to their being overly quotiented by
definitional equality thanks to the substitution lemma. The category of
renamings allows us to define the presheaves we need while not losing track of
how contexts evolve by substitution. I think that these two points are precisely
the desiderata satisfied by the category of renamings.

\begin{remark}
  There is an obvious inclusion \( \iota : \ren \rightarrow \cl \) which takes contexts to
  contexts and casts renamings as change-of-variable substitutions. When going
  between \( \ren \) and \( \cl \), we will take liberty to implicitly insert
  this coercion as needed without warning.
\end{remark}

Need to present its
\begin{enumerate}
  \item Definition as a comma: a context is a finite set of variables paired
        with an assignment of types to each variable; renamings are those
        functions of the underlying variable sets which preserve the extra
        globbed on typing information
  \item Straightforward definition
\end{enumerate}

\subsubsection{Kripke relations indexed by renaming contexts}
Should just provide the instance we'll be working with here to lower the
reader's cognitive burden of too much generality.

\subsection{Presheaves of syntax, defined over the category of renamings}
% open terms, neutrals, normals

\subsubsection{A lambda-algebra in Ren-hat}

\subsection{Why the syntactic category just won't do}
talk about why neutrals and normals can't support a substitution action
% should also talk briefly about why we can't define such presheaves over the
% syntactic category at this point.
\begin{remark}[Any category of presheaves are cartesian closed]
  This is a well-known fact. Maybe I can bloviate on this a smidge. I think it goes well in this subsection.
\end{remark}

\subsection{A harder example: the gluing category; or, the category of proof-relevant Ren-Kripke relations over types}
This subsection introduces Fiore's monster.
\subsubsection{The relative hom functor}
\subsubsection{Gluing semantics to syntax along the relative hom functor}
\subsection{The subcategory of (ordinary) variable-arity Kripke relations}


We can recover ordinary, proof-\emph{irrelevant} variable-arity Kripke relations
as a subcategory of the gluing category. In particular, ordinary variable-arity
Kripke relations arise as those objects
\( (D : \renhat, q : D \Longrightarrow \tm (\Delta), \Delta : \cl) \) of the gluing category whose
quotient map $q$ is a component-wise monomorphism; i.e., for each
\( \Gamma \in \ren \), we have that \( q_{\Gamma} : D(\Gamma) \rightarrowtail \tm (\Delta)(\Gamma) \) is a monomorphism.
Here's why. Recalling the definition of $\ren$-Kripke relations over $\tau \in \cl$,
we need to find in these data a $\ren$-indexed family \( \{ R_{\Gamma}\}_{\Gamma \in \ren}\)
of sets of $\cl$-morphisms into \( \tau \) subject to the following relative
monotonicity condition: for any renaming \( \rho : \Gamma' \rightarrow \Gamma \), if \( t : \Gamma \rightarrow \tau \) is
in \( R_{\Gamma}\), then we have that \( t \circ \rho : \Gamma' \rightarrow \tau \) is in \( R_{\Gamma'}\). Looking
again to our proposed Kripke predicate objects of the gluing category, we can
see that the presheaf \( R \) together with the natural mono \( q \) define for
each \( \Gamma \) a subset\footnote{this result is elementary for $\catset$, but also
  holds for any \emph{topos} modulo its notion of subobjects
  (\cite{leinster_informal_2011})} of the substitutions \( \Gamma \rightarrow \tau \). It is, of
course, tempting to dismiss the naturality of $q$ as wonky bureaucracy; but
naturality turns out to be essential to recovering the relative monotonicity
condition. To see why this recovers what we had before, let us look at the
naturality diagram of \( q \):

  \[\begin{tikzcd}
      {R (\Gamma)} &&& {\tm(\Delta) (\Gamma)} & t \\
      \\
      {R (\Gamma')} &&& {\tm(\Delta) (\Gamma')} & {t \circ \rho}
      \arrow["{q_{\Gamma}}", from=1-1, to=1-4, rightarrowtail]
      \arrow["{q_{\Gamma'}}", from=3-1, to=3-4, rightarrowtail]
      \arrow["{R (\rho)}"', from=1-1, to=3-1]
      \arrow["{\tm(\Delta) (\rho)}", from=1-4, to=3-4]
      \arrow[from=1-5, to=3-5, mapsto]
    \end{tikzcd}\]

  As mentioned before, because they are monos we may identify the component
  morphisms with their images. We write \( |q_{\Gamma}| \subseteq \tm(\Delta)(\Gamma) \) for the image,
  for each \( \Gamma \). Now what this diagram says is that for any
  \( q_{\Gamma }(r \in R(\Gamma)) = t \in |q_{\Gamma}|\), we have that
  \( t \circ \rho = q_{\Gamma'}(R(\rho)(r)) \in |q_{\Gamma'}|\). This is precisely the relative
  monotonicity condition for $\mathfrak{C}$-Kripke relations: containment in
  each predicate is functorial with respect to renaming \emph{up to renaming}.
  This perspective allows for a more conceptual understanding of the objects in
  the gluing category: the presheaves $R$ define context-indexed families of
  \emph{witnesses} to the inclusion of terms in the predicate, and $q$ is a
  quotient map that forgets the difference between distinct witnesses
  \( w, w' \in R(\Gamma) \) and whose image just records those terms
  \( t \in \tm (\Delta)(\Gamma)\) taken to be in the predicate.

\section{Obtaining a normalization function}
\subsection{A lambda-algebra for the gluing category}
\subsection{Cartesian closed structure for the gluing category}
% TODO: flesh this out some more
\subsection{A promise kept: normalization}

\chapter{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
\chaptermark{Conclusion}
\markboth{Conclusion}{Conclusion}
\setcounter{chapter}{4}
\setcounter{section}{0}

That's it for now.

% If you feel it necessary to include an appendix, it goes here.
\appendix
\chapter{The First Appendix}
\chapter{The Second Appendix, for Fun}


% This is where endnotes are supposed to go, if you have them.
% I have no idea how endnotes work with LaTeX.

\backmatter% backmatter makes the index and bibliography appear properly in the t.o.c...

% if you're using bibtex, the next line forces every entry in the bibtex file to be included
% in your bibliography, regardless of whether or not you've cited it in the thesis.
\nocite{*}

% Rename my bibliography to be called "Works Cited" and not "References" or ``Bibliography''
% \renewcommand{\bibname}{Works Cited}

% \bibliographystyle{bsts/mla-good} % there are a variety of styles available;
% \bibliographystyle{plainnat}
% replace ``plainnat'' with the style of choice. You can refer to files in the bsts or APA 
% subfolder, e.g.
\printbibliography[heading=bibintoc]
% \bibliographystyle{APA/apa-good}  % or
% \bibliography{thesis}
% Comment the above two lines and uncomment the next line to use biblatex-chicago.
% \printbibliography[heading=bibintoc]

% Finally, an index would go here... but it is also optional.
\end{document}
