\documentclass[12pt,twoside]{reedthesis}

\usepackage{graphicx,latexsym}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage[hyphens]{url}
\usepackage{rotating}
\usepackage{outlines}
\usepackage{enumitem} % custom labels

% font stuff
\usepackage{bbm, stmaryrd}
\usepackage{luatexja} % for memes

\usepackage{amsmath}
\usepackage{mathtools} % paired delimeters
\usepackage{braket}
\usepackage{epigraph} % funny quotes
\usepackage{tikz-cd} % diagrams
\usepackage{circuitikz} % circuit diagrams
\usepackage{emoji}
\usepackage{quiver} % fancy arrows

\usepackage{mathpartir} % inference rules

\usepackage[
backend=biber,
style=alphabetic,
citestyle=alphabetic
]{biblatex} % better citation style
\addbibresource{thesis.bib}

\usepackage{hyperref}

\hypersetup{
  colorlinks,
  allcolors=black,
  hidelinks,
}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{joke}[theorem]{Joke}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{Recall}[theorem]{recall}
\newtheorem{corollary}[theorem]{Corollary}

% \newcommand{\sslash}{\mathbin{/\mkern-6mu/}}
\newenvironment{sketch}{\textit{Sketch.}  }{\hfill$\sslash$}

\include{autodelims}
\include{reallywidetilde}
\include{macros}
\include{bsymbol}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}

% Comment out the natbib line above and uncomment the following two lines to use the new 
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the 
% bibliography is included. 
% \usepackage{biblatex-chicago}
% \bibliography{thesis}

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino

\title{The Way of Glue\\ A Head-First Dive into the Categorical Semantics of Lambda Calculi}
\author{Jay Kruer}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{December 2021}
\division{Mathematics and Natural Sciences}
\advisor{Ang\'elica Osorno}
\altadvisor{James (Jim) Fix}

\department{Mathematics}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
\thedivisionof{The Established Interdisciplinary Committee for Mathematics and Computer Science}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
% \approvedforthe{Committee}

\setlength{\parskip}{0pt}

\begin{document}
\maketitle
\frontmatter % this stuff will be roman-numbered
\pagestyle{empty} % this removes page numbers from the frontmatter

% Acknowledgements (Acceptable American spelling) are optional
% So are Acknowledgments (proper English spelling)
\chapter*{Acknowledgements}
% It's not often in life one gets a chance to thank the many people who have
% helped him on his way, so I've spent the last few months slowly accumulating a
% list of people I'd like to thank whether for their direct impact in making this
% thesis possible or just for having had an outsized impact on my life at one
% point or another. I can only start by thanking my advisors Ang\'elica and Jim
% for their part in making my thesis year one of my favorite's in my time at Reed
% and for making this thesis possible. I am first of all indebted to Ang\'elica's
% spooky ability to instantly grasp at understanding in an area relatively unknown
% to her. Without her hints at how to tackle an opaque construction every now and
% then, I think I'd probably be still fumbling around with the basics. Jim has had
% an outsized influence on the direction my intellectual life has taken. Jim's
% intro CS course taught partially in Standard ML was my first real exposure to
% mathematically structure programming and opened me up to a world that had until
% then had seemed inaccessible to me. Jim has also served as a great mentor in
% matters of personal taste and style (his course webpages are always out of this
% world cool.) I'll really miss our wacky math-cs crossover meetings, you two!

% The students and faculty in the Math department have the last few years a
% tremendously enriching experience. Albyn Jones and Irena Swanson, who taught my
% intro courses freshman year, are singled out for special thanks. I was not by
% any stretch a likely math major by the time I came to Reed. Having been brought
% from complete ignorance to a great appreciation for mathematics under Albyn and
% Irena's careful guidance was a great privilege and one I'll remember all my
% life! I am also grateful to Kyle Ormsby for always being an absolute chiller,
% encouraging me in early ambitions, and for giving me a taste of category theory
% before I fled from his topology class.

% Mom and Dad.

% Jaclyn, my love, thank you for being everything to me over the past (almost) two
% years and for your friendship for the last (almost) 4. You turned an ugly
% pandemic into a beautiful one, and I can't wait to spend the rest of it (and
% more!) with you.


% Thank you to Uncle Jay for your constant encouragement for my interests in
% computers. To Grandma, Aunt Susie, Aunt Julie, and all my extended family for
% your continued support!

% A few other teachers in my life also made a big impact on me. My first grade teacher Ms.\ King, 柳老師 (Hyong Rhew) for getting me to chill
% out a bit freshman year, Mrs.\ Leitsch for extensive encouragement in 9th grade
% English, Mr. Cool for encouragement on the robotics team (even if you couldn't
% get the team to switch from LabView), Mr.\ Raveli for reassuring me that it's
% okay to not know all the answers, Yuta, Shulav and Aditya for many fine hours of good
% lad time.

% Jake Buck

% Thanks to the hyperbolic crew: Francis Baer, Alec Forget, Usman Hafiz, Kiana
% McBride, and Luke Doms for helping to make Kyle's wild ride a dummy good time.

% Thanks to the many friendbobs of pika: Joebob, Jit, Eli, Gabe and Ciara, Becca,
% Andres, Nathan, Chloe. The time I spent with you all in Boston was and remains
% precious to me beyond measure!

% Thanks to Murali Vijayaraghavan for his mentorship and patient instruction while
% I was learning the ropes the ropes of CPU and hardware design.

% 吳老師, Ian Desai, Sara Rosenberger in the business office, the GNU project and
% free software foundation along with the developers of so many other free
% software projects whose generously donated works were instrumental in the
% production of this thesis.

% The following people made my freshman year at Reed. Thank you to Holden and Max
% for making WP117 home. Special thanks to Max for not holding against me my
% having thrown a mug at him. Thanks to Noah Koster for being one of my very first
% friends at Reed and for always truckin. You may not be the next Bill Gates, but
% you're a great guy. Thanks to Nick Chaiyachakorn for being the best boo. To
% Carter, Dan, Mary, and Salma for good times.

% The following people made my sophomore year much more tolerable. Thanks to Alice
% McKean for good times, and to Genya, Tristan, and the rest of the crew for so
% many great nights in Polytopia. Special thanks go to Young Kim for
% corrupting my soul. This thesis is in some sense a tribute to you, because I
% know how much you love category theory.

% Alice McKean

% My van

% Richard Fox at NKU

% Megan, Luke, Ryan, Kathleen

% Thanks to Curtis, Cody Roux and Dan McArdle at the Charles Stark Draper Laboratory for
% early encouragement!

% Thank you to the composers of Breath of the Wild and lofi girl for the
% soundtrack.

% Thank you to Steve Awodey for listening to me deliver a draft version of the
% argument laid out in Chapter 3 and for helpful comments. Thanks to Carlo
% Angiulini for helpfully answering my questions. Thank you to Ivan Di Liberti
% for many fun and useful mentorship Zoom meetings throughout the last few
% months!

% Finally, I would like to give special thanks to Paul Taylor who, though I do not
% know him personally, wrote the book that made this thesis possible. Paul's
% \emph{Practical Foundations of Mathematics} is one of the great books of
% computing, in the same league as Knuth's \emph{Art of Computer Programming} in
% that it is not just a useful centralization of human knowledge but that the
% presentation is painstakingly beautiful. On nearly all of the early days spent
% on this project I learned from Paul's book a profound perspective on programming
% or mathematics in general.

% I also owe massive debts to the great people of the \TeX StackExchange for \TeX
% macros used in the production of this document. Thank you to user4586 for their
% automatically-sized delimeters macro, to Steven B. Segletes for their really
% wide tildes macro, and to user13907 for their stylized B symbol. Thank you to
% the various people involved in the creation of the Lua \LaTeX system. And to the
% authors of the following packages:


% Thank you to Aaron Weiss for being a constant companion (even over discord),
% theory B homie, and an absolute pogchamp over the last 3 years of knowing you.
% Stay fresh, king.

% Many thanks to Jon Erickson, author of \emph{Hacking: The rt of Exploitation}
% for having gotten me started on this road so many years ago. What a strange
% route to gluing!

% The preface is optional
% To remove it, comment it out or delete it.
\chapter*{Preface}
\epigraph{And further, by these, my son, be admonished: of making many books
  there is no end; and much study is a weariness of the flesh.}{Ecclesiastes
  12:12, KJV.}

I don't know what to put here, but this is certainly a funny quote that should
find a home somewhere in the thesis.

\chapter*{Notation}
Following the great masters\footnote{\(\mathfrak{Kale\,\, Ormsby}\)}, the face
\( \mathfrak{Mathfrak} \) is used liberally and wherever possible without any
particular convention.


% \chapter*{List of Abbreviations}
% \begin{table}[h]
%   \centering % You could remove this to move table to the left
%   \begin{tabular}{ll}
%     \textbf{TMA}  	&  Too Many Abbreviations
%   \end{tabular}
% \end{table}


\tableofcontents
% if you want a list of tables, optional
\listoftables
% if you want a list of figures, also optional
% \listoffigures

% The abstract is not required if you're writing a creative thesis (but aren't they all?)
% If your abstract is longer than a page, there may be a formatting issue.
\chapter*{Abstract}
Normalization by gluing is based.

% \chapter*{Dedication}


\mainmatter% here the regular arabic numbering starts
\pagestyle{fancyplain} % turns page numbering back on

% The \introduction command is provided as a convenience.
% if you want special chapter formatting, you'll probably want to avoid using it altogether

\chapter*{Introduction}
\epigraph{You don't need a weatherman to know which way the wind blows.}{Bob Dylan}
\addcontentsline{toc}{chapter}{Introduction}
\chaptermark{Introduction}
\markboth{Introduction}{Introduction}
% The three lines above are to make sure that the headers are right, that the intro gets included in the table of contents, and that it doesn't get numbered 1 so that chapter one is 1.

% Double spacing: if you want to double space, or one and a half 
% space, uncomment one of the following lines. You can go back to 
% single spacing with the \singlespacing command.
% \onehalfspacing
% \doublespacing

Though we encounter many interesting objects and ideas along the way, this
thesis is primarily concerned with the \emph{open normalization} problem  for the simply typed lambda calculus. Some explaining is in order. First, we talk about the simply typed lambda calculus. The reader might be familiar with the \emph{untyped} lambda calculus. That mathematical object is the following system.

LAMBDA CALCULUS HERE

The Church-Turing thesis says that the lambda calculus and the Turing machine, a
more typical model of universal computation are equivalent: any Turing machine
can be simulated by the lambda calculus, and consequently any decidable problem
can be decided by the lambda calculus.

That the lambda calculus is so powerful is exciting, but some consider working
with that full power unwieldy. Indeed, there are programs that one can write
down in the lambda calculus which get ``stuck'' before computing a value,
meaning that there are lambda programs $p$ which reduce to a $p'$ which isn't a
value but cannot be reduced to some $p''$.

The usual solution to this problem is to tie our own hands a bit, but imposing a
regime of \emph{types}. The simplest example of such a regime is, appropriately,
\emph{simple types}. The simply-typed lambda calculus enriches the lambda
calculus with some base types, say booleans and natural numbers, and derived
types \( A \times B\) representing \emph{pairs of terms} of the types $A$ and $B$
along with \( A \Rightarrow B\) representing \emph{functions} taking an $A$ and giving a
$B$. For example, the type \( \mathbbm{B} \times \mathbbm{N}\) is inhabited by pairs
of a boolean and some natural number. Along with this type structure comes
\emph{rules} stipulating how it may be used. We will not explain this story in
depth in this thesis, but we will soon see these rules. The desired result
indeed follows from this setup: lambda terms that follow the typing rules do not
get stuck when evaluated. This is the famed \emph{type safety} property from
programming language theory. Another family of properties, namely
\emph{normalization} properties, follows from this type regime. It turns out
that any program in the lambda calculus will reduce to a value in a finite
number of evaluation steps. This property is called \emph{closed normalization}.
In the language of Turing machines, this means that programs written in the
simply typed lambda calculus always halt. In particular, the lambda calculus is
\emph{not} Turing complete and can only simulate deciding Turing machines. This
can be a problem for some applications. If you want, say, your web server to run
indefinitely without bound; the simply lambda calculus can't do that. You could,
however, make your program loop until the projected death of the sun and deploy
a new version of your server shortly thereafter. Beyond silly considerations
like this, the halting property of languages like the simply typed lambda
calculus is actually required for some applications.

An \emph{interactive theorem prover} is a computer program that allows a
computer user to state theorems and input proofs\footnote{individual systems
  vary in how manual this process is}, which are then checked by the program.
Many interactive proof systems, such as Coq or Agda, are based on
type\footnote{in the same sense as above, only with much more complicated type
  formers and rules} theory. Such proof systems leverage a principle called the
\emph{Curry-Howard isomorphism}, which allows one to represent theorems as
\emph{types} and proofs as \emph{programs}. The advanced type theories of such
systems allow one to state the sort of universally and existentially quantified
propositions one often encounters in mathematics. An \emph{absolutely critical}
property for systems like this is that the proof construction language (remember
that this is analogous to a programming language according to the Curry-Howard
isomorphism) be terminating for the following reason. Suppose you have stated a
proposition $P$. The Curry-Howard isomorphism allows us to represent $P$ by a
type $T_{P}$ such that constructing a term (a program potentially with
parameters) $t$ with type $T_{P}$ amounts to proving the proposition $P$. Given
any type, I can give you a non-terminating program of that type. This is easiest
to see by putting unguarded termination in the language as a form of
non-termination. The program simply calls itself recursively forever, infinitely
passing the buck but ostensibly having the desired type. Below we demonstrate
how this can be done by manually deactivating in the Coq proof assistant safety
features expressly intended to rule out such definitions.

\begin{verbatim}
j@computer ~ % coqtop
Welcome to Coq 8.14.0

Coq < Unset Guard Checking.

Coq < Fixpoint falso (u : unit) : False := falso tt.
falso is defined
falso is recursively defined (guarded on 1st argument)
\end{verbatim}

If we reset \emph{guard checking}, which places restrictions on the allowed
forms of recursive definitions so that they are \emph{well-founded}, we find
that Cod refuses this definition.

\begin{verbatim}
Coq < Set Guard Checking.

Coq < Fixpoint falso (u : unit) : False := falso tt.
Toplevel input, characters 0-46:
> Fixpoint falso (u : unit) : False := falso tt.
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error:
Recursive definition of falso is ill-formed.
In environment
falso : unit -> False
u : unit
Recursive call to falso has principal argument equal to
"tt" instead of a subterm of "u".
Recursive definition is: "fun _ : unit => falso tt".
\end{verbatim}

With this fact in mind, normalization proofs for the underlying proof language
are required of a trustworthy interactive theorem proving system, otherwise one
can easily prove false.

[TODO: Talk about how closed normalization is typically proved using ordinary logical predicates]

[TODO: Talk about open normalization somewhere nearby, and its importance in proof
assistants. Carefully express the difference between closed and open
normalization, why one would want such theorems. Open normalization is strictly stronger than closed normalization, but why is it useful? What's the difference between saying that all closed instances are normalizing vs. an open term itself is normalizing...]

[TODO: Our method + assumed background; mea culpa]

[TODO: method+: more constructive and more conceptual; the structure of our
constructions reflect the result we attempt to prove in a very clear way]

[TODO: method+: our method is constructive, which, together with the fact that
the result is open normlization means that we are giving a term reducer]




\chapter[Functorial semantics]{Functorial semantics: sketches and their models; algebraic theories and their algebras}\label{chapter:functorial_semantics}
In this chapter we will develop tools for reasoning about (syntactic)
\emph{theories}, which are ``notions of'' abstract structure. As an example,
this chapter will present a theory encoding the structure of a ring (as in
algebra.) A more complicated example will come in Chapter~\ref{chapter:stlc}
which will apply the ideas of this chapter to simple type theory. To discuss how
we write down our theories, we need another level of abstraction. We will work
with several \emph{notions of} (syntactic) theory. We will more laconically
refer to a notion of syntactic theory as a \emph{doctrine}. A \emph{doctrine} is
something like a framework specifying how we are to write down a theory. The
first doctrine we will consider is that of the \emph{elementary
  sketch}. % The reader familiar with and/or traumatized by
% experience with pencils of geodesics in hyperbolic geometry need not be scared
% away by this terminology; there is nothing non-Euclidean afoot here.
The doctrine of the \emph{elementary sketch} allows us to specify theories
involving \emph{unary} operations (those defined over a single parameter.) This
restriction on the arity of operations turns out to be quite limiting. To
address this, we will later upgrade the doctrine of elementary sketches to the
doctrine of \emph{algebraic theories} which allow encoding operations with any
finite number of parameters, thus covering a broad variety of gadgets one might
encounter in mathematics and computing. Algebraic theories are known more
famously as \emph{Lawvere theories} after categorical logic superstar (and
former Reed College professor!) William Lawvere who originally presented them
while building his functorial treatment of universal algebra. Emphasizing the
doctrinal upgrade, some authors refer to algebraic theories as \emph{finite
  product sketches} \cite{wells_sketches_2009} though we will tend to stick with
Lawvere's original terminology. As an example of the strength of algebraic
theories, we will show how to write down (as an algebraic theory) what it means
to be a ring, with no reference to sets or functions. In the following chapter,
we will use the doctrine of algebraic theories to develop categorical semantics
of the lambda calculus. This chapter is strictly expository in nature; indeed,
much of what follows draws heavily from Paul Taylor's \emph{Practical
  Foundations of Mathematics}~\cite{taylor_practical_1999}. My contribution is
to flesh out some of the examples found there, add some of my own, and make
other parts of the presentation more palatable and quickly digestible to the
reader already acquainted with basic category theory and type theory.

\section{An algebraic prelude}
We begin by recalling from algebra the notion of an \emph{action} of, say, a
group or a monoid. Actions are, from our perspective, a way of giving meaning,
or \emph{semantics} to elements of a set which enjoys some algebraic structure.
\begin{definition}\label{def:covariant action}
  Recall that a \textbf{covariant action} of a group or monoid \((M, id, \cdot)\) on
  a set \(A\) is a function \((-)_* (=) : M ‌\times A \rightarrow A\) such that
  \(\text{id}_* a = a\) and \( (g \circ f)_* a = g_* (f_* a) \). We can similarly a
  define the notion of a \textbf{contravariant action} which similarly requires
  the identity action to do nothing, but instead flips the order of action for
  compositions: $(g \circ f)^{*}a = f^{*}(g^{*} a)$
\end{definition}

For example, in algebra we learn that the dihedral group of size 8, written
$D_{4}$, acts on the square (with uniquely identified points) by reflections and
rotations\footnote{https://groupprops.subwiki.org/wiki/Dihedral\_group:D8}; each
of the operations encoded by the action results in the same image of the square
up to ignoring the unique identity of the points we started with. This action
gives geometric meaning to each of the group elements, and was used in the first
day of the author's algebra class to explain the algebraic mechanics of the
group itself; discovering which elements of the group are inverse to one another
is done by geometric experimentation using a square with uniquely colored
vertices. Similarly, the symmetric groups $S_{n}$ act on lists of length $n$ by
permutation of the list elements. In this case, the action can be even more
trivially defined. We now turn to the definition of an important property of
actions: \emph{faithfulness}.

\begin{definition}\label{def:faithful}
  A \textbf{faithful} action $(-)_{*}$ is one for which we have
  \[ \forall (a:A)\ldotp f_* a = g_* a \Longrightarrow f = g \] for all \( f, g \) in $M$. Morally,
  this requirement says that elements are \emph{semantically} equal (or, act the
  same) only when they are \emph{syntactically} equal (or, \emph{look}
  identical.)
\end{definition}

It can now be seen that the crucial property enjoyed by the natural action of
$D_{8}$ on the square which enabled our use of paper cutouts in studying the
group is faithfulness. If the action were not faithful, determining which
operations in $D_{8}$ are inverses would not be so easy as printing out a square
and plugging away, because we may (among other catastrophes) be working with an
action which may not take only the identity element to the
leave-everything-in-place operation on the square.

Having gesticulated that actions gives groups and monoids their meaning, we turn
to the development of the doctrines of \emph{elementary sketch} and
\emph{algebraic theory} which will allow us to generalize both sets with
algebraic structures and their actions to new settings.

\section{Elementary sketches and their models}
As promised, we begin with the definition.
\begin{definition}\label{def:elem sketch}
  An \textbf{elementary sketch} is comprised of the following data:
  \begin{enumerate}
    \item a collection \(X, Y, Z, \dots \) of named \textbf{base types} or
          \textbf{sorts}
    \item a \textbf{variable} \(x:X\) for each occurrence of each named sort.
    \item a collection of \textbf{unary operation-symbols} or
          \textbf{constructors} \(\tau\) having at most one variable. As a
          clarifying example: when sketching type theories, we will write
          \( x:X \vdash \tau(x) : Y \).
    \item a collection of equations or \textbf{laws} of the
          form: \[ \tau_n (\tau_{n-1}(\cdots \tau_2 (\tau_1 (x))\cdots )) = \sigma_m (\sigma_{m-1}(\cdots \sigma_2 (\sigma_1 (x))\cdots )) \]
  \end{enumerate}
\end{definition}

We will discuss the generality provided by this definition after some
intervening examples. One of the simplest examples is the sketch of a (free)
monoid on some set $S$:

\begin{example}[Sketch of a (free) monoid]\label{ex:monoid sketch}
  The requisite data for the sketch are as follows:
  \begin{enumerate}
    \item The collection of sorts is the singleton \( \{M\} \).
    \item The collection of variables is \( \{m:M\} \).
    \item The collection of operation symbols is the set \( S \). Each has as its signature \( M \rightarrow M \)
    \item No equations are imposed.
  \end{enumerate}
\end{example}

To really buy that this sketch generates a free monoid, we need an intervening
concept which makes more concrete what we mean when saying ``generates.'' The
idea should be familiar to the reader acquainted with type theory, despite the
drastically simplified setting.

\begin{definition}\label{def:term}
  Given an elementary sketch, a \textbf{term} $x : \Gamma \vdash X$ is a string of
  composable unary operation-symbols applied to a variable $\gamma : \Gamma$ as in:
  \( \tau_{n} (\tau_{n-1} (\cdots (\tau_{2}(\tau_{1}(\gamma))))) \). Composable unary-operation
  symbols are ones which have compatible domains and codomains in the usual
  sense as in set theory.
\end{definition}

We now propose a more precise version of the above claim: the terms of the
sketch defined above form the elements of a free monoid over $S$. Before we can
continue, we should decide what our term composition will be.

\begin{definition}[Composition of terms]\label{def:term composition}
  Composition of terms is by substitution for the variable: for a term
  \( \sigma : \Delta \vdash \Gamma\) and some terms \( \tau_{i}\) with \( \tau_{n} : \cdots \vdash \Xi \) we define
  \[ (\tau_{n} (\tau_{n-1} (\cdots (\tau_{2}(\tau_{1}(\gamma)))))) \circ \sigma = \tau_{n} (\tau_{n-1} (\cdots (\tau_{2}(\tau_{1}(\sigma(\delta)))))) : \Delta \vdash \Xi. \]
\end{definition}

With our notion of composition in hand, we can now handwave an argument for our
revised claim that the terms of the sketch form the elements of a free monoid.
It is well-known that substitution operation is associative; see, for example,
Chapter 1 of \cite{taylor_practical_1999} for a fantastic treatment of the
theory of substitution. As a consequence, any elementary sketch, including this
one, satisfies the associativity axiom of monoids for free. The identity term is
given by zero composable unary operation-symbols (i.e., the empty string)
applied to a variable. Because composition is given by substitution for the
variable, a lone variable does indeed work function as the identity. Freedom
comes from the fact that the sketch has no equations.

This loose argument is somewhat satisfying, but we can do better. To get there,
we will first develop a notion generalizing \emph{actions} from algebra. After
doing so, we will give more concrete meaning to this sketch and complete our
intuitive handle on it.

\begin{definition}\label{def:model}
  A \textbf{model} (also known as an algebra, an interpretation, a covariant
  action) of an elementary sketch is comprised of:
  \begin{enumerate}
    \item an assignment of a set $A_X$ to each sort $X$ and
    \item an assignment of a function $\tau_* : A_X \rightarrow A_Y$ for each
    operation-symbol of the appropriate arity such that:
    \item each law is preserved; i.e., for each law as before we have
    \[ {\tau_n}_* ({\tau_{n-1}}_* (\cdots {\tau_2}_* ({\tau_1}_* (x))\cdots )) = {\sigma_m}_* ({\sigma_{m-1}}_*(\cdots {\sigma_2}_* ({\sigma_1}_* (x))\cdots )) \]
    that is, the covariant action on operation-symbols is faithful in
    the sense defined above.
  \end{enumerate}
\end{definition}

The next definition will feature prominently in our later study of type theory,
but will also prove immediately useful in studying Example~\ref{ex:monoid
  sketch} by forming the sets of a ``for-free'' model for any elementary sketch.

\begin{definition}\label{def:clone}
  Given an elementary (unary) sketch, the \textbf{clone} at \( (\Gamma, X) \) is
  the set \( \text{Cn}_{\mathcal{L}} (\Gamma, X) \) of all the \textbf{terms} of sort
  $X$ assuming a single variable of sort $\Gamma$, quotiented by the laws of the
  sketch.
\end{definition}
The fact that a sketch's clones contain \emph{equivalence classes} (with respect
to the laws) of its terms will feature prominently in our later study of ideas
central to the goals of this thesis. In particular, clones alone don't allow for
any meaningful discussion of computational behavior of terms undergoing
reduction; a term's normal form and its various reducible forms are identified
in the clone.

It can be shown that the clones of a sketch form (the sets for) a model of a
sketch. In particular, it can be shown that the sketch acts covariantly on the
set of its clones:
\begin{theorem}\label{thm:clone model}
  Every elementary sketch has a faithful covariant action on its clones
  \(\mathcal{H}_{X} = \cup_{\Gamma} \text{Cn}_{\mathcal{L}}(\Gamma,X)\) by sequencing with
  the operation symbol. Substitution for the (single) variable in a term gives
  a faithful contravariant action on
  \(\mathcal{H}^{Y} = \cup_{\Theta} \text{Cn}_{\mathcal{L}}(Y,\Theta)\).
\end{theorem}
\begin{proof}
  The actions of \(\tau : X \rightarrow Y\) on
  \(\text{Cn}_{\mathcal{L}} (\Gamma,X) \subseteq \mathcal{H}_{X}\) and
  \(\text{Cn}_{\mathcal{L}} (Y,\Theta) \subseteq \mathcal{H}^{Y}\) are given by:
  \begin{itemize}
    \item \(\tau_{*}a_{n}(\cdots a_{2}(a_{2}(\sigma))\cdots) =
    \tau(a_{n}(\cdots(a_{2}(a_{1}(\sigma))))) \in
    \text{Cn}_{\mathcal{L}}(\Gamma,Y)\)
    \item \(\tau^{*}\zeta_{m}(\cdots \zeta_{2}(\zeta_{1}(y))) =
    \zeta_{m}(\cdots\zeta_{2}(\zeta_{1}(\tau(x)))) \in
    \text{Cn}_{\mathcal{L}}(X,\Theta)\)
  \end{itemize}
  where \(\sigma : \Gamma, x : X \text{ and } y:Y\). Covariance of the
  former is clear. Contravariance of the latter follows by considering the
  behavior of substitutions in sequence.
\end{proof}

Recalling our sketch of a monoid from Example~\ref{ex:monoid sketch}, the
substance of this covariant action morally amounts to saying that the sketch
acts on its terms by left multiplication (here ``multiplication'' is actually
just juxtaposition plus some parentheses) which gives the robust version of the
handwavy argument we provided above.

\begin{joke}
  A couple of type theorists walk into a Michelin starred restaurant. The menu
  reads in blackboard bold letters $\mathbbm{``NO\, SUBSTITUTIONS''}$. They promptly leave.
\end{joke}

The reader might have noted that there is a strong resemblance between the
notion of a sketch and that of a category. Indeed, the following result uses the
clone action defined above to show that we can associate to every sketch a
category and that to every category we can associate a sketch. These assignments
moreover induce an isomorphism of categories.

\begin{theorem}[The canonical elementary language]\label{thm:canonical_elementary_language} Every elementary sketch
  \( \mathcal{L} \) presents a category \( \cn_{\mathcal{L}}\) via the for-free
  action on its clones, and conversely any small category $C$ is presented by
  some sketch $\mathcal{L}$ in the sense that \( C \cong \cn_{\mathcal{L}}\). We
  write \( \lceil-\rceil \) for this isomorphism and call the sketch
  \( L(C) = \mathcal{L} \) the \emph{canonical elementary language} of \( C \).

  The language is defined as follows:
  \begin{itemize}
    \item The sorts \( \lceil X \rceil \) of \( L(C) \) are the objects \( X \) of \( C\)
    \item The operation symbols \( \lceil f \rceil \) are the morphisms \( f \) of \( C \) and
    \item The laws are \( \lceil \id \rceil (x) = x \) and \( \lceil g \rceil (\lceil f \rceil (x)) = \lceil g \circ f \rceil (x) \)
  \end{itemize}
  and the isomorphism \( C \cong \cn_{\mathcal{L}} \) is clear.
\end{theorem}

\section{The category of contexts and substitutions}
We now introduce a category which is special in both the structure it enjoys as
well as the central role it will play in the rest of this thesis. This category
goes by many names: \emph{syntactic category}, the verbose \emph{category of
  contexts and substitutions}, and the elusive \emph{classifying category}. We
endeavor to explain the meaning behind each of these names over the course of
the thesis, but for now we adopt the name most closely describing its
presentation.

% TODO: say something about what it means to present a category?
\newcommand{\syncat}[1]{\text{Cn}_#1^{\times}}
\begin{definition}[The category of contexts and substitutions]\label{def:syn cat}
  Given a sketch $\mathcal{L}$, the \textbf{category of contexts and substitutions}, written \( \syncat{\mathcal{L}} \) is presented as follows:
  \begin{outline}
    \1 The objects are the contexts of \( \mathcal{L} \), i.e., finite lists of
    distinct variables and their types.

    \1 The generating morphisms are:

    \2 Single substitutions or \emph{declarations} \( [a/x] : \Gamma \rightarrow [\Gamma, x:X] \)
    for each term \( \Gamma \vdash a : X \). The direction in the signature should be
    confusing unless you're either already an expert or a total novice to type
    theory.

    \2 Single omissions or \emph{drops} \( \hat{x} : [\Gamma, x : X] \rightarrow \Gamma \) for each
    variable $x:X$.

    \1 The laws are given by an extended version of the substitution lemma from
    type theory \cite{pierce_types_2002}. When talking about these laws, we will
    often call them ``the extended substitution lemma.'' The following laws are
    imposed for each collection of terms $a,b$ and distinct variables $x$ and
    $y$ such that $x$ does not appear free in $a$ and $y$ appears free in
    neither $a$ or $b$:
    \begin{align*}
      % declaration follow by drop does nothing
      [a/x] ; \hat{x} &= \id \\
      % successive declarations commute up to accounting for the first
      % declaration in the body of the second
      [a/x] ; [b/y]   &= [ [ a/x ]^{*} b/y ] ; [a/x] \\
      % non-overlapping declarations and drops commute
      [a/x]; \hat{y} &= \hat{y}; [a/x] \\
      % non-overlapping drops commute
      \hat{x}; \hat{y} &= \hat{y}; \hat{x} \\
      [x/y]; \hat{x}; [y/x]; \hat{y} &= \id
    \end{align*}
  \end{outline}
  We will briefly speak to the meaning of the laws. The first law says that
  binding a variable to some term and then forgetting the variable is just the
  same as doing nothing. The second law says that successive variable
  declarations commute \emph{up to accounting for the first declaration in the
    body of the second}. The third law says that \emph{non-overlapping}
  declarations and drops commute. The fourth law says that pairs of
  non-overlapping drops commute. The last law is tricky and is easier to explain
  by passing to the substitution point-of-view. Since the change of base functor
  is contravariant, this requires considering the compositions in reverse order
  as:
  \[ \hat{y}^{*}; [y/x]^{*}; \hat{x}^{*}; [x/y]^{*} = {\id}^{*} \] Rendered
  thus, this law means that introducing a free variable $y$ to the
  context\footnote{possibly having no effect if $y$ is already present},
  followed by replacing every free occurrence of $x$ with $y$, followed by
  re-introducing $x$ as a variable in the context, and then finally replacing
  every free occurrence of $y$ with $x$ is the same as doing nothing. More
  concisely at the expense of precision, renaming a free variable in a term and
  then un-renaming it results in the same term.
\end{definition}


We can give the syntactic category a model in the clones by acting by
substituting for variables, along the lines of Theorem~\ref{thm:clone model}.
The reader unfamiliar with substitution will find relief in
Example~\ref{ex:digital_logic}, where we show how this action works in terms of
a concrete (and visual) example from digital logic.
\begin{remark}
  The morphisms of the category of contexts and substitutions
  \( \syncat{\mathcal{L}} \) for some sketch \( \mathcal{L} \) acts
  contravariantly on the clones
  \( \mathcal{H}^{Y} = \cup_{X}\cn_{\mathcal{L}}(Y,X)\). In the case of single
  substitution \( [a/x]\), the action is by substituting the term $a$ for the
  variable $x$. In the case of weakenings, the action has no operational or
  syntactic significance.
\end{remark}

This category allows us to define a special class of functor. In our
case, that class of functor captures what it means to produce a model of an
elementary sketch. The proof of this theorem is rather bureaucratic, but its
importance is that it teaches us that the canonical elementary language of a
category is purpose-built so that its models are precisely set-valued functors
out of the category in question.

% TODO: need to have some corollary or theorem saying how the classifying
% category acts on the clones by substitution of the term

% TODO: make model object notation agree with earlier defintion. I think I want to go with X_A instead of A_X for the valuation of sort X in the algebra A.

\section{Models are essentially functors}
\begin{theorem}[The classifying category]\label{thm:classify_elem_sketch}
  Let $\mathcal{L}$ be an elementary sketch and \( \cn_{\mathcal{L}} \) the
  category it presents. Then the models of $\mathcal{L}$ correspond to functors
  $\cn_{\mathcal{L}} \rightarrow \mathfrak{Set}$.
\end{theorem}
\begin{proof}
  \( (\Rightarrow) \) Suppose we have an \( \mathcal{L}\)-model $A$. Then $A$ is an
  assignment of a set $\ceil{X}_{A}$ to each sort \( \ceil{X}\) and an
  assignment of a function \( \ceil{r}_{A} : X_{A} \rightarrow Y_{A}\) to each operation-symbol
  \( X \vdash \ceil{r}(x) : Y\) such that the laws (given by
  Theorem~\ref{thm:canonical_elementary_language}) of \( \mathcal{L} \) are preserved. These
  assignment form precisely the data of a functor

  \begin{align*}
   F_{A} &: \cn_{\mathcal{L}} \rightarrow \mathfrak{Set} \\
    X &\mapsto \ceil{X}_{A} \\
    (X \xrightarrow{r} Y) &\mapsto \ceil{r}_{A}
  \end{align*}.

  It remains to show functoriality of these assignments which follows from the
  laws of the canonical elementary language and faithfulness of the model. \\

  \( (\Leftarrow) \) Suppose we have a functor
  $F_A : \cn_{\mathcal{L}} \rightarrow \mathfrak{Set}$. We will construct a model $A$ of
  $\mathcal{L}$ from $F_{A}$ as follows: Recall from
  Theorem~\ref{thm:canonical_elementary_language} that the sorts \(\ceil{X} \)
  of the sketch $\mathcal{L}$ are precisely the objects $X$ of
  \( \cn_{ \mathcal{L}} \), and the operation symbols \( X \vdash \ceil{ f } : Y \)
  are the morphisms \( f \) of \( \cn_{\mathcal{L}}\). Now,
  \begin{enumerate}
    \item For each sort \(\ceil{X}\) we assign \( \ceil{X}_A = F_{A}(X)\).
    \item For each operation symbol \( \ceil{f} \) we assign \( \ceil{f}_{A} = F_{A}(f) \).
    \item Again by Theorem~\ref{thm:category_of_sketch}, the only laws of the
          sketch are that \(\ceil{\text{id}}(x) = x\) and
          \(\ceil{g}(\ceil{f}(x)) = \ceil{g \circ f}(x)\). According to the
          assignments in the previous two points, the first law says that
          \(F_{A}(\text{id}_{X}) = \text{id}_{\ceil{X}_{A}}\), and the second says that
          \( (F_{A} \ceil{g}) \circ (F_{A}(\ceil{f})) = F_{A} (g \circ f)\). Both are
          ensured by functoriality.
  \end{enumerate}
\end{proof}

% \subsection{Example morphisms in the syntactic category}
% A natural question for the operationally-minded reader to ask after having seen
% the definition of the syntactic category is: how does all this ornate structure
% encode terms in the calculus I'm interested in? Let us ask instead a more
% precise question: how do we represent by a substitution a term \(\Gamma \vdash t : T\)?
% For such a term, there is a canonical substitution (morphism of contexts)
% \( \Gamma \xrightarrow[]{[t/x]} \Gamma,x:X \) which ``picks'' that term in $T$. Here
% $[t/x]$ is an explicit encoding/formula for the substitution inserting $t$
% anywhere it sees $x$. The ordering of the codomain and domain here should be
% confusing, but the contravariant base change functor, which lifts this encoding
% to a real substitution \emph{operation} clarifies things; we have:
% \( [t/x]^{*} : \clone{}{\Gamma, x:X}{T} \longrightarrow \clone{}{\Gamma}{T} \). In words, the
% substitution operation takes a term of type $T$ under $\Gamma$ and an additional free
% variable $x:X$ and gives us a term of type $T$ under just $\Gamma$; we reduce our
% assumption set by filling in one of the assumptions with some concrete evidence,
% namely the (syntactic) term $t$. In the special case of a closed (syntactic)
% term $t$, we have \( [t/x]^{*} : \clone{}{x:X}{T} \longrightarrow \clone{}{\emptyset}{T}\).

\section{Algebraic theories and their algebras}
While conjuring up example elementary sketches, the reader will find that the
regime of unary operations regularly gets in the way of representing familiar
gadgets like rings or type theories. To address this deficiency, we introduce
the doctrine of \emph{algebraic theories} which generalizes the doctrine of
elementary sketches and allows for multi-input operation symbols. As we work
through this upgrade in doctrine, many of the notions (\emph{terms, clones,
  syntactic category, etc.}) we developed in the simplified world of elementary
sketches will come along for the ride without much changed.

\begin{definition}[Algebraic theory]\label{def:alg theory}
  A (finitary many-sorted) \textbf{algebraic theory} $\mathcal{L}$ has
  \begin{enumerate}
    \item a collection $\Sigma$ of base types or \textbf{sorts} $X$
    \item an inexhaustible collection of variables $x_{i}:X$ of each sort;
    \item a collection of \textbf{operation symbols},
          $x_{1}: X_{1},\dots , x_{k} : X_{k} \vdash r(x_{1},\dots, x_{k}) : Y$ each
          having an \textbf{arity}, namely a list of input sorts $X_{i}$, and an
          output sort $Y$; and
    \item a collection of \textbf{laws}, posed as equalities between different
          terms (in the sense defined before)
  \end{enumerate}
\end{definition}

We will write \( \termob \) for the nullary product of sorts, and moreover when
working with a \emph{constant} operation symbol \( \termob \vdash c() : X \), we will
often allow ourselves to simply write $c$ rather than $c()$.

\begin{remark}
  The syntactic category \(\syncat{\mathcal{L}}\) of an algebraic theory is
  given essentially as before.
  % TODO: fix this
\end{remark}

The next major concept we will introduce generalizes to algebraic theories the
notion of \emph{action} or \emph{model} we saw previously for elementary
sketches. As expected, the definition will be essentially the same up to taking
some products.

\begin{definition}[$\mathcal{L}$-algebra]\label{def:algebra}
  Given an algebraic theory $\mathcal{L}$ and a category $C$ with finite
  products (in the sense of the universal property as treated in the chapter on
  basic category theory) an \emph{$\mathcal{L}$-algebra in $C$} is comprised of
  \begin{enumerate}
    \item an object $A_{X}$ of $C$ for each sort $X$ of $\mathcal{L}$, and
    \item for each operation symbol $X_{1}, \dots , X_{k} \vdash r : Y$, an
          assignment of a map \(r_{A} : A_{X_{1}} \times \cdots \times A_{X_{k}} \rightarrow A_{Y}\) in
          $C$.
  \end{enumerate}
  such that the assignments respect the laws of $\mathcal{L}$.
\end{definition}

We now give some prototypical example theories and algebras. The first such pair
we consider is the familiar structure of a ring from abstract algebra, one of
whose algebras is the ring of integers under addition and multiplication.

\begin{example}[Algebraic theory of \emph{ring}]\label{ex:theory of ring}

  We sketch an algebraic theory encoding the familiar structure of a ring from
  abstract algebra. The presentation should look familiar (when squinting) to
  anyone with a background in abstract algebra, except that we force the
  existence of multiplicative and additive identities by requiring any model (to
  be defined!) of this theory to 1) provide \emph{global elements}, namely
  morphisms out of the terminal object of the category hosting the model and 2)
  satisfy the defining equations of the identity.

  \begin{enumerate}
    \item Sorts: The single sort is \( S \). The variable collection for the
          sort is \( \{x,y,z\} \cup \set{s_{i}}_{i\in\mathbb{N}} \).

    \item Operations: \begin{align*}
                        \cdot &: S \times S \rightarrow S, \\
                        + &: S \times S \rightarrow S,\\
                        0 &: \mathbbm{1} \rightarrow S,\\
                        1 &: \mathbbm{1} \rightarrow S,\\
                        - &: S \rightarrow S
                      \end{align*}

    \item Laws: \begin{align*}
                  +(x,y) &= +(y,x)\\
                  +(0(), x) &= x\\
                  +(x, -(x)) &= 0()\\
                  \cdot(x,y) &= \cdot(y,x)\\
                  \cdot(1(), x) &= x\\
                  \cdot(x, +(y,z)) &= +(\cdot(x,y), \cdot(x,z))
                \end{align*}
  \end{enumerate}
  Note that the countably infinite set of variables \( \{ s\}_{i\in\mathbb{N}}\)
  is added so that we may have deeply nested expressions, even if we had no need
  for them when stating the laws above. In fact, such countable variable sets
  are \emph{required} when defining an algebraic theory for precisely this
  reason. That this requirement was not imposed for elementary sketches is
  because there can only be one variable in a term, even in heavily nested
  terms, by construction.
\end{example}


 Having given
some concrete examples, we now allow ourselves another abstract definition: that
of an \emph{$\mathcal{L}$-algebra} for an algebraic theory:

\begin{example}[The ring of integers]\label{ex:integer ring}
  \begin{enumerate} \,
    \item For the single sort, we set $A_{S} = \mathbb{Z}$
    \item For the operations, we set
    \begin{enumerate}
      \item $\cdot_{A}$ to be the ordinary multiplication of integers
      \item $+_{A} = +$ where the second plus is ordinary addition of integers
      \item $0_{A}$ to the function $* \mapsto 0 \in \mathbb{Z}$
      \item $1_{A}$ to the function $* \mapsto 1 \in \mathbb{Z}$
      \item $-_{A}$ to the function $x \mapsto -x$ taking an integer to its additive inverse
    \end{enumerate}
    \item Verifying the rest of the laws is routine after understanding how to
          verify any one of them, so we demonstrate just one. We show that the
          $0$ selected by the model indeed serves as the left identity of
          addition in the model.
          \begin{proof}
            \begin{align*}
              +_{A} \circ \braket{0_{A}(*), \id} &= (y : \mathbb{Z}) \mapsto 0_{A}(*) + \id(y)\\
                                          &= (y : \mathbb{Z}) \mapsto 0_{\mathbb{Z}} + y \\
                                          &= (y : \mathbb{Z}) \mapsto y\\
                                          &= \id_{S_{A}} \\
            \end{align*}
            which is the interpretation of the variable $x$, as required.
          \end{proof}
  \end{enumerate}
\end{example}

The reader familiar with algebra will observe that this example amounts to
verifying that the integers form a ring under the standard multiplication and
addition operations we learn in elementary school. In general, the reader will
find that all \emph{rings} (in the conventional sense of abstract algebra) are
\( \mathfrak{Set}\)-valued \emph{algebras} of the algebraic theory of
\emph{ring}. The reader may also verify that the usual ring-homomorphisms in
\( \mathfrak{Set}\) are an instance of the generalized notion of
\( \mathcal{L}\)-algebra homomorphism that we introduce following an intervening
example theory-algebra pair from computing.

This example is meant for readers with a basic background in digital logic. An
interesting aspect of this example is that it admits some very practical
algebras.

\begin{example}[The algebraic theory of digital logic circuits]\label{ex:digital_logic}
  We can encode the language of digital logic circuits as an algebraic theory, presented as follows:

  \begin{enumerate}
    \item The single sort is \( \bitcoin \). We will write \( \bitcoin^{k} \)
          for the $k$-wide product \( \bitcoin \times \bitcoin \times \cdots \times \bitcoin \) for
          finite \( k \).
    \item The variable collection is \( \{ b_{k} \mid k \in \mathbbm{N} \} \).
    \item The operations, for each finite $k \in \nat$, are:
      \begin{align*}
        \texttt{AND}_{k} &: \bitcoin^{k} \rightarrow \bitcoin \\
        \texttt{OR}_{k} &: \bitcoin^{k} \rightarrow \bitcoin \\
        \texttt{NOT} &: \bitcoin \rightarrow \bitcoin \\
        \top &: \termob \rightarrow \bitcoin \\
        \bot &: \termob \rightarrow \bitcoin \\
      \end{align*}
    \item The laws, for each finite $k \in \nat$, are:
    \begin{align*}
      \texttt{AND}_{k} (b_{1},b_{2},\dots,\bot, \dots, b_{k}) = \bot \\
      \texttt{OR}_{k} (b_{1},b_{2},\dots,\top, \dots, b_{k}) = \top \\ \\
      \texttt{AND}_{k} (\top,\dots,\top) = \top \\
      \texttt{OR}_{k} (\bot, \dots, \bot) = \bot \\ \\
      \texttt{NOT}(\top) = \bot \\
      \texttt{NOT}(\bot) = \top \\
    \end{align*}
  \end{enumerate}
\end{example}

A mundane but useful algebra for this theory is given as follows: We assign the
the single sort to be the set \( \{0,1\} \). For the operation symbols, we
assign \( \top \) to the function \( * \mapsto 1\); \( \bot \) to function \( * \mapsto 0 \);
$\texttt{AND}_{k}$ to the function which multiplies all of its inputs; and
$\texttt{OR}_{k}$ to be the function which adds (modulo 2) its inputs. This
algebra provides a convenient way of writing down and quickly reducing boolean
circuits according to the familiar symbolic language of algebra.

A more interesting algebra comes from practical engineering. We can give an
algebra of the theory above by implementing the \emph{logic gate} operations
NOT, AND, and OR as component circuits built with \emph{metal oxide
  semiconductor field effect transistors}, also known as \emph{MOSFETs}. You
probably own a couple billion of them.

\begin{figure}[h]
  \caption{A diagram of a MOSFET, by Brews ohare - CC BY-SA 3.0,
    https://commons.wikimedia.org/w/index.php?curid=18796795}
\centering
\includegraphics[width=0.5\textwidth]{mosfet}
\end{figure}

The exact details of how a MOSFET is used to construct such circuits are beyond
the scope of this thesis; we refer the interested reader to Ben Eater's videos
on the constructions~\cite{eater_making_2015}. The upshot of this construction
is that we get, for say the NOT operation, a circuit component

\begin{center}
  \begin{circuitikz}
    \draw (0,0) node[not port] (mynot) {};
  \end{circuitikz}
\end{center}

which has low voltage on its output when it has high voltage applied to its
input, and vice versa. This behavior is precisely the equational law
characterizing the NOT operation symbol, and suggests that we interpret the
\( \top \) operation symbol as a source of high voltage and the \( \bot \) operation
symbol as a wire with no voltage applied. The AND and OR operations also enjoy
physical realizations in term of MOSFETs, as do the finite-input generalizations
of all of these operations.

The reader suspicious of abstract nonsense will complain that we have merely
dressed up in abstract nonsensical terms the well-known fact that electrical
circuits can implement combinational logic. Indeed, the utility of this example
lies not in some new exciting insight about digital circuits but rather, as we
will soon see, in leveraging our visual intuition about digital circuits to
better understand how substitution works, and why substituting for a variable is
a contravariant operation.

The circuit interpretation also provides a neat intuition for weakening.
Weakening by a variable is drawing a new input wire with the appropriate label,
and then not connecting it to anything. As an example, we have the following
equality.
\begin{align*}
 \widehat{b_{4}}^{*} \bigg({\tikz[baseline=-0.5ex]{ \draw (0,0) node[and port, number inputs=3](myand){}
    (myand.in 1) node [anchor=east] {\( b_{1} \)}
    (myand.in 2) node [anchor=east] {\( b_{2} \)}
    (myand.in 3) node [anchor=east] {\( b_{3} \)};
  }}\bigg) &= \tikz[baseline=-0.5ex]{ \draw (0,0) node[and port, number inputs=3](myand){}
    (myand.in 1) node [anchor=east] {\( b_{1} \)}
    (myand.in 2) node [anchor=east] {\( b_{2} \)}
    (myand.in 3) node [anchor=east] {\( b_{3} \)}
    (myand) ++(-1.725,-.75) node[](b4){\( b_{4}\)}
    (b4) ++(1,0) node [ground](myground){}
    (b4) -- (myground)
    ; }
\end{align*}

where we represent an unused input as one connected straight to ground.

Allowing ourselves to write the operations of the algebra for the operation
symbols of the theory for a moment, consider the morphism
\[ [ \tikz{ \draw node[and port, number inputs=3](myand){}
    (myand.in 1) node [anchor=east] {\( b_{1} \)}
    (myand.in 2) node [anchor=east] {\( b_{2} \)}
    (myand.in 3) node [anchor=east] {\( b_{3} \)};
  } \middle/ b_{4}] : [b_1 : \bitcoin, b_2:\bitcoin, b_3 : \bitcoin] \rightarrow [b_1:\bitcoin,b_2:\bitcoin,b_3:\bitcoin,b_4 :\bitcoin]\]

in the syntactic category. We can now consider a concrete example of a concrete
example of substitution in action by substituting along this morphism. Ignoring
the requisite intermediate weakenings, we have that

\[
  [ \tikz{ \draw node[and port, number inputs=3](myand){}
    (myand.in 1) node [anchor=east] {\( b_{1} \)}
    (myand.in 2) node [anchor=east] {\( b_{2} \)}
    (myand.in 3) node [anchor=east] {\( b_{3} \)};
  } \middle/ b_{4}]^* (\tikz { \draw node[or port](myor){}
    (myor.in 1) node [anchor=east] { \(b_{4}\) }
  (myor.in 2) node [anchor=east] { \( b_{5}\) };})
\]

which results in the circuit

\[
\tikz{ \draw (0,2) node[and port, number inputs=3](myand){}
    (myand.in 1) node [anchor=east] {\( b_{1} \)}
    (myand.in 2) node [anchor=east] {\( b_{2} \)}
    (myand.in 3) node [anchor=east] {\( b_{3} \)}

    (2,0) node[or port](myor){}

    (myor.in 2) node [anchor=east] { \( b_{5}\) }
    (myand.out) -| (myor.in 1);
    }
\]

Looking back at the morphism encoding this substitution operation, we should
remind ourselves that the \( b_{1}, b_{2}, b_{3}\) in the codomain context were
not necessarily \emph{used} in the original circuit; indeed, those variables
could be (as in this case) merely unused inputs which were added by a weakening
operation. What is essential is that such a weakening \emph{has put the input
  wires in place} before we slot the 3-wide AND into place.

\begin{definition}[$\mathcal{L}$-algebra homomorphism]\label{def:homomorphism}
  A \emph{homomorphism} \( \phi: A \rightarrow B\) of $\mathcal{L}$-algebras $A$ and $B$ in some
  category $\mathfrak{C}$ with finite-products is an assignment to each sort $X$
  of a $\mathfrak{C}$-morphism \( \phi_{X} : A_{X} \rightarrow B_{X}\) between the
  corresponding objects in each algebra such that diagrams of the following form
  commute:

  \[\begin{tikzcd}
      {A_{X_1}\times\cdots \times A_{X_k}} &&& {A_{X}} \\
      \\
      {B_{X_1}\times\cdots\times B_{X_k}} &&& {B_{X}}
      \arrow["{r_A}", from=1-1, to=1-4]
      \arrow["{r_B}", from=3-1, to=3-4]
      \arrow["{\phi_{X_1}\times \cdots \times \phi_{X_k}}"', from=1-1, to=3-1]
      \arrow["{\phi_{X}}", from=1-4, to=3-4]
    \end{tikzcd}\]

\end{definition}

\begin{remark}\label{rmk:alg_func}
  The following is an observation due to Lawvere in a paper written in his time
  teaching at Reed College \cite{lawvere_functorial_1963}. The familiarity of
  this diagram is no mistake: indeed, by analogy to
  Theorem~\ref{thm:classify_elem_sketch}, we may understand algebras as
  product-preserving functors. A mapping between algebras then is a natural
  transformation, hence the naturality diagram in
  Definition~\ref{def:homomorphism}. We will later make this analogy more
  concrete in Theorem~\ref{thm:classifying alg theory}.
\end{remark}

\begin{remark}
  Perhaps predictably, the $\mathfrak{C}$-valued algebras and homomorphisms of
  an algebraic theory $\mathcal{L}$ form a category, called
  $\textrm{Mod}_{\mathfrak{C}}(\mathcal{L})$.
  \begin{proof}
    Per Remark~\ref{rmk:alg_func}, we consider algebras and their homomorphisms
    as functors and natural transformations respectively. The identity morphisms
    are the identity natural transformations whose component morphisms are the
    identities of $\mathfrak{C}$. Composition of natural transformations is
    given by composition of their component morphisms, hence we may out-source
    the associativity condition to that guaranteed by the categorical structure
    of $\mathfrak{C}$.
  \end{proof}
\end{remark}

Many things you'd like to prove about a type theory are concerned with the
\emph{terms} of the theory at hand. \emph{Normalization} theorems talk about the
accessibility (under some reduction relation) of a certain class of terms from
any arbitrary open term. \emph{Canonicity} or \emph{closed normalization}
theorems talk about the accessibility of a different class of terms from
arbitrary \emph{closed} terms. These are but two examples of a broad spectrum of
properties one might desire of the terms of a theory. Considering the primacy of
term properties in type theory, it is rather strange that the notion of
semantics we have built so far makes no commentary on terms besides the action
on the clones given in Theorem~\ref{thm:clone model}. Our models so far have
only given meaning to the individual \emph{sorts} (types) and individual
\emph{operation symbols} (constructors) of the theory considered. In fact, this
is enough: our models extend canonically \emph{along the product structure} to
contexts and substitutions and thus give meaning to terms.

\DeclarePairedDelimiter{\sem}{\llbracket}{\rrbracket}

\begin{definition}[Extending a model to terms]\label{def:term model}
  Let $A$ be an $\mathcal{L}$-algebra in a category $\mathfrak{C}$. This algebra
  extends canonically to an interpretation $\sem{-}$ of contexts by the
  following definition recursive in the structure of contexts:
  \begin{align}
    \label{eq:contexts interp}
    \sem{\varnothing} &= \mathbbm{1}_{C} \\
    \sem{\Gamma, x : X} &= \sem{\Gamma} \times A_{X}
  \end{align}
  The (overly) careful reader will complain that $\mathfrak{C}$ doesn't
  necessarily feature a terminal object, but it turns out that a terminal object
  is guaranteed\footnote{as the nullary finite product} by the finite product
  closure we imposed on $\mathfrak{C}$ in our definition of algebras. We are
  good to go.

  Recalling more from the definition of an algebra, we know that $A$ gives
  meaning to each operation symbol \( Y_{1},\dots , Y_{k} \vdash r : Z \) as a
  morphism \( r_{A} : A_{Y_{1}} \times \cdots \times A_{Y_{k}} \rightarrow A_{Z} \) and gives meaning to
  each constant \( c : Z \) by a morphism \( \termob_{\mathfrak{C}} \rightarrow A_{Z} \). We can
  extend this to arbitrary terms in the context
  \( \Gamma \equiv \sem{x_{1} : X_{1}, \dots , x_{n} : X_{n}} \) by the following
  recursive definition:
  \begin{align*}
    \label{eq:term interp}
    \sem{x_{i}} &: \sem{\Gamma} \equiv A_{X_{1}} \times \cdots \times A_{X_{n}} \xrightarrow{\pi_{i}} A_{X_{i}} \\
    \sem{c} &: \sem{\Gamma} \xrightarrow{<_{!}} \mathbbm{1}_{\mathfrak{C}} \xrightarrow{c_{A}} A_{Z} \\
    \sem{r(u_{1}, \dots , u_{k})} &: \sem{\Gamma} \xrightarrow{\braket{\sem{u_{1}}, \dots, \sem{u_{k}}}} A_{Y_{1}} \times \cdots \times A_{Y_{k}} \xrightarrow{r_{A}} A_{Z}
  \end{align*}
  where the $\sem{u_{i}}$ are the interpretations of the sub-expressions of the
  expression in the final line, $\pi_{i}$ is the $i$th projection guaranteed to us
  by the universal property of products, and $<_{!}$ is the unique map into the
  terminal object. The angle bracket notion is used to express the product
  functor's action on morphisms in $\mathfrak{C}$. For clarity, we write out
  explicitly the composites for the reader:
  \begin{align*}
    \sem{x_{i}} &\equiv \pi_{i} \\
    \sem{c} &\equiv c_{A } \circ <_{!} \\
    \sem{r(u_{1}, \dots , u_{k})} &\equiv r_{A} \circ \braket{\sem{u_{1}}, \dots,\sem{u_{k}}}
  \end{align*}
\end{definition}

\begin{theorem}[The classifying category of an algebraic
  theory]\label{thm:classifying alg theory}
  Let \( \mathcal{L} \) be an algebraic theory. Then $\cn_{\mathcal{L}}$ has
  finite products and
  \begin{enumerate}
    \item there exists in \( \cn_{\mathcal{L}}\) an $\mathcal{L}$-algebra which
          satisfies the following universal property:
    \item Let $\mathfrak{C}$ be another category with finite products and its
          own an $\mathcal{L}$-algebra. Then the functor
          $\sem{-} : \cn_{\mathcal{L}} \rightarrow \mathfrak{C}$ preserves finite products
          and the $\mathcal{L}$-algebra, and is the unique such functor.
  \end{enumerate}
\end{theorem}
\begin{proof}
  We first show that the syntactic category has finite products. Recall that the
  objects of the syntactic category are variable contexts
  \([x : X, y : Y, \dots]\). For any other context \( [t : T, u : U, \dots] \)
  we have the
  product \[ [x : X, y : Y, \dots] \times [t : T, u : U, \dots] = [x : X, y : Y, \dots, t : T, u : U, \dots]\]
  That is, products are given by concatenation of contexts. The projections are
  given by weakening by all the variables in either context: that is, the second
  projection is \( \Gamma \times \Delta \xrightarrow{\hat{\gamma_{1}}\circ\cdots\circ\hat{\gamma_{k}}} \Delta \) where the
  \( \gamma_{i} \) are the variables of \( \Gamma \). We define the first projection
  similarly. The universal property for products is upheld by the equational
  laws concerned with weakenings in the category of contexts.
    % TODO: clean up proof

    Now come the more interesting promised results:
    \begin{enumerate}
      \item
      \begin{enumerate}
        \item The sorts $X$ of $\mathcal{L}$ are interpreted as single variable
        contexts $[x:X] \in \ob C$ where the variable $x$ is arbitrary.
        \item The operation symbols \( X_1, X_2, \dots \vdash r : Y \) of
        $\mathcal{L}$ are interpreted as substitutions \( [r(x_1, x_2, \dots)/y] :
        [x_1:X_1, x_2:X_2,\dots] \rightarrow [y : Y]\)
      \end{enumerate}
      \item The functor promised is precisely the one defined by
      Definition~\ref{def:term model}. Preservation of the model and of
      finite products both follow from the definition of the interpretation
      by induction on contexts. Uniqueness of the functor is in turn forced
      by preservation of the model and finite products.
    \end{enumerate}
\end{proof}
\chapter[Syntax and (functorial) semantics of the lambda calculus]{Functorial
  semantics of the simply typed lambda calculus in cartesian closed
  categories}\label{chapter:stlc}
\epigraph{``Eeny, meeny, miny, moe''}{Alonzo Church (Allegedly, on his choice of
  $\lambda$ as the name for his calculus.)}

This chapter exploits the heavy machinery developed in the previous chapter to
give meaning, in specially structured categories, to the types and terms of the
simply typed lambda calculus. Here is how we shall do so: First, we will present
various a suite of simple type theories as a series of \emph{algebraic theories}
differing only in their equational laws. One of these type theories will be the
typical simply typed lambda calculus with the full gamut of equational laws,
including \( \beta \)-conversion and \( \eta \)-conversion and \( \alpha \)-renaming.
Second, we present an interesting perspective on a well known type of
categorical structure, namely \emph{cartesian closedness}, by explicitly
defining it in terms of the definitional \( \beta\) and \( \eta \) laws from type
theory. We will find that this characterization exactly coincides with the one
found in typical books on category theory. Finally, we will show that any
interpretation of base types of the lambda calculus\footnote{as above} gives
rise to an interpretation of lambda terms in any \emph{cartesian closed}
category with an interpretation of the base types. Unless otherwise noted, what
follows is an adaptation of \cite[Chapter 4.7]{taylor_practical_1999}. We begin
by presenting the term language and type system for the calculus under
consideration.


\section{The simply typed lambda calculus}
We'll work with the simply typed lambda calculus with some collection $T$ of
\emph{base types} (say natural numbers, integers, booleans, or some other type
of object the reader is interested in). We will not dwell on the details of
standard aspects of this development and instead refer the reader to the
standard references \cite{pierce_types_2002}, \cite{harper_practical_2016} for
the full story.

\begin{definition}[Types]\label{def:stlc_types}
  Given a set of base types \( T\), the types \( \types \) of the simply typed
  lambda calculus are generated by the following grammar:
  \[
    \tau \Coloneqq \termob \mid \tau \rightarrow \tau \mid \tau * \tau \mid \theta
  \]
  where \( \theta \) is drawn from \( T \). [TODO: explain grammars? I think the edit
  above should mostly address the disambiguity Angelica pointed out] Note that
  the unit type \( \termob \) is not a base type but rather can be considered a
  nullary product of types.
\end{definition}

\begin{definition}[Terms]\label{def:stlc_terms}
  The terms of the simply typed lambda calculus (with booleans) are generated by the
  following grammar:
  \[
    t \Coloneqq x \mid () \mid \pi_{1}\, t \mid \pi_{2}\, t \mid (t_{1}, t_{2}) \mid t_{1}\, t_{2} \mid \abstr{x}{\tau}{t}
  \]
  where the variables $x$ are drawn from a countably infinite set \( V \).
\end{definition}

The typing rules are given as follows:
\begin{definition}[Typing rules]\label{def:stlc_rules}
    \begin{mathpar}
    \inferrule[]{ \Gamma \vdash t : \tau_1 * \tau_2 }{ \Gamma \vdash \pi_{i} t: \tau_{i} } \and \inferrule{ \Gamma \vdash t_{i} : \tau_{i} }{(\tau_1,\tau_{2}) : \tau_{1} * \tau_{2}}\\
    \inferrule{ \Gamma \vdash t_{1} : \tau' \rightarrow \tau  \\  \Gamma \vdash t_{2} : \tau' }{ \Gamma \vdash t_{1} t_{2} : \tau } \and \inferrule{ \Gamma,x:\tau' \vdash t : \tau}{ \Gamma \vdash \abstr{x}{\tau'}{t} : \tau' \rightarrow \tau}\\
    \inferrule*{ }{ \Gamma, x:\tau, \Gamma' \vdash x : \tau }\\
    \inferrule{ }{ \Gamma \vdash () : \termob }
  \end{mathpar}
\end{definition}

\section[Raw CCS and beta-eta is exactly CCS]{Raw cartesian closed structure, beta-eta rules, and cartesian closed structure}
The following notion mediates between \emph{having lambda abstraction} and the
more structured situation enjoyed by usual presentations of the lambda calculus.
The mediating notion, namely \emph{raw cartesian closed structure}, merely
requires that one be able to write down lambda abstractions, and that they
behave nicely with respect to substitutions that don't interfere with the bound
variable. Notably lacking in \emph{raw cartesian closed structure} from the more
structured situation referred to above are the \emph{$\beta$- and $\eta$-laws} which
explain how to \emph{compute} with lambda abstraction.
% Both the former and latter situations predictably have analogues in
% categories, in which exponential objects will serve as function types, the
% counit of the product-hom adjunction is the evaluation, and lambda abstraction
% is given by exponential transposition. We will see that the less structured

The definition comes from Taylor
\cite{taylor_practical_1999}.

\begin{definition}[Raw cartesian closed structure]
  Let \( C \) be a category with finite products together with product
  projections. We say that \( C \) is \emph{raw cartesian closed} or \emph{has
    raw cartesian closed structure} if we have the following for each pair of
  objects \( X, Y \) of \( C \):
  \begin{enumerate}
    \item An object \( Y^{X} \)
    \item A morphism, \emph{application}, \( \evsig{X}{Y} \) and
    \item For each object \( \Gamma \), a function of hom-sets
          \( \lambda_{\Gamma, X, Y} : C[\Gamma \times X, Y] \rightarrow C[\Gamma, Y^{X}] \) obeying the naturality
          law:
          \[
            \lambda_{\Gamma, X, Y} ( \mathfrak{p} \circ (\mathfrak{u} \times \id_{X})) = \lambda_{\Gamma, X, Y}(\mathfrak{p}) \circ \mathfrak{u}
          \]
          for each \( \mathfrak{u} : \Gamma \rightarrow \Delta \) and
          \( \mathfrak{p} : \Delta \times X \rightarrow Y \).
        \end{enumerate}
        Looking closely, the naturality law essentially says that substitutions
        ``not touching'' the bound variable commute with lambda abstraction.
        Informally, this is a good equation to have in mind:
        \( \mathfrak{u}^{*}(\lambda x\, . p) = \lambda x.\, (\mathfrak{u}^{*}p) \).
\end{definition}

We will say that an algebraic theory $\mathcal{L}$ \emph{has raw cartesian
  closed structure} if its classifying category \( \cnprod \) has raw cartesian
closed structure.

The following theorem extends Definition~\ref{def:term model} and shows how to
construct an interpretation of terms from an algebra in a raw cartesian closed
category. The essence is that we extend the assignments of base types and
operation symbols along products (as we did before when dealing with ordinary
algebraic theories) and along the new exponential objects as well.

\begin{theorem}\label{thm:rawccsinterp}
  Let \( \mathcal{L}\) be an algebraic theory and $C$ be a category with raw
  cartesian closed structure and an algebra for \( \mathcal{L}\). The algebra
  for \( \mathcal{L}\) extends uniquely along the raw cartesian closed structure
  to provide an interpretation of terms, which defines a functor
  \( \sem{-} : \cn_{\mathcal{L}} \rightarrow C\)
\end{theorem}
\begin{proof}
  Building on Definition~\ref{def:term model}, we define the interpretation by
  structural recursion:
  \begin{itemize}
    \item The interpretation of base types are given by the algebra for \( \mathcal{L}\)
    \item The interpretation of an exponential \( \Delta^{\Gamma}\) is
          \( \sem{\Delta}^{\sem{\Gamma}}\) where the latter is the exponential entailed by
          the raw cartesian closed structure.
    \item Contexts are taken to products as in Definition~\ref{def:term model}.
    \item The variables, operation symbols, and the laws are treated as in
          Definition~\ref{def:term model}.
    \item The last clause of the raw cartesian closed structure gives the notion
          of lambda abstraction in $C$.
  \end{itemize}
\end{proof}


\begin{definition}[Beta-eta rules]
  A raw cartesian closed algebraic theory $\mathcal{L}$ satisfies the
  \emph{$\beta$-$\eta$ rules} if for all
  \( \mathfrak{p} \in \cn_{\mathcal{L}}(\Gamma \times X,Y) \) we have the equations
  \begin{align*}
    \ev{X}{Y} \circ (\lambda_{\Gamma,X,Y}(\mathfrak{p}) \times \id_{X}) &= \mathfrak{p} && (\beta) \\
    \lambda_{Y^{X},X,Y}(\ev{X}{Y}) &= \id_{Y^{X}} && (\eta)\\
  \end{align*}
\end{definition}

These equations deserve some commentary. The beta rule says that application of
an abstracted body $\mathfrak{p}$ to the identity gives you back the body you
started with: the beta rule forces that application of lambda expressions does
nothing more than substitute for the abstracted variable. The eta rule says that
taking a function $f$, applying it to a variable $x$, then finally abstracting
over that variable $x$ is the same operation as doing nothing to $f$. We will
see the more familiar symbolic forms of these rules in the definition of the
theory of the usual calculus below.

We now define a notion more well-known outside of computing. Cartesian
closed structure endows a category with the ability to take products and
function spaces over its objects in a suitable fashion; as can be seen below,
the notion of Cartesian product and function space in the category of sets are
examples of suitable such constructions. It will turn out that this familiar
situation is equivalent to the combination of raw cartesian closed structure and
beta-eta rules.

\begin{definition}[Cartesian closed structure]
  Let \( C \) be a category. An \emph{exponential} of objects \( X \) and
  \( Y \) is an object $Y^{X}$ of \( C \) together with a morphism
  \( \epsilon : Y^{X} \times X \rightarrow Y \) such that for each object \( \Gamma \) of \( \mathfrak{C}\)
  and morphism \( p : \Gamma \times X \rightarrow Y \) there is a unique morphism
  \( \tilde{p} : \Gamma \rightarrow Y^{X} \) called the \emph{exponential transpose} such that
  \( p = \epsilon \circ (\tilde{p} \times \id_{X})\). This is a universal property: exponentials
  are unique up to unique isomorphism. A category is \emph{cartesian closed} if
  it has all finite products and all exponentials.
\end{definition}

The category \( \catset \) is the prototypical cartesian closed category whose
products are the usual cartesian products of sets and whose exponentials are
function sets: for sets $X$ and $Y$, \( Y^{X} = \{ \textrm{functions
} f \mid \textrm{dom}(f) = X \wedge \textrm{cod}(f) = Y \}\). Another good source of
example cartesian closed categories is topos theory. All elementary topoi,
including categories of presheaves, are cartesian closed
\cite{leinster_informal_2011}.

It turns out that all of these examples of cartesian closed categories can also
be characterized as raw cartesian closed categories that satisfy the beta-eta
rules.

\begin{theorem}[Finite-product category + raw CCS + beta-eta $\iff$ cartesian closed]\label{thm:rawbetaetaisccs}
  Let \( \mathfrak{C} \) be a category. Then \( \mathfrak{C}\) is cartesian
  closed if and only if \( \mathfrak{C} \) has finite products and is both raw
  cartesian closed and satisfies the beta-eta laws.
\end{theorem}

We will not repeat Taylor's proof \cite{taylor_practical_1999}, but we will say
that the proof largely comes down to these two facts: that exponential
transposes are unique and that the characterizing proprety of the transpose is
exactly the \( \beta \) rule.
% \begin{proof}
%   For the first direction, suppose that \( \mathfrak{C} \) is cartesian closed.
%   Then \( \mathfrak{C} \) has all exponential and all products. The map
%   \( \abstr{\Gamma}{X}{Y} : \mathfrak{C}[\Gamma\times X, Y] \rightarrow \mathfrak{C}[\Gamma, Y ^{X}]\)
%   required for raw cartesian closed structure is precisely given by the map
%   which takes the exponential transpose: \( p \mapsto \tilde{p}\). The naturality law
%   for the map is given by the product-hom adjunction. The \( \beta\) rule is the
%   universal property of the exponential transpose, and is hence satisfied.



%   required for raw cartesian closed structure. Its \emph{naturality law} is
%   precisely expressed by the naturality of the isomorphism witnessing the
%   adjunction. The \emph{application} or \emph{evaluation} map is given by the
%   counit \( \epsilon_{X,Y} : (- \times X) \circ ({-}^{X}) \rightarrow \id_{\mathfrak{C}}\) associated with
%   the above adjunction.
% \end{proof}

\section{An algebraic treatment of the lambda calculus}
Finally, we will present the lambda calculus as a series of algebraic theories,
each of which are identical except for the equations they admit. These theories
correspond to instances of the lambda calculus whose respective definitional
equalities identify more or fewer lambda terms. We will see that algebras of
these theories are essentially functors valued in specially structured
categories.

\begin{definition}[Algebraic theory of the lambda calculus]
  The \emph{$\alpha$-lambda calculus} is presented as the following algebraic theory called \( \mathcal{L}_{\lambda\alpha}\):
  \begin{enumerate}
    \item Sorts: We define the sorts to be the set \( \types \) given in
          Definition \ref{def:stlc_types}.
    \item Variables: The variables are defined as the collection
          \( \{ v : \tau \mid (v, \tau) \in V \times \types \} \) where $V$ is the countably
          infinite set $V$ of untyped variables as in
          Definition~\ref{def:stlc_terms}.
    \item We define the following operation symbols for each
          \(\tau_{1},\tau_{2},\tau,\tau' \in \types\):
          \begin{align*}
            t : \tau_{1} * \tau_{2} &\vdash \pi_{1}(t) : \tau_{1} \\
            t : \tau_{1} * \tau_{2} &\vdash \pi_{2}(t) : \tau_{2} \\
            [t_{1} : \tau_{1}, t_{2} : \tau_{2}] &\vdash (t_{1},t_{2}) : \tau_{1} * \tau_{2} \\
            \\
            [t : \tau' \rightarrow \tau , t' : \tau'] &\vdash t\, t' : \tau \\\\
            &\vdash () : \termob\\
          \end{align*}
          The reader will note that we have not yet added an operation symbol
          for lambda abstraction. This requires careful consideration, because
          lambda abstraction is not really an operation symbol but rather a
          family of operation symbols defined mutually with the others. For each
          term \( \Gamma, x:\tau' \vdash t : \tau \), we add a new operation symbol
         \begin{align*}
           \Gamma &\vdash (\lambda x.\, t)(\overrightarrow{\gamma}) : \tau
         \end{align*}
         where $\overrightarrow{\gamma}$ is the list of variables comprising $\Gamma$.

          Finally, the complete collection of operation symbols is defined as
          the least set closed under taking abstractions in this way and
          containing the operation symbols already mentioned above.

    \item The only equation is the $\alpha$-rule which says that terms can be
          identified up to renamings of their bound variables.
          \begin{align*}
            \alphalaw && (\alpha)
          \end{align*}

          Note that we do not include the $\beta\eta$-rules in this version.
  \end{enumerate}
\end{definition}

With this theory in hand, we first show that it is raw cartesian closed (i.e.
that it supports a reasonably coherent notion of lambda abstraction.) After
that, we will add to the theory the \( \beta\) and \(\eta \) laws. Finally, we will use
the preceding theorems to argue \emph{from $\beta$ and $\eta$} to show that the
resulting theory of the typical lambda calculus is cartesian closed.

\begin{theorem}[$\alpha$-lambda calculus is raw cartesian closed ]
  The theory \( \mathcal{L}_{\lambda\alpha}\) is raw cartesian closed
\end{theorem}
\begin{proof}
  [TODO: Fix Paul's mess, see page 20 of Angelica's notes]
  In the following we write \( [ X \Rightarrow Y ]\) for the exponential \( Y ^{X}\), for the
  sake of legibility. The exponential
  \[[{[x_{1} : X_{1},x_{2} : X_{2}\ldots, x_{j} : X_{j}]} \Rightarrow {[y_{1} : Y_{1},y_{2} : Y_{2},\ldots,y_{k} : Y_{k}]}]\]
  is the context \( [f_{1} : F_{1} ,f_{2} : F_{2}, \ldots, f_{k} : F_{k}]\) where the
  \( f_{i}\) are new variables
  and \[ F_{i} = X_{1} \Rightarrow [X_{2} \Rightarrow \cdots [X_{j} \Rightarrow Y_{i}] \cdots] \] Finally, we define
  \begin{align*}
    \textrm{ev}_{\overrightarrow{X},\overrightarrow{Y}} &= [(\cdots(f_{1}(x_{1})x_{2}) \cdots x_{j}) / y_{1}] \circ \cdots [(\cdots(f_{k}(x_{1})x_{2}) \cdots x_{j}) / y_{k}] \\
    \lambda_{\Gamma, \overrightarrow{X}, \overrightarrow{Y}} [\overrightarrow{p} / \overrightarrow{y}] &= [(\lambda x_{1}.\,(\lambda x_{2}. \ldots (\lambda x_{k} .\, p_{1}) \ldots ))/f_{1}] \circ  \cdots [(\lambda x_{1}.\,(\lambda x_{2}.\, \ldots (\lambda x_{k} .\, p_{k}) \ldots ))/f_{k}] \\
  \end{align*}

  Naturality with respect to weakening and single substitution follows from the
  fact that substitution for (or weakening by) a variable $x$ commutes with
  abstraction of a distinct variable $y$: for any terms $p$ and $c$, we have
  \( [c/y]^{*} (\lambda x.\, p ) \equiv \lambda x.\, ([c/y]^{*}p)\). The same situation holds for
  weakening. The full naturality law follows from this and the fact that single
  substitution and weakening are the generating morphisms of the syntactic
  category.
\end{proof}

\begin{definition}[Lambda calculus]\label{def:alpha_beta_eta_theory}
  The lambda calculus, or the $\alpha\beta\eta$-lambda calculus is defined as the algebraic
  theory of the $\alpha$-lambda calculus enriched with the following additional
  equational laws:
  \begin{align*}
    \betalaw && (\beta)\\
    \etalaw && (\eta)\\
  \end{align*}

  We write \( \mathcal{L}_{\lambda\alpha\beta\eta}\) or simply \( \lambda \) for the new theory, and
  \( \cl \) for its classifying category.
\end{definition}

\begin{definition}[Lambda algebra]
  By a \emph{lambda algebra}, we mean an algebra for the theory
  \( \mathcal{L}_{\lambda\alpha\beta\eta}\).
\end{definition}

The following results quickly follow the definition of the theory of the lambda
calculus and the work we did in Chapter~\ref{chapter:functorial_semantics}.
\begin{theorem}
  The lambda calculus is a raw cartesian closed algebraic theory with beta-eta.
\end{theorem}

\begin{theorem}
  The syntactic category \( \cl \) of the theory \( \mathcal{L}_{\lambda\alpha\beta\eta} \) is
  cartesian closed and has a lambda algebra satisfying the following universal
  property: if $C$ is a cartesian closed category with a lambda algebra then
  there is a unique functor \( \sem{-} : \cl \rightarrow C \) that preserves the cartesian
  closed structure and the lambda algebra.
\end{theorem}
\begin{proof}
  Cartesian closure follows immediately from the previous result and
  Theorem~\ref{thm:rawbetaetaisccs}. The rest is given essentially as in
  Theorem~\ref{thm:classifying alg theory}, except that we must handle the new
  exponentials with more care. Theorem~\ref{thm:rawccsinterp} provides the
  requisite care and extends the functor defined in Definition~\ref{def:term
    model} to provide one which preserves exponentials as required.
\end{proof}

This final result will prove important in Chapter~\ref{chapter:gluing}.

\chapter{Normalization by gluing}\label{chapter:gluing}
\epigraph{You, you were like glue\\
holding each of us together\\
I slept through July\\
while you made lines in the heather}{Fleet Foxes, ``Lorelai''}

This chapter will consider the normalization problem for the simply typed lambda
calculus using the technology we've developed so far. Normalization comes in
both weak and strong flavors, but both are properties of a \emph{reduction}
relation, say, \( - \rightarrow = \) defined over the terms of a theory. By a \emph{normal
  form} we mean a term $t$ for which there is no other $t'$ such that
\( t \rightarrow t' \). Writing \( - \rightarrow^{*}\, = \) for the least transitive, reflexive
closure of this relation, we say the reduction system enjoys \emph{weak
  normalization} if for any well-typed term \( e \), there exists a normal form
\( n \) such that \( e \red n\). A reduction system enjoying \emph{Strong
  normalization} is one for which \emph{every} reduction sequence ends in a
normal term. \emph{Metatheorems} of this kind tend to resist standard techniques
like straightforward induction over the term structure of the theory under
consideration. Instead, metatheoreticians resort to \emph{occult} techniques
like logical relations. The method of logical relations is, broadly speaking,
opaque even to experienced practitioners. In short, a logical relation is a
relation of terms indexed by the types of the theory whose inclusion criteria in
some vague sense mirror the type structure of the theory. Such logical relations
are easy to work with in simple settings like that of the closed normalization
(which asks whether closed terms all have a normal form) problem for the
simply-typed lambda calculus (see \cite{pierce_types_2002}) but logical
relations are well known to become devilishly complicated when working with
theories whose type structure is more complicated [TODO: is this legit]. Still
more complication arise when attempting to apply logical relations to more
complicated metatheoretic problems such as the \emph{open normalization} problem
for the simply typed lambda calculus. Open normalization generalizes the closed
normalization problem to terms with free variables. Such problems demand that
the relation be indexed not just by sorts, but also by the elements of some
poset \cite{harper_kripke-style_nodate}. That poset might be, as in the case of
this problem, the poset of contexts \( \Gamma \) ordered by weakenings \( \hat{x}\).
Such a relation indexed by a poset is called a Kripke relation if it
additionally satisfies a monotonicity condition. In the example of the previous
sentence, these conditions amount to saying that a term which has a normal form
when considered as a term under the context \( \Gamma \) should also have a normal
form when considered as a term under any extended context \( \Gamma, x', \dots, z'\).
The \emph{Artin gluing} construction, torn from the topos theorist's cookbook,
is a more transparent encoding of the mechanics of Kripke logical relations.
Where the method of Kripke logical relations is ad-hoc and mysterious, gluing
regularizes the thought involved and delivers more conceptual proofs and theory.
The gluing construction is perhaps overshadowed in fame by one of its instances:
The \emph{scone} or \emph{Sierpinski cone} is well-known outside of type
theoretic circles for its use in proving results similar to closed
normalization. Because we are interested in open normalization, the scone
construction is not suited to the problem at hand. The reader interested in the
broader context is encouraged to read on in Section 22 of Part II of Lambek and
Scott's \emph{Introduction to higher order categorical logic}
\cite{lambek_introduction_1989}.

\section{The comma construction and friends}
This section introduces a general construction that will, among other things,
allow us to define the gluing construction from which this chapter gets its
name. The loose idea of the comma is to glob some extra data to the objects of a
category in a way that supports a well-defined notion of an
object-with-extra-data-morphism which preserves the attached data. This
intuition perhaps underlies the name for the gluing construction. Our specific
use of the gluing construction will involve gluing presheaves of syntactic terms
(as you would write them down on paper) together with presheaves of semantic
terms (which are \emph{substitutions}.) That is, the extra data we glob on is
the semantics of terms, and the notion of extra-data-preserving morphism is a
pair of a syntactic transformation and a substitution which commute with the
semantic interpretations of the syntax.

\begin{definition}[Comma category]
  Let $E,D,C$ be categories and $F: D \rightarrow C \leftarrow E : G$ be a pair of functors sharing
  their codomain $C$. The comma category \( F \downarrow G \) has as its
  \begin{enumerate}
    \item Objects: triples \( (d : D, Fd \xrightarrow{f} Ge, e : E) \)
    \item Morphisms: arrows $(h,k) : (d, f, e) \rightarrow (d', f', e')$ are pairs of
          $D$ and $E$-morphisms \(h : d \rightarrow d', k : e \rightarrow e'\) making the following
          diagram commute:
          \[
            \begin{tikzcd}
              Fd \arrow{r}{Fh} \arrow{d}[swap]{f} & Fd' \arrow{d}{f'} \\
              Ge \arrow{r}[swap]{Gk} & Ge'\\
            \end{tikzcd}
          \]
  \end{enumerate}
\end{definition}

\subsection{An easy comma: the category of renamings}
As a warm-up example, we present the \emph{category of renamings} which can be
nicely expressed as an instance of the comma. In elementary terms, the category
has the same objects as the syntactic category (i.e., contexts) but the
morphisms are a restricted class of substitutions, which are only allowed to
substitute for a variable \emph{by a variable of the same type} or weaken by a
variable. Thus the category of renamings is something like a less proof-relevant
version of the category of contexts and substitutions in the following sense: if
there exists a substitution relating two contexts in syntactic category, then
there exists a renaming relating the same contexts. The upshot is that renamings
allow us to track changes in context \emph{due to a substitution} without
actually working with substitutions directly. Working over \( \cl \) is
problematic because substitutions (and thus the terms they represent) are
identified up to computational equality, whereas we would like to distinguish
between terms at differing stages of reduction (e.g. distinguishing between a
term and its normal form.) We will understand this problem in greater detail in
Remark~\ref{rmk:syntactic-cat-bad}. Concisely, the category of renamings allows
us to define the presheaves we need while not losing track of how contexts
evolve by substitution\footnote{The reader might complain now, as I did, that if
  we only care about tracking how contexts evolve by substitutionsn then we
  should simply work with the category of context \emph{weakenings}. The problem
  here is that the category of weakenings lacks finite products, which precludes
  the use of a trick (which we will soon see \emph{does} work in the case of the
  category of renamings) for explicating the binding structure of its category
  of presheaves}. We present the category abstractly as a comma and at the
same time spell out concretely its morphisms in terms of the substitutions of
the syntactic category:
\begin{definition}[Category of renamings]
  Recall from Chapter~\ref{chapter:stlc} that \( V \) is some countably infinite
  set of variables and \( \types \) is the set of all types in the simply typed
  lambda calculus generated from a set of base types \( T \). Let \( \fin \) be
  the category whose objects are finite subsets of \( V \) and whose morphisms
  are all functions between the underlying sets. Let
  \( \mathbb{T} : \fin \rightarrow \catset \) be the functor which is constantly
  \( \types \) on objects and constantly \( \id_{\types}\) on morphisms. Let
  \( U : \fin \rightarrow \catset \) be the forgetful functor taking finite variable sets
  to their underlying sets and functions to functions. Now by the \emph{category
    of renamings} we mean the \emph{opposite category} of the comma
  \( U \downarrow \mathbb{T} \) whose
  \begin{itemize}
    \item Objects are \emph{pairs} \( (V : \fin, \Gamma : V \rightarrow \types) \), i.e.,
    finite variable list together with an assignments of types to a each
    variable. Note that we elide the final entry of the triple of the
    comma objects, since it adds no extra information. These objects are
    precisely the contexts of the familiar classifying category.
    \item Morphisms of contexts \( (V , \Gamma) \rightarrow (V', \Gamma')\) are functions
    \( \rho : V \rightarrow V' \) making the following diagram commute:
    \[
      \begin{tikzcd}
        V \arrow{d}[swap]{\Gamma} \arrow{r}{\rho} & V' \arrow{d}{\Gamma'} \\
        \types \arrow{r}[swap]{\id_{\types}} & \types\\
      \end{tikzcd}
    \]
          The reason the comma morphisms are single functions and not pairs is
          that the second function would not communicate any data, it would just
          be taken by \( \mathbb{T}\) to the identity no matter what it is. We
          now unpack what this means. The functions \( \rho \) are
          \emph{type-preserving renamings}: for each variable \( x \in V\), we
          have that \( \Gamma'(\rho x) = \Gamma(x)\). In particular, this restricts \( \rho \)
          to the following classes of morphisms in the classifying category:
          substitutions of variables for variables of the same type, context
          extension with new variables, and all compositions of these. The
          equations are given by the substitution lemma, as in the syntactic
          category.
  \end{itemize}

  We write \( \ren = (U \downarrow \mathbb{T})^{\textrm{op}}\) for the category of
  renamings.
\end{definition}

\begin{remark}\label{rmk:reninclusioncl}
  There is an obvious inclusion \( \iota : \ren \rightarrow \cl \) which takes contexts to
  contexts and casts renamings as change-of-variable substitutions. When going
  between \( \ren \) and \( \cl \), we will take the liberty to implicitly
  insert this coercion as needed without further warning. It turns out that this
  inclusion is \emph{faithful} and thus witnesses \( \ren \) as a
  \emph{subcategory} of the syntactic category.
\end{remark}

\subsection{Variable-arity Kripke relations}
In order to motivate the next example of a comma construction, we will define
\emph{variable-arity Kripke relations}. Variable-arity Kripke relations are,
loosely speaking, families of relations parameterized by the objects of some
\emph{category} (c.f. the Kripke logical relations mentioned in the
introduction, which vary over the objects of a \emph{poset}) for which inclusion
in the relations respects, in a sense to be defined, the morphisms of that
category.
\begin{definition}[$C$-Kripke relation]
  Let $C$ and $S$ be categories. For a functor \( \varsigma : C \rightarrow S \), a
  \emph{$C$-Kripke relation} $R$ of \emph{arity} $\varsigma$ over an object \( A \) of
  \( S \) is a family of sets \( \{ R(c) \subseteq S[\varsigma(c), A]\}_{c \in C}\) satisfying the
  following \emph{monotonicity} condition:

  For each morphism \( \rho : c' \rightarrow c \) in \( C \) and every \( a : \varsigma(c) \rightarrow A \) in
  $R(c)$, the map \( a \circ \varsigma(\rho) : \varsigma(c') \rightarrow A\) is in $R(c')$.
\end{definition}

In order to disentangle this admittedly abstract definition, we specialize to
the case of \( \ren\)-Kripke relations which are perhaps more graspable.

\begin{example}[A class of \( \ren \)-Kripke relations over \( \cl \)]
  Consider the inclusion functor \( \iota : \ren \rightarrow \cl \). Following the definition
  above, we can define a \( \ren\)-Kripke relation $R$ of \emph{arity} $\iota$ over
  any type\footnote{i.e., a singleton context} \( \tau \) of \( \cl \) by producing
  a family of sets \( \{ R(\Gamma) \subseteq \cl[\Gamma, \tau]\}_{\Gamma \in \ren}\), namely a selection of
  terms of type \( \tau \) in each context \( \Gamma \), along with a proof of the
  monotonicity condition: for each \emph{renaming} \( \rho : \Gamma' \rightarrow \Gamma \) in
  \( \ren \) and every \emph{term} \( t : \Gamma \rightarrow \tau \) in $R(\Gamma)$, the map
  \( t \circ \iota(\rho) : \Gamma' \rightarrow \tau\) is in $R(\Gamma')$. This example demonstrates that we can
  think of Kripke relations as families of unary relations for which inclusion
  in any of the relations in the family, say $R(\Gamma)$, those unary relations of
  terms which can be \emph{lifted} along a renaming to yield a proof of
  inclusion in the relation at any other context \( \Gamma' \) enjoying a renaming
  into \( \Gamma \).
\end{example}

Even with a more concrete example, it can be hard to understand what the utility
of a construction like this is without knowing how to map between such
$C$-Kripke relations of a given arity. In fact, we will not say explicitly what
a $C$-Kripke morphism is at all. Instead we turn directly to the work of
defining the \emph{gluing category} which turns out to generalize $C$-Kripke
relations to \emph{proof relevant Kripke logical predicates}. Indeed, there is a
a category of $C$-Kripke relations whose objects are defined as above; that
category can be found to be a full subcategory of the gluing category which we
introduce next. We refer the reader to \cite{fiore_semantic_2002} for more
commentary on this result and for a more detailed treatment of Kripke relations
in general.

\subsection{A harder example: the gluing category; or, the category of proof-relevant Ren-Kripke relations over types}
With the category of renamings in hand, we can now define \emph{as a comma} the
gluing category. To define it, we first need to define a functor along which to
take the comma. In a loose sense that will be explained in due course, this
functor defines \( \ren \)-presheaves of \emph{open} (semantic) terms.
\subsubsection{The relative hom functor}
Every functor \( \varsigma : \mathcal{R} \rightarrow \mathcal{S} \) induces the following
situation:

% https://q.uiver.app/?q=WzAsNSxbMCwwLCJcXG1hdGhjYWx7Un0iXSxbMiwwLCJcXG1hdGhmcmFre1NldH1ee1xcbWF0aGNhbHtSfV5cXHRleHRybXtvcH19Il0sWzAsMSwiXFxtYXRoY2Fse1N9Il0sWzIsMSwiXFxtYXRoZnJha3tTZXR9XntcXG1hdGhjYWx7U31eXFx0ZXh0cm17b3B9fSJdLFsxLDBdLFswLDIsIlxcdmFyc2lnbWEiLDJdLFsyLDMsIuOCiCIsMix7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoiYm90dG9tIn19fV0sWzIsMSwiXFxicmFrZXR7XFx2YXJzaWdtYX0iLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XSxbMywxLCJcXHZhcnNpZ21hXioiLDJdXQ==
\[\begin{tikzcd}
	{\mathcal{R}} & {} & {\mathfrak{Set}^{\mathcal{R}^\textrm{op}}} \\
	{\mathcal{S}} && {\mathfrak{Set}^{\mathcal{S}^\textrm{op}}}
	\arrow["\varsigma"', from=1-1, to=2-1]
	\arrow["{よ}"', hook', from=2-1, to=2-3]
	\arrow["{\braket{\varsigma}}", dashed, from=2-1, to=1-3]
	\arrow["{\varsigma^*}"', from=2-3, to=1-3]
\end{tikzcd}\]

That is, we get a functor
\[
  \braket{\varsigma} : \mathcal{S} \rightarrow \mathfrak{Set}^{\mathcal{R}^{\textrm{op}}}
\]
by adjusting the Yoneda embedding into the category of $\mathcal{S}$-presheaves.
Specializing to the case of the inclusion \( \iota : \ren \rightarrow \cl \) of
Remark~\ref{rmk:reninclusioncl} gives us a functor
\begin{align*}
  \mathfrak{Tm} : \cl &\rightarrow \renhat \\
  \Delta &\mapsto \cl(\iota(-), \Delta)\\
\end{align*}

where \( \renhat \) is the category \( \mathfrak{Set}^{\ren^{\textrm{op}}} \).
This functor can be construed as taking a syntactic context to a presheaf of
open terms. This is a confusing idea at first, and it helps to consider the
simple cases to understand it. Consider any singleton context \( \tau : \cl \).
$\tm$ takes $\tau$ to the presheaf \( \cl(-, \tau)\) which takes any renaming context
\( \Gamma \) to \( \cl(\Gamma, \tau)\). Recalling the definition of the syntactic category
and its generating morphisms, the latter set comprises the terms of type \( \tau \)
closed under $\Gamma$, represented as single substitutions \( [t/x] : \Gamma \rightarrow \tau \).
Generalizing to multivariable target contexts \( \Delta \) gives presheaves of
\emph{lists} of open terms of the types in $\Delta$.

It turns out that the category of \( \ren\) presheaves shares the cartesian
closed structure of \( \cl \) and that \( \tm \) preserve this structure.
\begin{remark}\label{rmk:tm-cartesian-closed}
  Any category of presheaves, including \(\renhat\), is cartesian closed.
  Furthermore, the relative hom functor is a \emph{cartesian closed functor},
  meaning that for contexts \( \Gamma \) and \( \Delta \) we have the following
  isomorphisms of presheaves:
  \begin{enumerate}
    \item \(  \tm(\Gamma) \times \tm(\Delta) \cong \tm(\Gamma \times \Delta) \)
    \item \( {\tm(\Gamma)}^{\tm(\Delta)} \cong \tm(\Gamma^{\Delta}) \)
  \end{enumerate}

  We write \[ \tm(\Gamma \times \Delta) \xrightarrow{i_{\pi}} \tm(\Gamma) \times \tm(\Delta) \] for the first
  isomorphism and \( \tm(\Gamma)^{\tm(\Delta)} \xrightarrow{i_{e}} \tm(\Gamma^{\Delta} )\) for the
  second.

  The reader should consult Chapter 8 of Awodey's \emph{Category Theory}
  \cite{awodey_category_2010} for more information about these results.
\end{remark}

\subsubsection{Gluing syntax to semantics along the relative hom functor}
We at last define the \emph{gluing category} as the comma of the category of
renamings along the relative hom functor \( \tm \) just defined.

\begin{definition}[The gluing category]
  The gluing category \( \gl \) is defined as the comma \( \renhat \downarrow \tm \).
  Explicitly, its objects are triples
  \( (R : \renhat, q : R \Rightarrow \tm(\Delta), \Delta : \cl) \). The objects of the gluing
  category are \emph{proof relevant Kripke logical predicates}, in a sense that
  will be more clear after a digression to follow. Following the definition of
  the comma construction, the morphisms \( (R, q, \Delta) \rightarrow (R', q', \Delta') \) are pairs
  $(d : R \rightarrow R', \delta: \cl[\Delta', \Delta])$ are pairs of a $\renhat$ natural transformation
  and a substitution making the following diagram commute:
  % https://q.uiver.app/?q=WzAsNCxbMCwwLCJEIl0sWzIsMCwiRCciXSxbMCwyLCJcXG1hdGhmcmFre1RtfShcXERlbHRhKSJdLFsyLDIsIlxcbWF0aGZyYWt7VG19KFxcRGVsdGEnKSJdLFswLDEsImQiXSxbMiwzLCJcXG1hdGhmcmFre1RtfShcXGRlbHRhKSJdLFswLDIsInFfe1xcRGVsdGF9IiwyXSxbMSwzLCJxX3tcXERlbHRhJ30iXV0=
  \[\begin{tikzcd}
      R && {R'} \\
      \\
      {\mathfrak{Tm}(\Delta)} && {\mathfrak{Tm}(\Delta')}
      \arrow["d", from=1-1, to=1-3]
      \arrow["{\mathfrak{Tm}(\delta)}", from=3-1, to=3-3]
      \arrow["{q}"', from=1-1, to=3-1]
      \arrow["{q'}", from=1-3, to=3-3]
    \end{tikzcd}\]

  We will refer to objects and morphisms in the gluing category as \emph{glued
    objects} and \emph{glued morphisms} respectively. We do not have a great
  name for the maps \( q : R \Rightarrow \tm(\Delta) \) that form part of the data of a glued
  object. In practice, these maps will often be the semantic interpretation of
  syntactic terms in \( \cl \), so for glued objects in general we will call
  \( q \) the \emph{interpretation} even if $q$ is not necessarily the usual
  semantic interpretation.
\end{definition}

We can get a foothold understanding of the objects of the gluing category by
considering them as a presheaf together with, for each \( \Gamma \), an
interpretation \( q_{\Gamma} \) of the sets of the presheaf into the set of semantic
terms \( \tm(\Delta)(\Gamma)\), such that the interpretation commutes with renamings in a
way that will be further explained in just a bit.

Holding off our desire to further understand the objects, we can already
understand the morphisms. A morphism \( (d, \delta) \) is a natural transformation of
\(\ren \)-presheaves glued together with a substitution, such that performing
on \( R \) the transformation \( d \) and then looking at the \emph{semantics}
of the resultant presheaf \( R' \) by interpreting along \( q' \) is the same as
interpreting the semantics of the original presheaf \( R \) along \( q \) and
then performing a semantic transformation by substituting with \( \delta \). This
intuition will become more clear when we define glued objects over
\emph{presheaves of syntax} for which the interpretation \( q : R \rightarrow \tm(\Delta)\) is
the actual \emph{interpretation of syntax} in the classifying category.

We can now better understand the objects by understanding how the gluing
category subsumes the notion of variable-arity Kripke relations.

\subsubsection{The subcategory of (ordinary) variable-arity Kripke relations}
We can recover ordinary, proof-\emph{irrelevant} variable-arity Kripke relations
as a subcategory of the gluing category. In particular, ordinary variable-arity
Kripke relations arise as those objects
\( (D : \renhat, q : D \Longrightarrow \tm (\Delta), \Delta : \cl) \) of the gluing category whose
quotient map $q$ is a component-wise monomorphism; i.e., for each
\( \Gamma \in \ren \), we have that \( q_{\Gamma} : D(\Gamma) \rightarrowtail \tm (\Delta)(\Gamma) \) is a monomorphism.
Here's why: recalling the definition of $\ren$-Kripke relations over $\tau \in \cl$,
we need to find in these data a $\ren$-indexed family \( \{ R_{\Gamma}\}_{\Gamma \in \ren}\)
of sets of $\cl$-morphisms into \( \tau \) subject to the following monotonicity
condition: for any renaming \( \rho : \Gamma' \rightarrow \Gamma \), if \( t : \Gamma \rightarrow \tau \) is in
\( R_{\Gamma}\), then we have that \( t \circ \rho : \Gamma' \rightarrow \tau \) is in \( R_{\Gamma'}\). Looking
again to our proposed Kripke predicate objects of the gluing category, we can
see that the presheaf \( R \) together with the natural mono \( q \) define for
each \( \Gamma \) a subset of the substitutions \( \Gamma \rightarrow \tau \).
It is tempting to dismiss the naturality of $q$ as bureaucracy, but naturality
turns out to be essential to recovering the monotonicity condition. To see this,
we need to look at the naturality diagram of \( q \):

  \[\begin{tikzcd}
      {R (\Gamma)} &&& {\tm(\Delta) (\Gamma)} & t \\
      \\
      {R (\Gamma')} &&& {\tm(\Delta) (\Gamma')} & {t \circ \rho}
      \arrow["{q_{\Gamma}}", from=1-1, to=1-4, rightarrowtail]
      \arrow["{q_{\Gamma'}}", from=3-1, to=3-4, rightarrowtail]
      \arrow["{R (\rho)}"', from=1-1, to=3-1]
      \arrow["{\tm(\Delta) (\rho)}", from=1-4, to=3-4]
      \arrow[from=1-5, to=3-5, mapsto]
    \end{tikzcd}\]

  As mentioned before, because they are monos we may identify the component
  morphisms with their images. We write \( |q_{\Gamma}| \subseteq \tm(\Delta)(\Gamma) \) for the image,
  for each \( \Gamma \). Now what this diagram says is that for any
  \( q_{\Gamma }(r \in R(\Gamma)) = t \in |q_{\Gamma}|\), we have that
  \( t \circ \rho = q_{\Gamma'}(R(\rho)(r)) \in |q_{\Gamma'}|\). This is precisely the monotonicity
  condition for $\ren$-Kripke relations over \( \Delta \): containment in each
  predicate is functorial with respect to renaming \emph{up to renaming}.

  The perspective gained above allows for a more conceptual understanding of the
  objects in the gluing category: the presheaves $R$ define context-indexed
  families of \emph{witnesses} to the inclusion of terms in the predicate, and
  $q$ is a quotient map that forgets the difference between distinct witnesses
  \( w, w' \in R(\Gamma) \) and whose image just records those terms
  \( t \in \tm (\Delta)(\Gamma)\) taken to be in the predicate; insofar as $q$ is a mono,
  these objects are exactly variable-arity Kripke relations over the context
  \( \Delta \).

\section{Presheaves of stratified neutral and normal syntax}
In this section, we will enlist a motley crew of \emph{presheaves of syntax}
which more-or-less represent certain classes of terms in the lambda calculus.
These presheaves are defined over $\ren$ rather than $\cl$ for reasons that will
be detailed in Remark~\ref{rmk:syntactic-cat-bad}. We will ultimately define
lambda algebras over these presheaves, for which we require some understanding
of how to represent variables in $\renhat$ and how exponentiation in $\renhat$
corresponds to lambda abstraction.
\subsection{Variables and binding in Renhat}
\begin{definition}[Variable presheaf]\label{def:varpsh}
  We can define a presheaf of \emph{typed variables} in $\renhat$ with the Yoneda embedding on $\ren$:
  \[
    \mathfrak{V}_{\tau} = \yoneda \tau = \ren(-, \tau)
  \]

  With that definition, we have \( \varpsh(\Gamma) = \ren(\Gamma,\tau) \) where the
  right-hand side is comprised of renamings \( \Gamma \rightarrow [x:\tau]\) which are
  \emph{functions} \( \rho : \dom([x:\tau]) \rightarrow \dom(\Gamma)\) such that
  \( \Gamma(\rho(x)) = [x : \tau](x) = \tau\). That is, the \( \rho \) are functions selecting a
  variable of type $\tau$ in \( \Gamma \). More concisely, we have an isomorphism
  \( \varpsh(\Gamma) \cong \{ x \mid (x:\tau) \in \Gamma \}\) by which we allow ourselves to consider
  this a \emph{presheaf of syntax}.
\end{definition}

The Yoneda lemma delivers the following insight about a special class of
exponential objects in \( \renhat \). Let \( \mathfrak{P} : \renhat \).
Exponentiation by a representable/variable presheaf, \( \varpsh = \yoneda \tau\)
gives

\begin{align*}
  \mathfrak{P}^{\mathfrak{V}_{\Delta}}(\Gamma)  &= \mathfrak{P}^{\yoneda \Delta}(\Gamma) \\
                                    &= \renhat[\yoneda \Gamma \times \yoneda \Delta, \mathfrak{P}] && (2)\\
                                    &\cong \renhat[\yoneda (\Gamma \times \Delta)] && (\textrm{since the Yoneda embedding is cartesian closed}) \\
                                    &\cong \mathfrak{P}(\Gamma\times\Delta) && (\textrm{by the Yoneda lemma})\\
\end{align*}

Where step (2) follows from the definition of the exponentials in the category
of presheaves, c.f. page 46 of \cite{mac_lane_sheaves_1992}.

The presheaves of typed variables together with the simplified view of
variable-exponentiation in $\renhat$ will allow us to more easily define
algebras for a new algebraic theory \( \NN \) of stratified \emph{neutrals and
  normals}, which allows for a more fine-grained discussion of normal terms.

\subsection{Stratifying neutral and normal terms}
We introduce a new type system over the syntax and type structure of the lambda
calculus as defined in Chapter~\ref{chapter:stlc}. This new type system will
distinguish between \emph{neutral terms}, a special class of \emph{normal terms}
which are in some sense beta-redexes whose reduction is \emph{blocked} by a
variable in the head term, and all other normal terms. In some sense,
\emph{neutral terms} can be regarded as those terms which are normal only
because they are stuck waiting on the value of a variable.

\begin{definition}[Neutral and normal judgments]\label{def:neut-norm-rules}
  \begin{mathpar}
    \inferrule*[Right={ \( (x:\tau) \in \Gamma \) }]{ }{ \Gamma \vdash_\neu x : \tau }\\
    \inferrule{ \Gamma \vdash_\neu M : \tau_1 * \tau_2}{\Gamma \vdash_\neu \pi_i M : \tau_i} \and \inferrule{ \Gamma \vdash_\neu t_{1} : \tau' \rightarrow \tau  \\  \Gamma \vdash_\nf t_{2} : \tau' }{ \Gamma \vdash_\neu t_{1} t_{2} : \tau } \\

    \inferrule{}{ \Gamma \vdash_\nf () : \termob } \and \inferrule{\Gamma \vdash_\nf N_i : \tau_i}{\Gamma \vdash_\nf (N_1, N_2) : \tau_1 * \tau_2} \and \inferrule{\Gamma, x : \tau \vdash_\nf b : \tau' }{\Gamma \vdash_\nf \abstr{x}{\tau}{b} : \tau \rightarrow \tau'} \\
    \inferrule*[Right={ ($\theta \in T$ \textrm{a base type}) }]{\Gamma \vdash_\neu t : \theta}{\Gamma \vdash_\nf t : \theta} \\
  \end{mathpar}
\end{definition}

\begin{definition}[Algebraic theory of neutrals and normals]\label{def:theory_neut_norm}
  The judgments above suggest the definition of a theory with a richer sort
  structure than that of the theory \( \mathcal{L}_{\lambda\alpha\beta\eta} \) defined back in
  Chapter \ref{chapter:stlc}. In particular, the new sort structure will feature
  both a neutral sort and a normal sort for each type \( \tau \), allowing us to
  define algebras that distinguish between these.

  We define \( \NN \) as the algebraic theory corresponding (c.f.
  Theorem~\ref{thm:canonical_elementary_language}) to the category with the
  following objects and generating morphisms:
  \begin{enumerate}
    \item The objects are the collection generated by taking (syntactic)
          products and exponentials over the collection
          \( \Sigma = \{ \mathcal{M}_\tau \mid \tau \in \types \} \cup \{ \mathcal{N}_\tau \mid \tau \in \types \} \cup \{ \mathcal{V}_\tau \mid \tau \in \types \} \)
    \item Generating morphisms, for each \( \tau, \tau' \in \types \):
    \begin{align*}
      \textrm{var}_\tau &: \mathcal{V}_{\tau} \rightarrow \mathcal{M}_{\tau} \\
      \textrm{fst}_{\tau}^{\tau'} &: \mathcal{M}_{\tau \times \tau'} \rightarrow \mathcal{M}_{\tau}\\
      \textrm{snd}_{\tau}^{\tau'} &: \mathcal{M}_{\tau' \times \tau} \rightarrow \mathcal{M}_{\tau}\\
      \textrm{app}_{\tau}^{\tau'} &: \mathcal{M}_{\tau' \rightarrow \tau} \times \mathcal{N}_{\tau'} \rightarrow \mathcal{M}_{\tau}\\
      \textrm{incl}_{\theta} &: M_{\theta} \rightarrow N_{\theta} \\
       \textrm{unit} &: \termob \rightarrow \mathcal{N}_{\termob} \\
       \textrm{pair}_{\tau}^{\tau'} &: \mathcal{N}_{\tau} \rightarrow \mathcal{N}_{\tau'} \rightarrow \mathcal{N}_{\tau \times \tau'} \\
       \textrm{abs}_{\tau \rightarrow \tau'} &: {\mathcal{N}_{\tau'}}^{\mathcal{V}_{\tau}} \rightarrow \mathcal{N}_{\tau \rightarrow \tau'} \\
    \end{align*}
    \item The laws are the usual $\alpha-$, $\beta-$, and $\eta-$rules.
  \end{enumerate}
  Note that the domain of the unit operation symbol is the nullary product of
  sorts.
\end{definition}

\begin{remark}\label{rmk:upgrade_to_stratified}
  Any \( \renhat-\) lambda algebra over the family
  \( \{ \mathfrak{X}_{\tau} \}_{\tau \in \types}\) gives rise to an algebra for the
  algebraic theory \( \NN \) over the family \(\{ \mathfrak{A}_\tau \}_{\tau\in\types}\)
  by setting
  \begin{align*}
    \mathfrak{A}_{\mathcal{M}_{\tau}} &= \mathfrak{X}_{\tau} \\
    \mathfrak{A}_{\mathcal{N}_{\tau}} &= \mathfrak{X}_{\tau} \\
    \mathfrak{A}_{\mathcal{V}_{\tau}} &= \varpsh \\
  \end{align*}
  and setting the operation symbols as in the lambda algebra.
\end{remark}

\begin{remark}[A lambda algebra of open substitutions]\label{rmk:tm-lam-alg}
  By Theorem~\ref{thm:classifying alg theory}, the syntactic category \( \cl \)
  of the \( \alpha\beta\eta\)-lambda calculus has a lambda algebra, and an induced
  interpretation of terms \( \sem{-} \).

  The morphisms
  \begin{align*}
    \pi_{1} &: \sem{\tau} \times \sem{\tau'} \rightarrow \sem{\tau} \\
    \pi_{2} &: \sem{\tau} \times \sem{\tau'} \rightarrow \sem{\tau'} \\
    \epsilon     &: \sem{\tau'}^{\sem{\tau}} \times \sem{\tau} \rightarrow \sem{\tau'} \\
  \end{align*}

  in the syntactic category can be lifted by \( \tm \) to \( \renhat \) to
  provide the operations for a lambda algebra over the family
  \( \{ \tm(\tau) \}_{\tau \in \types} \)

  The operations are given as follows:
  \begin{align*}
    \varpsh &\xrightarrow{\sem{-}} \tm(\tau) \\
    \termob &\xrightarrow{i_{\termob}} \tm(\termob) \\
    \tm(\tau*\tau') &\xrightarrow{\tm(\pi_{1})} \tm(\tau) \\
    \tm(\tau*\tau') &\xrightarrow{\tm(\pi_{2})} \tm(\tau') \\
    \tm(\tau) \times \tm(\tau') &\xrightarrow{i_{\pi}} \tm(\tau*\tau') \\
    \tm({\tau'}^{\tau}) \times \tm(\tau) \xrightarrow{i_{\pi}} &\tm(({\tau'})^{\tau} \times \tau) \xrightarrow{\tm(\epsilon)} \tm(\tau') \\
    \tm(\tau')^{\varpsh} &\xrightarrow{\cong} \tm((\tau')^{\tau})
  \end{align*}
  where \( i_\termob \) and \( i_{\pi}\) are isomorphisms induced by \( \tm \)'s
  status as a Cartesian closed functor. We write \( \tm \) for this algebra.
\end{remark}

\begin{remark}\label{rmk:tm-nn-alg}
  The lambda algebra just defined induces, by
  Remark~\ref{rmk:upgrade_to_stratified}, an \( \NN \)-algebra over \( \tm \) with the
  assignment of sorts
  \begin{align*}
    \mathcal{V}_{\tau} &\mapsto \varpsh \\
    \mathcal{M}_{\tau} &\mapsto \tm(\tau) \\
    \mathcal{N}_{\tau} &\mapsto \tm(\tau) \\
  \end{align*}
  and letting the operations be exactly those of the lambda algebra: since the
  \( \mathcal{M}_{\tau} = \mathcal{N}_{\tau} = \tm(\tau)\), the signatures of the
  required operations are exactly the same. We write \( (\tm, \tm) \) for this
  induced algebra.
\end{remark}

\subsection{Presheaves of syntax over the category of renamings}
\begin{definition}[A presheaf of open syntactic terms]
  For each type $\tau \in \types$, define
  \[
    \mathfrak{L}_{\tau} = \{ t \mid \Gamma \vdash t : \tau \}_{\Gamma \in \ren}
  \]
  Together with the \emph{renaming action}, defined for each $\rho : \Gamma' \rightarrow \Gamma $ as
  \begin{align*}
    \rho^{*} : \{ t \mid \Gamma \vdash t : \tau \} &\rightarrow \{ t \mid \Gamma' \vdash t : \tau \} \\
                             t &\mapsto \rho^{*}t
  \end{align*}
  where \( \rho^{*}t\) is the result of \( \rho \) (regarded as a substitution) acting
  on \( t \) by the action of the clone model (c.f. Theorem~\ref{thm:clone
    model}), the above families in fact define presheaves
  \[
    \mathfrak{L}_{\tau} : \renhat
  \]
  where functorialty of the renaming action is inherited from that of the clone
  model as in Theorem~\ref{thm:clone model}.
\end{definition}

\begin{remark}[A lambda algebra on the presheaves of open syntax]\label{def:open_syn_algebra}
  The presheaves of open syntax \( \mathfrak{L}_{\tau}\) form the objects of an
  algebra for the theory \( \mathcal{L}_{\lambda\alpha\beta\eta} \) defined in
  Definition~\ref{def:alpha_beta_eta_theory}.

  The operations are given by the usual typing rules for the simply typed lambda
  calculus, as in Definition~\ref{def:stlc_rules}. We write \( \mathfrak{L} \)
  for this algebra.
\end{remark}

\begin{remark}[A stratified-lambda algebra on the presheaves of open syntax]
  By Remark~\ref{rmk:upgrade_to_stratified}, the lambda algebra of open syntax
  from Definition~\ref{def:open_syn_algebra} induces an algebra of the theory
  \( \NN \).
\end{remark}

We can define presheaves of neutral and normal terms similarly, with the same
presheaf action by renaming as before.

\begin{definition}[A presheaf of neutral terms]
  For each $\tau \in \types$, the families
  \[
    \mathfrak{Ne}_{\tau} = \{ t \mid \Gamma \nedash t : \tau \}_{\Gamma \in \ren}
  \]
  define a presheaf
  \[ \mathfrak{Ne}_{\tau} : \renhat \]
  under the renaming action.
\end{definition}

\begin{definition}[A presheaf of normal terms]
  For each $\tau \in \types$, the families
  \[
    \mathfrak{Nf}_{\tau} = \{ t \mid \Gamma \nfdash t : \tau \}_{\Gamma \in \ren}
  \]
  define a presheaf
  \[ \mathfrak{Nf}_{\tau} : \renhat\]
  under the renaming action.
\end{definition}

After teasing out the latent binding structure enjoyed by the category of
presheaves, we will find in Definition~\ref{def:strat-lam-alg} that the
presheaves of neutrals and normals give rise to a \( \NN \)-algebra over
\( \renhat \).

\begin{remark}[Why the syntactic category just won't do]\label{rmk:syntactic-cat-bad}
  As mentioned earlier, a major motivation for defining the category of
  renamings in the first place (to which we went to considerable trouble!) is
  that the syntactic category is an unsuitable base category over which to
  define presheaves like the ones above. Let's go back to basics and recall that
  a presheaf is not just a fancy family of sets, but crucially comes with a
  faithful contravariant action taking a morphism in the base category to a
  function of \emph{sets of the family} going in the opposite direction. If we
  take the example of the presheaf of opens of type \(\tau\),
  \( \mathfrak{L}_{\tau}\), there are no apparent problems. We could define the
  family \( \{ \mathfrak{L}_{\tau}(\Delta)\}_{\Delta\in\cl}\) essentially as before, and use
  the following presheaf action:
  \begin{align*}
    \cl[\Delta,\Gamma] &\rightarrow \catset[\mathfrak{L}_{\tau}(\Gamma), \mathfrak{L}_{\tau}(\Delta)] \\
    \delta &\mapsto (t \mapsto \delta^{*} t)
  \end{align*}
  which acts by actually performing the substitution on a term in the set. This
  action's utility breaks down however, when considering the presheaves
  \( \nfpsh \). Supposing we were able to define \( \nfpsh \) instead over the
  classifying category, with the same family as before but with the natural
  substitution action shown above we would have for each substitution
  \( \delta : \Delta \rightarrow \Gamma\) a function of sets \( \nfpsh(\Gamma) \rightarrow \nfpsh(\Delta) \). For a variable
  \( (x : \tau) \in \Gamma \), then, the substitution
  \( [ (\lambda x: \termob.\, x) \textrm{\unit} / y ] \) is taken to a function of
  sets \( \nfpsh(\Gamma, y : \termob) \rightarrow \nfpsh(\Gamma)\) performing that substitution on
  terms. The term \( (\lambda x.\, x) \textrm{\unit} \) is evidently not a normal form
  (since a \( \beta \)-reduction step applies) but \( x \) is a normal form in
  \( \nfpsh(\Gamma, y : \termob)\) so that this action forces
  \( (\lambda x: \termob.\, x) \textrm{\unit} \in \nfpsh(\Gamma) \). The essence of the
  problem is that normal forms are not closed under substitutions, so the
  natural substitution action is ruled out. Whether there is a different
  suitable action by the classifying category on this family is a good question
  to ponder.
\end{remark}

\subsection{A stratified lambda-algebra of neutrals and normals in Renhat}
\begin{definition}[A stratified lambda-algebra of neutrals and normals]\label{def:strat-lam-alg}
  The presheaves of neutrals and normals defined above give rise to an algebra
  of the theory \( \NN \) in \( \renhat\). The sorts \( \mathcal{N}_{\tau}\)
  (resp.~\( \mathcal{M}_{\tau} \)) are taken to be the presheaves
  \( \mathfrak{Nf}_{\tau}\) (resp.~\( \mathfrak{Ne}_{\tau} \)) and the sorts
  \( \mathcal{V}_{\tau}\) are taken to be the representable/variable presheaves
  \( \mathfrak{V}_{\tau} \) defined in Definition~\ref{def:varpsh}.

  The operations correspond to the typing rules of
  Definition~\ref{def:neut-norm-rules}.

  We write \( (\mathfrak{Ne}, \mathfrak{Nf})\) for this algebra.
\end{definition}

\begin{remark}\label{rmk:interpretations-into-tm}
  It turns out that the algebra \( (\mathfrak{Ne}, \mathfrak{Nf})\) is initial
  in the category \( \textrm{Mod}_{\renhat}(NN) \) \cite{fiore_semantic_2002}.
  With this fact, the \( \NN \)-algebra \( (\tm, \tm) \) over
  \( \{ (\tm(\tau), \tm(\tau)) \}_{\tau} \) together with the \( \NN\)-algebra over
  \( \{ (\mathfrak{Ne_{\tau}}, \mathfrak{Nf_{\tau}}) \}_{\tau\in\types} \) just presented
  and the \( \NN\)-algebra on \( \{ \mathfrak{L}_{\tau} \}_{\tau\in\types} \) induce,
  for each \( \tau \in \types \), \(NN\)-homomorphisms~\footnote{in the sense of
    Definition~\ref{def:homomorphism}} \( l : \mathfrak{L} \rightarrow \tm \) and
  \( (m,n) : (\mathfrak{Ne}, \mathfrak{Nf}) \rightarrow (\tm, \tm )\) such that the
  following diagram commutes:

  % https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXG1hdGhmcmFre05lfSJdLFsxLDAsIlxcbWF0aGZyYWt7TH0iXSxbMiwwLCJcXG1hdGhmcmFre05mfSJdLFsxLDEsIlxcbWF0aGZyYWt7VG19Il0sWzAsMSwiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoibW9ubyJ9fX1dLFsyLDEsIiIsMix7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Im1vbm8ifX19XSxbMCwzLCJtIiwyXSxbMSwzLCJsIiwyXSxbMiwzLCJuIl1d
\[\begin{tikzcd}
	{\mathfrak{Ne}} & {\mathfrak{L}} & {\mathfrak{Nf}} \\
	& {\mathfrak{Tm(\tau)}}
	\arrow[tail, from=1-1, to=1-2]
	\arrow[tail, from=1-3, to=1-2]
	\arrow["m"', from=1-1, to=2-2]
	\arrow["l"', from=1-2, to=2-2]
	\arrow["n", from=1-3, to=2-2]
\end{tikzcd}\]

In explicit terms, the map \( l_{\tau} \) for each \( \tau \in \types \) is the usual
semantic interpretation of terms in the syntactic category:
\begin{align*}
  l_{\tau}(\Gamma) : \mathfrak{L}_{\tau}(\Gamma) &\rightarrow \tm(\tau)(\Gamma) \\
  t &\mapsto \sem{\Gamma \vdash t : \tau} \\
\end{align*}

The maps \( m_{\tau} \), \( n_{\tau}\) are the usual semantic interpretation
precomposed with the respective inclusions into open terms.
\end{remark}

\chapter{Obtaining a normalization function}
\section{Desiderata for a normalization function}
For all this talk of normals forms and normalization, we haven't said much about
what a normalization function must be. Of course, it should take a lambda term
to a normal form, but the desiderata are far more than that. The following are
some of the important properties a normalization function
\( \nf_{\tau}^{\Gamma} : \opens_{\tau}(\Gamma) \rightarrow \nfpsh(\Gamma) \) should satisfy:
\begin{itemize}
  \item Semantics preservation: For all terms \( t \in \opens_{\tau}(\Gamma)\),
  \[ \nf_{\tau}^{\Gamma} (t) \equiv_{\beta\eta} t\]

  \item Equation preservation: For all terms
        \( t, t' \in \opens_{\tau}(\Gamma) \),
        \[ t \equiv_{\beta\eta} t' \Rightarrow \nf_{\tau}^{\Gamma} (t) = \nf_{\tau}^{\Gamma} (t') \]
\end{itemize}

These properties together with the signature of the function above encode most
of what one might reasonably expect of a normalization function, and indeed
these are the ones we shall prove about the normalization we plan to construct.
The strength of the approach we have built towards so far is that the proofs of
the above properties will essentially fall out of having constructed the
normalization function as a composite (with the right domain and codomain) of
some glued maps. It should be said that the above are not a complete enumeration
of the properties one might request of a normalization function. Some
theoreticians might demands that normal forms are \emph{fixed} by the
normalization function; that is, \( \nf_{\tau}^{\Gamma}(N) = N\) for any normal form
$N$. We do not show this; for that, refer the reader to Fiore
\cite{fiore_semantic_2002}.

Now that we understand what a normalization function must be, we can set about
constructing it. As hinted at above, our course will be plotted like this:

First, we will elaborate the cartesian closed structure of the gluing category
so that we can extend its lambda algebras along that structure to
interpretations of lambda terms. Later, we will define an \( NN\)-algebra of
\emph{glued} neutrals and normals whose neutral objects \( \mu_{\theta}\) will serve as
the interpretation of a base type \( \theta \). Finally, we will define the
normalization function as a composite of the interpretation induced by this
assignment and (more or less) the some of the glued operations for the
\( NN\)-algebra mentioned above. It will turn out that the characterizing
property of such glued morphisms says exactly that the semantics is preserved by
these morphisms, from which the first property is almost trivial. The second
property is even more immediate, as well will find. [TODO: do another pass of
this intro]

\begin{definition}[Forgetful projections]
  The assignments
  \begin{align*}
    \gl &\rightarrow \cl \\
    (R, q, \Delta) &\mapsto \Delta \\\\
    \gl[(R,q,\Delta), (R', q', \Delta')] &\rightarrow \cl[\Delta, \Delta'] \\
    (d, \delta) &\mapsto \delta \\
  \end{align*}

  form a functor \(\semproj : \gl \rightarrow \cl \) which \emph{forgets the syntax}
  leaving only the semantic components of a glued object or glued morphism.

  We similarly get a functor \( \synproj : \gl \rightarrow \renhat \) which strips away
  the semantics leaving only the syntax defined by
  \begin{align*}
    (R, q, \Delta) &\mapsto R \\
    (d,\delta) &\mapsto d \\
  \end{align*}
\end{definition}

\section{Cartesian closed structure for the gluing category}
In order to give an interpretation of terms in the gluing category, we must give
an explicit account of its cartesian closed structure. We will say what its
products are, but not prove the universal property: we send the reader to
\cite{sterling_normalization_2018} for that part. We will however give a sketch
of the universal property for the exponentials, which is not shown in either of
the sources we consulted on connections between gluing and normalization
(\cite{sterling_normalization_2018}, \cite{fiore_semantic_2002}). The result
itself is well-known, but the sketch has not been fully verified and should be
taken with a grain of salt.

\begin{theorem}[Products in the gluing category]
  The terminal object (nullary product) is
  \( (\termob : \renhat, t : \termob \rightarrow \tm(\termob), \termob : \cl) \) where and
  \( t \) is the unique map \( \termob \xrightarrow{\cong} \tm(\termob) \)
  guaranteed by cartesian closure of \( \tm \). The binary product
  \( (P, p, \Delta) \times (Q, q, \Gamma) \) of \( (P, p, \Delta)\) and \( (Q,q,\Gamma)\) is
  \( (P \times Q, r, \Delta \times \Gamma)\) where $r$ is the composite
  \[ P \times Q \xrightarrow{p \times q} \tm(\Delta) \times \tm(\Gamma) \xrightarrow[\cong]{i_{\pi}} \tm(\Delta \times \Gamma)\]
\end{theorem}

\begin{theorem}[Exponentials in the gluing category]
  For objects \( (R_{1}, q_{1}, \Delta_{1})\) and \( (R_{2},q_{2},\Delta_{2})\) in
  \( \gl \), the exponential \( (R_{2}, q_{2}, \Delta_{2})^{(R_{1}, q_{1}, \Delta_{1})}\)
  is \( (R, q, {\Delta_{2}}^{\Delta_{1}}) \) in the pullback diagram
  \[\begin{tikzcd}
      R && {{R_2}^{R_1}} \\
      \\
      {\mathfrak{Tm}(\Delta_2 ^ {\Delta_1})} && {\mathfrak{Tm}(\Delta_2)^{R_1}} \\
      \\
      \\
      && {}
      \arrow["q"', from=1-1, to=3-1]
      \arrow["r", from=1-1, to=1-3]
      \arrow["{{q_2}_*}", from=1-3, to=3-3]
      \arrow["{{q_1}^* \circ \tilde{p}}"', from=3-1, to=3-3]
    \end{tikzcd}\]
  where \[ p = \tm(\epsilon) \circ (\tm(\Delta_{2}^{\Delta_{1}}) \times \tm(\Delta_{1}) \xrightarrow{\cong} \tm(\Delta_{2}^{\Delta_{1}}\times \Delta_{1})) \]  is the composition of the lifting of the syntactic category's evaluation to
  \( \renhat \) with the isomorphism witnessing the product preservation of
  \( \tm \), and \( \tilde{p} \) is its exponential transpose.
\end{theorem}

\begin{sketch}
  The universal property for exponentials is encoded by the product-hom
  adjunction. It suffices to show an isomorphism
  \[ \gl[(R_{X}, q_{X}, \Delta_{X})\times(R_{Y}, q_{Y}, \Delta_{Y}), (R_{Z}, q_{Z}, \Delta_{Z})] \cong \gl[(R_{X}, q_{X}, \Delta_{X}), (R_{Z},q_{Z},\Delta_{Z})^{(R_{Y}, q_{Y}, \Delta_{Y})}] \]

  recalling the definition of products in the gluing category, we must show

  \[ \phi : P \cong E : \psi \]

  where
  \begin{align*}
    &\tm(\Delta_{2}^{\Delta_{1}}) \times \tm(\Delta_{1}) \xrightarrow{i_{\pi}} \tm(\Delta_{2}^{\Delta_{1}}\times \Delta_{1}) \\
    &P = \gl[(R_{X} \times R_{Y}, i_{\pi} \circ (q_{X} \times q_{Y}),  \Delta_{X} \times \Delta_{Y}), (R_{Z}, q_{Z}, \Delta_{Z})] \\
    &E = \gl[(R_{X}, q_{X}, \Delta_{X}), (R_{Z},q_{Z},\Delta_{Z})^{(R_{Y}, q_{Y}, \Delta_{Y})}] \\
  \end{align*}

  To come up with this isomorphism, it helps to consider what the morphisms in
  $P$ and $E$ are. Looking back to the definition of products and our proposed
  definition for the exponentials reveals that a morphism $(d,\delta) \in P$ must fit
  into the upper half of the diagram below, where any morphism \( (d',\delta') \in E\)
  must fit into the lower half of the diagram. As such, the components of the
  map \( \phi \) evaluated at some \((d, \delta) \in P \) must be the dotted arrows in
  the lower half of the diagram below.

  % https://q.uiver.app/?q=WzAsMTksWzAsMCwiUl9YXFx0aW1lcyBSX1kiXSxbMCwyLCJcXG1hdGhmcmFre1RtfShcXERlbHRhX1hcXHRpbWVzXFxEZWx0YV9ZKSJdLFszLDIsIlxcbWF0aGZyYWt7VG19KFxcRGVsdGFfWikiXSxbMywwLCJSX1oiXSxbMCw3LCJcXG1hdGhmcmFre1RtfShcXERlbHRhX1gpIl0sWzEsNywiXFxtYXRoZnJha3tUbX0oe1xcRGVsdGFfWn1ee1xcRGVsdGFfWX0pIl0sWzEsNSwiUiJdLFszLDUsIntSX1p9XntSX1l9Il0sWzMsNywiXFxtYXRoZnJha3tUbX0oXFxEZWx0YV9aKV57Ul9ZfSJdLFs1LDFdLFswLDUsIlJfWCJdLFsxLDBdLFsxLDJdLFs1LDBdLFs1LDJdLFswLDNdLFsyLDZdLFsxLDRdLFsxLDNdLFswLDMsImQiXSxbMywyLCJxX1oiXSxbMCwxLCJpX1xccGkgXFxjaXJjIChxX1hcXHRpbWVzIHFfWSkiLDJdLFsxLDIsIlxcZGVsdGEiLDJdLFs2LDcsInIiXSxbNyw4LCJ7cV9afV8qIl0sWzYsNSwicSIsMl0sWzUsOCwie3FfWX1eKiBcXGNpcmMgXFx3aWRldGlsZGV7XFxtYXRoZnJha3tUbX0oXFxlcHNpbG9uKSBcXGNpcmMgaV9cXHBpfSIsMl0sWzEwLDYsImQnIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn19fV0sWzEwLDQsInFfWCIsMl0sWzQsNSwiXFxkZWx0YSciLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XSxbNiwxNiwiIiwwLHsic3R5bGUiOnsibmFtZSI6ImNvcm5lciJ9fV0sWzE4LDE3LCIiLDAseyJsYWJlbF9wb3NpdGlvbiI6NDAsIm9mZnNldCI6LTUsImxldmVsIjoyLCJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	{R_X\times R_Y} & {} && {R_Z} && {} \\
	&&&&& {} \\
	{\mathfrak{Tm}(\Delta_X\times\Delta_Y)} & {} && {\mathfrak{Tm}(\Delta_Z)} && {} \\
	{} & {} \\
	& {} \\
	{R_X} & R && {{R_Z}^{R_Y}} \\
	&& {} \\
	{\mathfrak{Tm}(\Delta_X)} & {\mathfrak{Tm}({\Delta_Z}^{\Delta_Y})} && {\mathfrak{Tm}(\Delta_Z)^{R_Y}}
	\arrow["d", from=1-1, to=1-4]
	\arrow["{q_Z}", from=1-4, to=3-4]
	\arrow["{i_\pi \circ (q_X\times q_Y)}"', from=1-1, to=3-1]
	\arrow["\tm(\delta)"', from=3-1, to=3-4]
	\arrow["r", from=6-2, to=6-4]
	\arrow["{{q_Z}_*}", from=6-4, to=8-4]
	\arrow["q"', from=6-2, to=8-2]
	\arrow["{{q_Y}^* \circ \reallywidetilde{\mathfrak{Tm}(\epsilon) \circ i_\pi}}"', from=8-2, to=8-4]
	\arrow["{d'}", dashed, from=6-1, to=6-2]
	\arrow["{q_X}"', from=6-1, to=8-1]
	\arrow["{\delta'}"', dashed, from=8-1, to=8-2]
	\arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=6-2, to=7-3]
	\arrow["{\phi}", shift left=5, Rightarrow, dashed, from=4-2, to=5-2]
\end{tikzcd}\]

where \( \tm(\Delta_{Z})^{\tm(\Delta_{Y})} \xrightarrow{i_{e}} \tm(\Delta_{Z}^{\Delta_{Y}})\) is the
isomorphism witnessing that the relative hom functor preserves exponentials as
in Remark~\ref{rmk:tm-cartesian-closed}. Observing the arrows in sight, a
plausible choice for \( \delta' \) is \( \tilde{\delta} \).

The choice for \( d' \) is a more tricky question. \( d' \) should be an arrow
into the pullback \( R \). We know nothing about nothing about \( R \) except
that it fits into the pullback diagram above. The upside of our ignorance is
that it makes our choice of \( d' \) automatic: it must be one of the mediators
required by the universal property of the pullback, in particular the dotted
arrow in the diagram below. To get this dotted arrow, we need to verify that the
outer square of the following diagram commutes.
% https://q.uiver.app/?q=WzAsNixbMSwxLCJSIl0sWzAsMCwiUl9YIl0sWzEsMywiXFxtYXRoZnJha3tUbX0oe1xcRGVsdGFfWn1ee1xcRGVsdGFfWX0pIl0sWzMsMywiXFxtYXRoZnJha3tUbX0oXFxEZWx0YV9aKV57Ul9ZfSJdLFszLDEsIntSX1p9XntSX1l9Il0sWzIsMl0sWzAsNCwiciJdLFs0LDMsIntxX1p9XyoiXSxbMCwyLCJxIiwyXSxbMiwzLCJ7cV9ZfV4qIFxcY2lyYyBcXHdpZGV0aWxkZXtcXG1hdGhmcmFre1RtfShcXGVwc2lsb24pIFxcY2lyYyBpX1xccGl9IiwyXSxbMCw1LCIiLDIseyJzdHlsZSI6eyJuYW1lIjoiY29ybmVyIn19XSxbMSwyLCJcXGRlbHRhJyBcXGNpcmMgcV9YIiwyLHsiY3VydmUiOjN9XSxbMSw0LCJcXHRpbGRle2R9IiwwLHsiY3VydmUiOi0zfV0sWzEsMCwiXFxleGlzdHMhZCciLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkb3R0ZWQifX19XV0=
\[\begin{tikzcd}
	{R_X} \\
	& R && {{R_Z}^{R_Y}} \\
	&& {} \\
	& {\mathfrak{Tm}({\Delta_Z}^{\Delta_Y})} && {\mathfrak{Tm}(\Delta_Z)^{R_Y}}
	\arrow["r", from=2-2, to=2-4]
	\arrow["{{q_Z}_*}", from=2-4, to=4-4]
	\arrow["q"', from=2-2, to=4-2]
	\arrow["{{q_Y}^* \circ \reallywidetilde{\mathfrak{Tm}(\epsilon) \circ i_\pi}}"', from=4-2, to=4-4]
	\arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=2-2, to=3-3]
	\arrow["{\tm(\delta') \circ q_X}"', curve={height=18pt}, from=1-1, to=4-2]
	\arrow["{\tilde{d}}", curve={height=-18pt}, from=1-1, to=2-4]
	\arrow["{\exists!d'}"', dotted, from=1-1, to=2-2]
\end{tikzcd}\]

We need to show
that \[ q_{Y}^{*} \circ \reallywidetilde{\tm(\epsilon) \circ i_{\pi}} \circ \tm(\tilde{\delta}) \circ q_{X} = {q_{Z}}_{*} \circ \tilde{d} \]
which should strike the reader as suspiciously similar to the characterizing
property of the glued morphism \( (d,\delta)\), namely
that \[ \tm(\delta) \circ i_{\pi} \circ (q_{X} \times q_{Y}) = q_{Z} \circ d. \] In what follows, we
call this equation the gluing equation.

To untangle this mess, we pass to the lambda notation for the transpose as in
Chapter~\ref{chapter:stlc}. We can express the left-hand side of the desired
equality in this notation (dropping the explicit type annotations and adding
explicit variables for both abstracted variables and ordinary free variables
representing morphism inputs) as
\begin{align*}
  q_{Y}^{*} \circ (\lambda y.\, \tm(\epsilon) (i_{\pi}(f,y))) \circ \tm(\delta)(x) \circ q_{X} &= q_{Y}^{*} \circ (\lambda y.\, \tm(\epsilon) (i_{\pi}(\tm(\delta(x)),y))) \circ q_{X}\\

                                                               &= q_{Y}^{*} \circ (\lambda y.\, \tm(\epsilon) (i_{\pi}(\tm(\delta(x)),y))) \circ q_{X} \\
                                                               &= q_{Y}^{*} \circ (\lambda y.\, \tm(\delta)(i_{\pi}(x,y))) \circ q_{X} \\
                                                               &= \lambda y.\, \tm(\delta)(i_{\pi}(q_{X}(x),q_{Y}(y)))


\end{align*}
where the second and third steps respectively follow from associativity of
composition and the lifting along \( \tm \) of the universal property of
transposes in \( \cl \). We are also using the fact that the universal property
of exponentials forces \( i_{\pi} \) to be the unique isomorphism which acts as a
syntactic pair constructor, i.e., it takes genuine pairs to syntactic pairs.
What we are left with is exactly the transpose of the left-hand side of the
gluing equation:
\begin{align*}
  \reallywidetilde{\tm(\delta) \circ i_{\pi} \circ (q_{X} \times q_{Y})} &= \lambda y.\, \tm(\delta) (i_{\pi}((q_{X}\times q_{Y}) (x, y))) \\
                                                     &= \lambda y.\, \tm(\delta (i_{\pi}(q_{X}(x),q_{Y}(y))))
\end{align*}
Moreover, the right-hand side of the desired equality is evidently the transpose
of the right-hand side of the gluing equation. Because taking transposes is
well-defined, the preceding two facts gives us the desired equality.

We can now summarize the rightward map for the isomorphism:
\begin{align*}
  \phi_{1}(d) &= d' && (\textrm{the unique mediating arrow from the argument above})\\
  \phi_{2}(\delta) &= \tilde{\delta}
\end{align*}


The leftward side of the isomorphism, \( \psi \), is substantially easier,
because we don't need to interact much with the pullback. We define

\begin{align*}
  \psi_{1}(d') &= \epsilon \circ ((d' \circ r) \times \id)  \\
  \psi_{2}(\delta') &= \tm(\epsilon) \circ (i_{\pi} \circ (\delta' \times \id) \circ i_{\pi}^{-1}) \\
\end{align*}

With our maps in hand, we can verify that they form a bijection. Because we have
defined \( d' \) by the universal property of the pullback, we have that
\( d' \circ r = \tilde{d} \) whence \( \psi_{1}(\phi_{1}(d)) = \epsilon \circ (\tilde{d} \times \id) \) so
that \( \psi_{1}(\psi_{1}(d)) = d \) by the universal property of the transpose in
\( \renhat \). The second required equality also follows by the universal
property of the transpose, this time in \( \cl \). We have
\( \psi_{2}(\phi_{2}(\delta)) = \epsilon \circ (\tilde{\delta} \times \id) \) so that \( \psi_{2}(\phi_{1}(\delta)) = \delta \)
as required.

With that, we have sketched the bijection. The full details, along with the
naturality condition are left to the reader\footnote{who should email me when
  they figure it out.}.
\end{sketch}

\begin{corollary}
  The gluing category \( \gl \) is cartesian closed.
\end{corollary}

\section{Gluing syntax to semantics}
We will define some glued objects which, in some sense, glue the presheaves of
syntax we have defined in \( \renhat \) together with their semantics in the
classifying category. These glued objects will ultimately assemble into the
objects for an algebra of the theory \( NN \).

\begin{definition}\label{def:yonedabar}
  The relative hom functor induces the embedding
  \begin{align*}
    \overline{\yoneda} : \ren &\hookrightarrow \gl \\
    \Gamma &\mapsto (\yoneda(\Gamma), \yoneda(\Gamma) \xrightarrow{\underline{\iota}_{\Gamma}} \tm(\Gamma), \Gamma) \\
  \end{align*}
  where
  \begin{align*}
    (\underline{\iota}_{\Gamma})_{\Delta} : \ren[\Delta, \Gamma] &\rightarrow \cl[\Delta, \Gamma] \\
    \rho &\mapsto \iota(\rho) \\
  \end{align*}

  which fits into the following diagram
  % https://q.uiver.app/?q=WzAsNyxbMiwwLCJcXHJlbiJdLFsyLDEsIlxcZ2wiXSxbMCwxLCJcXHJlbmhhdCJdLFs0LDEsIlxcY2wiXSxbMiwyLCIoUixxLFxcRGVsdGEpIl0sWzQsMiwiXFxEZWx0YSJdLFswLDIsIlIiXSxbMCwxLCJcXG92ZXJsaW5le1xceW9uZWRhfSIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzAsMiwiXFx5b25lZGEiLDIseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFswLDMsIlxcaW90YSIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoiYm90dG9tIn19fV0sWzEsM10sWzEsMl0sWzQsNSwiXFxzZW1wcm9qIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoibWFwcyB0byJ9fX1dLFs0LDYsIlxcc3lucHJvaiIsMix7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Im1hcHMgdG8ifX19XV0=
\[\begin{tikzcd}
	&& \ren \\
	\renhat && \gl && \cl \\
	R && {(R,q,\Delta)} && \Delta
	\arrow["{\overline{\yoneda}}", hook, from=1-3, to=2-3]
	\arrow["\yoneda"', hook, from=1-3, to=2-1]
	\arrow["\iota", hook', from=1-3, to=2-5]
	\arrow[from=2-3, to=2-5]
	\arrow[from=2-3, to=2-1]
	\arrow["\semproj", maps to, from=3-3, to=3-5]
	\arrow["\synproj"', maps to, from=3-3, to=3-1]
\end{tikzcd}
\]

and satisfies the following form of the Yoneda lemma:
% https://q.uiver.app/?q=WzAsNixbMCwwLCIoZCxcXGRlbHRhKSJdLFsyLDAsImQoXFxpZCkiXSxbMCwxLCJcXGdsW1xcb3ZlcmxpbmV7XFx5b25lZGEoLSl9LCAoUixxLFxcRGVsdGEpXSJdLFsyLDEsIlIoLSkiXSxbMSwyLCJcXGNsW1xcaW90YSgtKSxcXERlbHRhXT1cXHRtKFxcRGVsdGEpIl0sWzEsMV0sWzAsMSwiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoibWFwcyB0byJ9fX1dLFsyLDMsIlxcY29uZyJdLFszLDQsInEiXSxbMiw0LCJcXHNlbXByb2oiLDJdXQ==
\[\begin{tikzcd}
	{(d,\delta)} && {d(\id)} \\
	{\gl[\overline{\yoneda}(-), (R,q,\Delta)]} & {} & {R(-)} \\
	& {\cl[\iota(-),\Delta]=\tm(\Delta)}
	\arrow[maps to, from=1-1, to=1-3]
	\arrow["\cong", from=2-1, to=2-3]
	\arrow["q", from=2-3, to=3-2]
	\arrow["\semproj"', from=2-1, to=3-2]
\end{tikzcd}\]
\end{definition}

This embedding allows us to define a typed-indexed family of glued objects which
glue the syntax, $x,y,z,\ldots,$ etc., of variables to the their semantics as
substitutions.

\newcommand{\yonedabar}{\overline{\yoneda}}

\begin{definition}[Gluing syntax and semantics of variables]
  We define the glued
  object \[ \nu_{\tau} = \yonedabar(\tau) = (\varpsh, \varpsh \rightarrow \tm(\tau), \tau)\] where the
  components of the interpretation are the usual interpretation of terms in the
  classifying category.
\end{definition}

We do the same for the syntactic presheaves of neutrals and normals we defined
earlier. In each case, the components of the quotient map are the interpretation
of terms in the classifying category.

\begin{definition}[Gluing syntax and semantics of neutrals]
  \[ \mu_{\tau} = (\neut, \neut \xrightarrow{m_{\tau}} \tm(\tau), \tau) \]
\end{definition}

\begin{definition}[Gluing syntax and semantics of normals]
  \[ \eta_{\tau} = (\norm, \norm \xrightarrow{n_{\tau}} \tm(\tau), \tau) \]
\end{definition}

With these glued objects, we can define an \( \NN \)-algebra over these families
of glued variables, glued neutrals, and glued normals. In turn
Definition~\ref{def:term model} will allow us to leverage this to interpret
substitutions as gluing category morphisms between these glued objects. The
algebra we define will be constructed by gluing together the syntactic
\( \NN \)-algebra in \( \renhat \) together with the semantic
\( \NN \)-algebra\footnote{i.e., the one induced by
  Remark~\ref{rmk:upgrade_to_stratified} and the usual lambda algebra in the
  classifying category} in the classifying category.

\begin{definition}[An algebra of stratified neutrals and normals in the gluing category]\label{def:glued-algebra}
  The family \( \{ (\mu_{\tau}, \eta_{\tau})\}_{\tau\in\types}\) define the objects of an
  \( \NN \)-algebra with the operations given as follows:
  \begin{itemize}
    \item For each \( \tau, \tau' \in \types\), the pair of maps
    \[ (\var_{\tau} : \varpsh \rightarrow \mathfrak{Ne}_{\tau} , \id_{\sem{\tau}})\]
    is a map \( \nu_{\tau} \rightarrow \mu_{\tau} \) in \( \renhat \downarrow \tm \).

    That this pair forms a glued morphism follows from the fact that
    \( (m,n) : (\mathfrak{Ne},\mathfrak{Nf}) \rightarrow (\tm, \tm)\) is a
    \( NN \)-homomorphism. In particular, we have that the following
    diagram commutes:

    % https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXG1hdGhmcmFre1Z9XFx0YXUiXSxbMiwwLCJcXG1hdGhmcmFre05lfV9cXHRhdSJdLFsyLDIsIlxcbWF0aGZyYWt7VG19KFxcdGF1KSJdLFsxLDFdLFswLDEsIlxcdGV4dHJte3Zhcn1fXFx0YXUiXSxbMSwyLCJtIl0sWzAsMiwiXFxzZW17LX0iLDJdXQ==
    \[\begin{tikzcd}
        {\mathfrak{V}\tau} && {\mathfrak{Ne}_\tau} \\
        & {} \\
        && {\mathfrak{Tm}(\tau)}
        \arrow["{\textrm{var}_\tau}", from=1-1, to=1-3]
        \arrow["m", from=1-3, to=3-3]
        \arrow["{\sem{-}}"', from=1-1, to=3-3]
      \end{tikzcd}\]

    Inserting the lifted identity map at the bottom gives precisely the
    required square.

    \item For each \( \tau, \tau' \in \types\), the pair of maps
    \[ (\fst_{\tau}^{\tau'} : \mathfrak{Ne}_{\tau*\tau'} \rightarrow \mathfrak{Ne}_{\tau}, \pi_{1} : \sem{\tau} \times \sem{\tau'} \rightarrow \sem{\tau}) \]
    is a map \( \mu_{\tau*\tau'} \rightarrow \mu_{\tau} \) in \( \renhat \downarrow \tm \).

    That this pair forms a glued morphisms again follows from the fact
    that \( (m,n) : (\mathfrak{Ne},\mathfrak{Nf}) \rightarrow (\tm, \tm)\) is a
    \( NN \)-homomorphism. In particular, we have that the following
    diagram commutes:

    % https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXG1hdGhmcmFre05lfV97XFx0YXUgXFx0aW1lcyBcXHRhdSd9Il0sWzIsMCwiXFxtYXRoZnJha3tOZX1fXFx0YXUiXSxbMiwyLCJcXG1hdGhmcmFre1RtfShcXHRhdSkiXSxbMCwyLCJcXG1hdGhmcmFre1RtfShcXHRhdSBcXHRpbWVzIFxcdGF1JykiXSxbMCwxLCJcXHRleHRybXtmc3R9X1xcdGF1XntcXHRhdSd9Il0sWzEsMiwibV9cXHRhdSJdLFswLDMsIm1fe1xcdGF1XFx0aW1lc1xcdGF1J30iLDJdLFszLDIsIlxcdG0oXFxwaV8xKSIsMl1d
    \[\begin{tikzcd}
        {\mathfrak{Ne}_{\tau \times \tau'}} && {\mathfrak{Ne}_\tau} \\
        \\
        {\mathfrak{Tm}(\tau \times \tau')} && {\mathfrak{Tm}(\tau)}
        \arrow["{\textrm{fst}_\tau^{\tau'}}", from=1-1, to=1-3]
        \arrow["{m_\tau}", from=1-3, to=3-3]
        \arrow["{m_{\tau\times\tau'}}"', from=1-1, to=3-1]
        \arrow["{\tm(\pi_1)}"', from=3-1, to=3-3]
      \end{tikzcd}\]

    Which is exactly the required square. In fact, each of the remaining
    cases work out in this unsurprising way, so we will stop mentioning
    it. It is worth noting that one reason these squares line up so
    cleanly is that we defined the lambda algebra on \( \tm \) by lifting
    the relevant operations from \( \cl \) into \( \renhat \) along
    \( \tm \).

    \item For each \( \tau, \tau' \in \types\), the pair of maps
    \[ (\snd_{\tau}^{\tau'} : \mathfrak{Ne}_{\tau'*\tau} \rightarrow \mathfrak{Ne}_{\tau}, \pi_{2} : \sem{\tau'} \times \sem{\tau} \rightarrow \sem{\tau}) \]
    is a map \( \mu_{\tau'*\tau} \rightarrow \mu_{\tau} \) in \( \renhat \downarrow \tm \).
    \item For each \( \tau, \tau' \in \types\), the pair of maps
    \[ (\app_{\tau}^{\tau'} : \mathfrak{Ne}_{\tau'\rightarrow\tau} \times \mathfrak{Nf}_{\tau'} \rightarrow \mathfrak{Ne}_{\tau}, \epsilon : (\sem{\tau'} \rightarrow \sem{\tau}) \times \sem{\tau'} \rightarrow \sem{\tau}) \]
    is a map \( \mu_{\tau'\rightarrow\tau} \times \eta_{\tau'} \rightarrow \mu_{\tau}\) in \( \renhat \downarrow \tm \).


    \item For each base type \( \theta \in T\), the pair of isomorphisms
          \[ \mathfrak{Ne}_{\theta} \cong \mathfrak{Nf}_{\theta} , \id_{\sem{\theta}}\] is an
          isomorphism \( \mu_{\theta} \cong \eta_{\theta}\) in \( \renhat \downarrow \tm \).
    \item The pair of isomorphisms
          \[ \termob \cong \mathfrak{Nf}_{\termob}, \id_{\termob}\] is an isomorphism
          \( \termob \cong \eta_{\termob}\) in \( \renhat \downarrow \tm \).
    \item For \( \tau, \tau' \in \types \), the pair of isomorphisms
          \[ \pair_{\tau*\tau'} : \mathfrak{Nf}_{\tau} \times \mathfrak{Nf}_{\tau'} \xrightarrow{\cong} \mathfrak{Nf}_{\tau*\tau'} , \id_{\sem{\tau} \times \sem{\tau'}}\]
          is an isomorphism \( \eta_{\tau} \times \eta_{\tau'} \xrightarrow{\cong} \eta_{\tau*\tau'} \) in
          \( \renhat \downarrow \tm \).
          \item For \( \tau, \tau' \in \types \), the pair of isomorphisms
          \[ \abs_{\tau \rightarrow \tau'} : \mathfrak{Nf}_{\tau'}^{\varpsh} \xrightarrow{\cong} \mathfrak{Nf}_{\tau \rightarrow \tau'}, \id_{\sem{\tau'}^{\sem{\tau}}}\]
          is an isomorphism \( \eta_{\tau'}^{\nu_{\tau}} \xrightarrow{\cong} \eta_{\tau\rightarrow\tau'}\) in \( \renhat \downarrow \tm \).
  \end{itemize}
\end{definition}

Note that the glued operations are given by pairs of syntactic operations and
\emph{semantic operations} for elimination forms, and pairs of syntactic
operations and the \emph{identity} for introduction forms.

Finally we can give an interpretation of base types in the gluing category in terms of the glued neutrals
\begin{align*}
  T &\xrightarrow{\bar{s}} \renhat \downarrow \tm \\
  \theta &\mapsto \mu_{\theta}\\
\end{align*}

Together with a suitable interpretation of base constructors and eliminators
(which are taken to be a parameter of this development) as glued morphisms, this
interpretation defines a lambda algebra of glued neutrals. The universal
property of the classifying category and its lambda algebra in turn induces a
unique functor
\[ \sem{-}_{\gl} : \cl \rightarrow \gl \] as in Theorem~\ref{thm:classifying alg theory}.
We write \( \sem{-}_{\gl} : \cl \rightarrow \gl \) for both this functor and the
interpretation of terms acquired by precomposing the functor with the usual
interpretation of terms in the classifying category. It is crucial to understand
that though we have \( \sem{\theta}_{\gl} = \mu_{\theta}\) for base types $\theta$, this equality
does \emph{not} hold at higher types \( \tau \in \types\). In the case of products,
the interpreted type \( \sem{\theta \times \theta'}_{\gl} \) is the actual product
\( \mu_{\theta} \times \mu_{\theta'}\) and not \( \mu_{\theta\times\theta'} \). In what follows, we still allow
ourselves to write \( \sem{-} \) for the usual interpretation of terms in the
classifying category, distinguishing the new interpretation only by a subscript.
The induced interpretation \( \sem{-}_{\gl}\) extends the usual interpretation
of terms in the syntactic category in the following sense:
\( \sem{\Gamma \vdash t : \tau}_{\gl} \) is a pair of the form
$(\sem{\Gamma \vdash t : \tau}_{\renhat}, \sem{\Gamma \vdash t : \tau })$ where
\( \sem{-}_{\renhat} : \cl \rightarrow \renhat \) functor induced by the
\(\renhat\)-lambda algebra over the family \( \{ \nepsh \}_{\tau\in\types}\) and the
universal property of the classifying category.

\begin{lemma}\label{lem:sem-pi-is-id-endofunctor}
  The composite \( \semproj \circ \sem{-}_{\gl} : \cl \rightarrow \cl \) is the identity
  endofunctor on \( \cl \).
\end{lemma}
\begin{proof}
  This follows from Theorem~\ref{thm:classifying alg theory}. In particular,
  since \( \cl \) is the initial category with a model of the lambda calculus,
  we have that there is a unique functor \( \cl \rightarrow \cl \) preserving the
  cartesian closed structure and the lambda algebra. The identity preserves the
  cartesian closed structure and the lambda algebra, so that uniqueness forces
  the desired equality.
\end{proof}

Now is a good time look ahead to where we're going, and see how what we've done
so far will get us there.

\section{Taking stock: charting a path to normalization}\label{sec:taking-stock}
We now have enough language to say exactly what it is we're hoping to acquire in
this chapter. Let \( \tau \in \types \) and suppose
\( \sem{\tau}_{\gl} = (\mathfrak{R}_{\tau}, q, \tau) \). We wish to come up with maps
\( \uparrow_{\tau}\) (pronounced ``reflect'', or for the LISPer ``unquote'') and
\( \downarrow_{\tau}\) (pronounced ``reify'', or for the LISPer ``quote'') at each type
\( \tau \in \types \) to fill in the dotted arrows in the upper diagram such that the
lower diagram commutes. In classical approaches to normalization by evaluation,
reflection can be construed as lifting syntax into a semantic domain: in
practice, this looks like, say, taking syntactic functions in the object
language to \emph{actual functions} in the host language. Dually, reification is
thought of as lowering semantic objects to a syntactic representation.

% https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXG1hdGhmcmFre05lfV9cXHRhdSJdLFsyLDAsIlxcbWF0aGZyYWt7Un1fXFx0YXUiXSxbNCwwLCJcXG1hdGhmcmFre05mfV9cXHRhdSJdLFsyLDEsIlxcbWF0aGZyYWt7VG19Il0sWzAsMSwiXFx1cGFycm93X1xcdGF1IiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZG90dGVkIn19fV0sWzEsMiwiXFxkb3duYXJyb3dfXFx0YXUiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkb3R0ZWQifX19XSxbMiwzLCJuX1xcdGF1Il0sWzAsMywibV9cXHRhdSIsMl0sWzEsMywicl9cXHRhdSIsMl1d
\[\begin{tikzcd}
	{\mathfrak{Ne}_\tau} && {\mathfrak{R}_\tau} && {\mathfrak{Nf}_\tau} \\
	&& {\mathfrak{Tm}(\tau)}
	\arrow["{\uparrow_\tau}", dotted, from=1-1, to=1-3]
	\arrow["{\downarrow_\tau}", dotted, from=1-3, to=1-5]
	\arrow["{n_\tau}", from=1-5, to=2-3]
	\arrow["{m_\tau}"', from=1-1, to=2-3]
	\arrow["{r_\tau}"', from=1-3, to=2-3]
\end{tikzcd}\]

% https://q.uiver.app/?q=WzAsOSxbMCwwLCJcXHByb2RfaVxcbWF0aGZyYWt7TmV9X3tcXHRhdV9pfSAiXSxbMiwwLCJcXHByb2RfaVxcbWF0aGZyYWt7Un1fe1xcdGF1X2l9Il0sWzQsMCwiXFxtYXRoZnJha3tOZn1fe1xcdGF1fSJdLFsxLDBdLFsyLDEsIlxccHJvZF9pXFx0ZXh0cm17Q259X1xcbWF0aGNhbHtcXGxhbWJkYX1ee1xccmlnaHRhcnJvd30oLSxcXHRhdV9pKSJdLFsxLDFdLFsyLDIsIlxcdGV4dHJte0NufV9cXG1hdGhjYWx7XFxsYW1iZGF9XntcXHJpZ2h0YXJyb3d9KC0sXFxHYW1tYSkiXSxbMywwLCJcXG1hdGhmcmFre1J9X1xcdGF1Il0sWzQsMiwiXFx0ZXh0cm17Q259X1xcbWF0aGNhbHtcXGxhbWJkYX1ee1xccmlnaHRhcnJvd30oLSxcXHRhdSkiXSxbMCwxLCJcXHByb2RfaVxcdXBhcnJvd157XFx0YXVfaX0iXSxbMSw0LCJcXHByb2RfaSByX3tcXHRhdV9pfSJdLFswLDQsIlxccHJvZF9pbV97XFx0YXVfaX0iLDJdLFs0LDYsIlxcY29uZyJdLFs3LDIsIlxcZG93bmFycm93XntcXHRhdX0iXSxbMSw3LCJcXG1hdGhiYntzfVxcbGxicmFja2V0XFxHYW1tYVxcdmRhc2ggdDpcXHRhdVxccnJicmFja2V0Il0sWzYsOCwic1xcbGxicmFja2V0XFxHYW1tYVxcdmRhc2ggdCA6IFxcdGF1IFxccnJicmFja2V0XyoiLDJdLFsyLDgsIm5fXFx0YXUiXSxbNyw4LCJyX1xcdGF1IiwyXV0=
\[\begin{tikzcd}
	{\prod_i\mathfrak{Ne}_{\tau_i} } & {} & {\prod_i\mathfrak{R}_{\tau_i}} & {\mathfrak{R}_\tau} & {\mathfrak{Nf}_{\tau}} \\
	& {} & {\prod_i\textrm{Cn}_{\mathcal{\lambda}}^{\rightarrow}(-,\tau_i)} \\
	&& {\textrm{Cn}_{\mathcal{\lambda}}^{\rightarrow}(-,\Gamma)} && {\textrm{Cn}_{\mathcal{\lambda}}^{\rightarrow}(-,\tau)}
	\arrow["{\prod_i\uparrow^{\tau_i}}", from=1-1, to=1-3]
	\arrow["{\prod_i r_{\tau_i}}", from=1-3, to=2-3]
	\arrow["{\prod_im_{\tau_i}}"', from=1-1, to=2-3]
	\arrow["\cong", from=2-3, to=3-3]
	\arrow["{\downarrow^{\tau}}", from=1-4, to=1-5]
	\arrow["{\mathbb{s}\llbracket\Gamma\vdash t:\tau\rrbracket}", from=1-3, to=1-4]
	\arrow["{s\llbracket\Gamma\vdash t : \tau \rrbracket_*}"', from=3-3, to=3-5]
	\arrow["{n_\tau}", from=1-5, to=3-5]
	\arrow["{r_\tau}"', from=1-4, to=3-5]
\end{tikzcd}\]

Supposing we can achieve this, our normalization function will be precisely the
the upper-right composite of the lower diagram. Because the diagram commutes,
the normalization function computes for a term $t$ a normal form with the same
\emph{semantics} as $t$; that is, as evident from the diagram, we will have an
equality of morphisms \( t \equiv \nf(t)\) in the syntactic category.

To come up with such maps, we shall produce some intermediate maps
\[
  \mu_{\tau} \xrightarrow{\Uparrow^{\tau}} \sem{\tau}_{\gl} \xrightarrow{\Downarrow^{\tau}} \eta_{\tau}
\]
in the gluing category. Setting \( \downarrow^{\tau} = \synproj (\Downarrow^{\tau})\) and
\( \uparrow^{\tau} = \synproj(\Uparrow^{\tau})\), we find that the triangles above follow from
demonstrating that the above glued maps project in the semantics onto the
identity: \( \semproj(\Downarrow^{\tau}) = \id_{\sem{\tau}} = \semproj(\Uparrow^{\tau})\). This follows
by considering the universal property of a glued morphism. In the case of the
reflect map, we get a diagram like this

% https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXG1hdGhmcmFre05lfV9cXHRhdSJdLFsyLDAsIlxcbWF0aGZyYWt7Un1fXFx0YXUiXSxbMCwyLCJcXG1hdGhmcmFre1RtfShcXHRhdSkiXSxbMiwyLCJcXG1hdGhmcmFre1RtfShcXHRhdSkiXSxbMiwzLCJcXG1hdGhmcmFre1RtfShcXHBpX3tcXHRleHRybXtzZW19fShcXFVwYXJyb3dee1xcdGF1fSkpPVxcdGV4dHJte2lkfSIsMl0sWzAsMiwibV9cXHRhdSIsMl0sWzAsMSwiXFxwaV97XFx0ZXh0cm17c3lufX0oXFxVcGFycm93XlxcdGF1KSA9XFx1cGFycm93XlxcdGF1Il0sWzEsMywicl9cXHRhdSIsMV1d
\[\begin{tikzcd}
	{\mathfrak{Ne}_\tau} && {\mathfrak{R}_\tau} \\
	\\
	{\mathfrak{Tm}(\tau)} && {\mathfrak{Tm}(\tau)}
	\arrow["{\mathfrak{Tm}(\pi_{\textrm{sem}}(\Uparrow^{\tau}))=\textrm{id}}"', from=3-1, to=3-3]
	\arrow["{m_\tau}"', from=1-1, to=3-1]
	\arrow["{\pi_{\textrm{syn}}(\Uparrow^\tau) =\uparrow^\tau}", from=1-1, to=1-3]
	\arrow["{r_\tau}", from=1-3, to=3-3]
\end{tikzcd}\]

which is the required triangle. In the reification case, we get the desired
triangle along the same lines. Convinced thus, we can set about defining the
required glued maps.

\section{Glued reification and reflection}\label{def:reify-reflect}
While defining these glued maps as pairs of suitable morphisms, we must take
care to verify that the pairs form actual glued morphisms. Fortunately, the
careful setup in the preceding pages makes this process almost automatic.
\begin{definition}
  The glued maps are defined by induction on the type structure of \( \types \):
  \begin{itemize}
    \item For a base type \( \theta \in T \), we define \( \Uparrow^{\theta} = \id_{\mu_{\theta}} \) and
    \( \Downarrow^{\theta} = \mu_{\theta} \xrightarrow[\cong]{\incl_{\theta}} \eta_{\theta} \)
    \item For the empty product/unit type \( \termob \), we define \( \Uparrow^{\termob} = (\mu_{\termob} \xrightarrow[\cong]{!} \termob )\) and \( \Downarrow^{\termob} = (\termob \xrightarrow[\cong]{(\unit, \id)} \eta_{\termob})\)

    The former is the identity which is a map in the gluing category by
    definition. The latter is an already defined glued map from
    Definition~\ref{def:glued-algebra}.

    \item For types \( \tau, \tau' \in \types\), we define 
    \[ \Uparrow^{\tau*\tau'} : \mu_{\tau*\tau'} \rightarrow \sem{\tau}_{\cl} \times \sem{\tau'}_{\cl}\] as the pair of the following composites:
    \begin{align*}
      &\mu_{\tau*\tau'} \xrightarrow{(\fst_{\tau}^{\tau'}, \pi_{1})} \mu_{\tau} \xrightarrow{\Uparrow^{\tau}} \sem{\tau}_{\gl} \\
      &\mu_{\tau*\tau'} \xrightarrow{(\snd_{\tau'}^{\tau}, \pi_{2})} \mu_{\tau'} \xrightarrow{\Uparrow^{\tau'}} \sem{\tau'}_{\gl} \\
    \end{align*}

    and define \( \Downarrow^{\tau*\tau'} : \sem{\tau}_{\gl} \times \sem{\tau'}_{\gl} \rightarrow \eta_{\tau*\tau'}\) as the composite
    \[ \sem{\tau}_{\gl}\times \sem{\tau'}_{\gl} \xrightarrow{\Downarrow^{\tau}\times \Downarrow^{\tau'}} \eta_{\tau} \times \eta_{\tau'} \xrightarrow[\cong]{(\pair_{\tau*\tau'}, \id)}     \eta_{\tau*\tau'} \]

          In each case, the first pair in the composite is a glued map from
          Definition~\ref{def:glued-algebra} while the second pair is a glued
          map by the induction hypothesis, so that the composite itself is a
          glued map. The product of these glued maps is a glued map by the
          universal property of products.

    \item For types \( \tau, \tau' \in \types \), we define the reflection map
    \[ \Uparrow^{\tau\rightarrow\tau'} : \mu_{\tau\rightarrow\tau'} \rightarrow {\sem{\tau'}_{\gl}}^{\sem{\tau}_{\gl}} \]
    as the exponential transpose of the composite
    \[ \mu_{\tau\rightarrow\tau'} \times \sem{\tau}_{\gl} \xrightarrow{\id \times \Downarrow^{\tau}} \mu_{\tau \rightarrow \tau'} \times \eta_{\tau} \xrightarrow{（\app_{\tau'}^{\tau}, \epsilon）} \mu_{\tau'} \xrightarrow{\Uparrow^{\tau'}} \sem{\tau'}_{\gl}\]

    By the universal property of the transpose, it suffices to  show that
    the composite is a glued map of the appropriate domain and codomain.
    This follows from the induction hypothesis, the universal property
    of products (as in the previous induction step), and since
    \( （\app_{\tau'}^{\tau}, \epsilon） \) is a glued map from
    Definition~\ref{def:glued-algebra}.

    We define the reification map as
    \[ \Downarrow^{\tau\rightarrow\tau'} : {\sem{\tau'}_{\gl}}^{\sem{\tau}_{\gl}} \rightarrow \eta_{\tau \rightarrow \tau'} \] as the composite
    \[ {\sem{\tau'}_{\gl}}^{\sem{\tau}_{\gl}} \xrightarrow{(\Downarrow^{\tau'})^{(\Uparrow^{\tau} v_{\tau})}} {\eta_{\tau'}}^{\nu_{\tau}} \xrightarrow[\cong]{(\abs_{\tau\rightarrow\tau'} , \id)} \eta_{\tau\rightarrow\tau'}\]
    where \( v_{\tau} = (\var_{\tau} , \id) : \nu_{\tau} \rightarrow \mu_{\tau}\).

    That this is a glued map follows from
    Definition~\ref{def:glued-algebra} and definition of the
    post/pre-composition functors TODO: what are these actually called,
    maybe check out topos theory book?
  \end{itemize}
\end{definition}

With the glued maps in hand, we can prove that they do nothing in the semantics.
Naturally, the following theorem will prove crucial when demonstrating that our
normalization function computes normal forms with the same semantics as the
input term. This result is stated but not proven in Fiore's extended abstract
\cite{fiore_semantic_2002}. The proof is my own.
\begin{theorem}[Reification and reflection are the identity in the semantics]\label{thm:reif-refl-sempres}
  For each type \( \tau \in \types \), we have the identities
  \[
    \semproj (\Uparrow^{\tau}) = \id_{\tau} = \semproj(\Downarrow^{\tau})
  \]
\end{theorem}
\begin{proof}
  The proof proceeds, like the definitions of the reification/reflection maps, by induction on the structure of types:
  \begin{itemize}
    \item For a base type \( \theta \in T\), the reflection map is
          \( \Uparrow^{\theta} = \id_{\mu_{\theta}}\). By functoriality of the interpretation
          \( \sem{-}_{\gl} : \cl \rightarrow \gl \) and
          Lemma~\ref{lem:sem-pi-is-id-endofunctor}, we have that
          \( \semproj (\id_{\mu_{\theta}}) = \id_{\sem{\theta}_{\cl}}\), as required. The
          reification map is
          \( \Downarrow^{\theta} = \mu_{\theta} \xrightarrow[\cong]{\incl_{\theta}} \eta_{\theta} \) whose semantic
          component is the identity by Definition~\ref{def:glued-algebra}.

    \item For the empty product/unit type \( \termob \), the reflection map
          \( \Uparrow^{\termob} \) is the unique arrow from \( \mu_{\termob}\) into the
          terminal object of the gluing category. The interpretation
          \( \sem{-}_{\gl}\) preserves the cartesian closed structure so that
          \( \mu_{\theta} = \termob \) and unique arrow in question is forced to be the
          identity in \( \gl \), whose semantic component is also the identity
          in \( \cl \).

          The reification map \( \Downarrow^{\termob} \) is the \( \unit \) operation for
          the glued algebra and has the identity as its semantic component by
          definition.
    \item For \( \tau, \tau' \in \types\), the reflection map \( \Uparrow^{\tau\times\tau'}\) for
          their product is defined as the pair of the following composites:
          \begin{align*}
            &\mu_{\tau*\tau'} \xrightarrow{(\fst_{\tau}^{\tau'}, \pi_{1})} \mu_{\tau} \xrightarrow{\Uparrow^{\tau}} \sem{\tau}_{\gl} \\
            &\mu_{tau*\tau'} \xrightarrow{(\snd_{\tau'}^{\tau}, \pi_{2})} \mu_{\tau'} \xrightarrow{\Uparrow^{\tau'}} \sem{\tau'}_{\gl} \\
          \end{align*} so that
          \begin{align*}
            \semproj (\Uparrow^{\tau\times\tau'}) &= (\semproj (\Uparrow^{\tau}) \circ \pi_{1}) \times (\semproj(\Uparrow^{\tau'}) \circ \pi_{2}) \\
                                &= (\id \circ \pi_{1}) \times (\id \circ \pi_{2}) && \textrm{(by the induction hypothesis)} \\
                                &= \pi_{1} \times \pi_{2}
          \end{align*}
          which is the identity on \( \sem{\tau}_{\cl} \times \sem{\tau'}_{\cl} \) as
          required.

          The reification map
          \( \Downarrow^{\tau*\tau'} : \sem{\tau}_{\gl} \times \sem{\tau'}_{\gl} \rightarrow \eta_{\tau*\tau'}\) is defined
          as the composite
          \[ \sem{\tau}_{\gl}\times \sem{\tau'}_{\gl} \xrightarrow{\Downarrow^{\tau}\times \Downarrow^{\tau'}} \eta_{\tau} \times \eta_{\tau'} \xrightarrow[\cong]{(\pair_{\tau*\tau'}, \id)} \eta_{\tau*\tau'} \].

          whose semantic component is the identity by the induction hypothesis
          and the definition of the product functor in the gluing category.

          \item For \( \tau, \tau' \in \types \), the reflection map \( \Uparrow^{\tau \rightarrow \tau'}\) for the function type over these is defined as the exponential transpose of the composite
          \[ \mu_{\tau\rightarrow\tau'} \times \sem{\tau}_{\gl} \xrightarrow{\id \times \Downarrow^{\tau}} \mu_{\tau \rightarrow \tau'} \times \eta_{\tau} \xrightarrow{（\app_{\tau'}^{\tau}, \epsilon）} \mu_{\tau'} \xrightarrow{\Uparrow^{\tau'}} \sem{\tau'}_{\gl}\] whence

            \begin{align*}
              \semproj (\Uparrow^{\tau \rightarrow \tau'}) &= \semproj (\reallywidetilde{\Uparrow^{\tau} \circ（\app_{\tau'}^{\tau}, \epsilon）\circ (\id \times \Downarrow^{\tau})}) \\
                                    &= \reallywidetilde{\semproj (\Uparrow^{\tau}) \circ \semproj (\app_{\tau'}^{\tau},\epsilon) \circ \semproj (\id \times \Downarrow^{\tau})} && \textrm{(by functoriality of $\semproj$)} \\
                                    &= \reallywidetilde{\id \circ \epsilon \circ (\id \times \id)} && \textrm{(induction hypothesis, definition of $\semproj$)} \\
                                    &= \reallywidetilde{\id \circ \id} && \textrm{(UP of the transpose, and since $\reallywidetilde{\id} = \id$)} \\
                                    &= \reallywidetilde{\id} \\
                                    &= \id \\
            \end{align*} as required.

            Now the reification map \( \Downarrow^{\tau \rightarrow \tau'} \) is defined as the composite
          \[ (\abs_{\tau \rightarrow \tau'}, \id) \circ (\Downarrow^{\tau'})^{(\Uparrow^{\tau} v_{\tau})}\] so that
          \begin{align*}
            \semproj(\Downarrow^{\tau\rightarrow\tau'}) &= \semproj(\abs_{\tau \rightarrow \tau'}, \id) \circ {(\semproj \Downarrow^{\tau'})}^{\semproj(\Uparrow^{\tau}) \circ \semproj(v_{\tau})} \\
                               &= \id \circ {(\id)}^{\id \circ \id} && \textrm{(induction hypothesis)} \\
                               &= {\id}^{\id} \\
                               &= \id^{*} \circ \id_{*} \\
          \end{align*}
          which is the identity on the exponential
          \( \sem{{\tau'}}_{\cl}^{\sem{\tau}_{\cl}}\) in the classifying category.
  \end{itemize}
\end{proof}
\newcommand{\normalize}{{\nf}\,_{\tau}^{\Gamma}}
\section{A promise kept: a function from open terms to normal terms}
Having defined our glued reify-reflect maps at each type, we have established
the desired diagram from Section~\ref{sec:taking-stock}. We can now define a
function \( \normalize : \mathfrak{L}_{\tau}(\Gamma) \rightarrow \mathfrak{Nf}_{\tau}(\Gamma)\) as the
composite

\[ \mathfrak{L}_{\tau}(\Gamma) \xrightarrow{l_{\tau}} \tm(\tau)(\Gamma) \xrightarrow{\sem{-}} \gl [\sem{\Gamma}, \sem{\tau}] \xrightarrow{(\Uparrow_{\Gamma} v_{\Gamma})^{*} \circ {\Downarrow^{\tau}}_{*}} \gl [\yoneda(\Gamma), \eta_{\tau}] \xrightarrow[\cong]{(d,\delta) \mapsto d(\id_{\Gamma})} \nfpsh(\Gamma) \]

where
\begin{align*}
  \Uparrow_{\Gamma} &= \prod_{(x:\tau)\in\Gamma} \Uparrow^{\tau} \\
  v_{\Gamma} &= \yonedabar(\Gamma) \xrightarrow{\cong} \prod_{(x:\tau)\in\Gamma}\nu_{\tau} \xrightarrow{\prod_{(x:\tau)\in\Gamma} v_{\tau}} \prod_{(x:\tau)\in\Gamma}\mu_{\tau} \\
\end{align*}

and recalling that \( \nu_{\tau} \xrightarrow{v_{\tau}} \mu_{\tau}\) is the \( \var_{\tau} \)
operation from the \( \NN \)-algebra on the gluing category.

Since the final isomorphism in the composite is a form of the Yoneda lemma and
hence given by evaluation at the identity, we have the following explicit
formula for each term $t$:
\[ \normalize (t) = (\Downarrow^{\tau} \sem{\Gamma \vdash t : \tau} \Uparrow_{\Gamma} v_{\Gamma}) (\id_{\Gamma}) \]

The function we've defined takes open terms to normal forms, but it remains to
establish the various correctness properties characterizing a normalization
function. The laborious setup work of this chapter turns out to allow us to do
so with ease.

\section{Reaping what we've sown: easy proofs of the correctness properties}
\begin{theorem}[Normalization respects computational equality]
  For every pair of terms \( t, t' \in \mathfrak{L}_{\tau}(\Gamma) \), if
  \( t \equiv_{\beta\eta\alpha} t' \) then \( {\nf}\,_{\tau}^{\Gamma}(t) = \nf\,_{\tau}^{\Gamma}(t')\).
\end{theorem}
\begin{proof}
  \( \beta\eta\alpha \)-equivalent terms have the same interpretation in the classifying
  category, because the classifying category is quotiented by definitional
  equality. Symbolically, we have \( l_{\tau}(t) = l_{\tau}(t')\) from which the
  required equality is immediate by the definition of the normalization function
  as a composite starting with \( l_{\tau}\).
\end{proof}

\begin{theorem}[Semantics preservation]
  The following diagram commutes for every type \( \tau \in \types \):
  % https://q.uiver.app/?q=WzAsMyxbMCwwLCJcXG1hdGhmcmFre0x9X1xcdGF1Il0sWzIsMCwiXFxtYXRoZnJha3tOZn1fXFx0YXUiXSxbMSwxLCJcXG1hdGhmcmFre1RtfShcXHRhdSkiXSxbMCwxLCJcXHRleHRybXtuZn1fXFx0YXUiXSxbMCwyLCJsX1xcdGF1IiwyXSxbMSwyLCJuX1xcdGF1Il1d
  \[\begin{tikzcd}
      {\mathfrak{L}_\tau} && {\mathfrak{Nf}_\tau} \\
      & {\mathfrak{Tm}(\tau)}
      \arrow["{\textrm{nf}_\tau}", from=1-1, to=1-3]
      \arrow["{l_\tau}"', from=1-1, to=2-2]
      \arrow["{n_\tau}", from=1-3, to=2-2]
    \end{tikzcd}\]
\end{theorem}
\begin{proof}
  Per the version of the Yoneda lemma from Definition~\ref{def:yonedabar}, we
  have that the composite \( n_{\tau} \circ ((d, \delta) \mapsto d(\id))\) of the semantic
  interpretation of normal forms in \( \cl \) with the isomorphism witnessinga
  the Yoneda lemma is the semantic projection \( \semproj \). So it suffices to
  show that
  \( \semproj (\Downarrow^{\tau} \sem{\Gamma \vdash t : \tau}_{\gl} (\Uparrow_{\Gamma}v_{\Gamma}) ) = \sem{\Gamma \vdash t : \tau}_{\cl} \).
  By Lemma~\ref{lem:sem-pi-is-id-endofunctor}, the interpretation of terms in
  the gluing category extends the interpretation of terms in the classifying
  category, so that
  \( \semproj (\sem{\Gamma \vdash t : \tau}_{\gl}) = \sem{\Gamma \vdash t : \tau}_{\cl}\). Now the desired
  equality follows from observing that the glued morphisms \( \Downarrow^{\tau} \),
  \( \Uparrow^{\tau}\), and \( v_{\tau} \) are all the identity in their semantic component,
  by Theorem~\ref{thm:reif-refl-sempres} and Definition~\ref{def:glued-algebra}.
\end{proof}

\section{Looking forward: ``blah'' by gluing}

\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
\chaptermark{Conclusion}
\markboth{Conclusion}{Conclusion}
\setcounter{chapter}{4}
\setcounter{section}{0}

That's it for now.

% If you feel it necessary to include an appendix, it goes here.
% \appendix
% \chapter{The First Appendix}

% This is where endnotes are supposed to go, if you have them.
% I have no idea how endnotes work with LaTeX.

\backmatter% backmatter makes the index and bibliography appear properly in the t.o.c...

% if you're using bibtex, the next line forces every entry in the bibtex file to be included
% in your bibliography, regardless of whether or not you've cited it in the thesis.
\nocite{*}

% Rename my bibliography to be called "Works Cited" and not "References" or ``Bibliography''
% \renewcommand{\bibname}{Works Cited}

% \bibliographystyle{bsts/mla-good} % there are a variety of styles available;
% \bibliographystyle{plainnat}
% replace ``plainnat'' with the style of choice. You can refer to files in the bsts or APA 
% subfolder, e.g.
\printbibliography[heading=bibintoc]
% \bibliographystyle{APA/apa-good}  % or
% \bibliography{thesis}
% Comment the above two lines and uncomment the next line to use biblatex-chicago.
% \printbibliography[heading=bibintoc]

% Finally, an index would go here... but it is also optional.
\end{document}
